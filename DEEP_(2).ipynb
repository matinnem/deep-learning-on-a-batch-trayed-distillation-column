{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W2IUH0UHNdY",
        "outputId": "b2d47f42-29ef-4170-9518-b982d9710dc9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'rm' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "     ######clarify variables and files########\n",
        "%reset -f\n",
        "!rm *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "P5dFu0wCHQxL",
        "outputId": "5ed732ad-d08f-4563-8978-25bed4fc76d9"
      },
      "outputs": [],
      "source": [
        "#         ######importing csv files: please import Bias_correction_ucl.csv and sobar-72.csv in google colab#####\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !{sys.executable} -m pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7uR7OQOaIArg"
      },
      "outputs": [],
      "source": [
        "#importing main librarries\n",
        "import pandas as pd\n",
        "from pandas.io.formats.info import DataFrameTableBuilderVerbose\n",
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sp\n",
        "import sklearn\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeTETgbgIuBc",
        "outputId": "acd87fae-3a13-4157-8cd7-6ad921fac9ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      condensor_pressure(atm)  reboiler(pot)_heat_duty(Watt)  reflux_ratio  \\\n",
            "0                         0.1                          466.7           0.2   \n",
            "1                         0.1                          466.7           0.4   \n",
            "2                         0.1                          466.7           0.6   \n",
            "3                         0.1                          466.7           0.8   \n",
            "4                         0.1                          466.7           1.0   \n",
            "...                       ...                            ...           ...   \n",
            "1295                      1.0                          933.3          12.2   \n",
            "1296                      1.0                          933.3          12.4   \n",
            "1297                      1.0                          933.3          12.6   \n",
            "1298                      1.0                          933.3          12.8   \n",
            "1299                      1.0                          933.3          13.0   \n",
            "\n",
            "      input_mass_fraction_of_acetic_acid  pot_pressure(atm)  daily_work(min)  \\\n",
            "0                                   0.99           0.198692          78.4891   \n",
            "1                                   0.99           0.198692          87.1483   \n",
            "2                                   0.99           0.198692          95.8063   \n",
            "3                                   0.99           0.198692         104.4650   \n",
            "4                                   0.99           0.198692         113.1170   \n",
            "...                                  ...                ...              ...   \n",
            "1295                                0.99           1.098692         308.1360   \n",
            "1296                                0.99           1.098692         312.3540   \n",
            "1297                                0.99           1.098692         316.5750   \n",
            "1298                                0.99           1.098692         320.7970   \n",
            "1299                                0.99           1.098692         325.0160   \n",
            "\n",
            "      produced_acetic_acid_mass_fraction  reboiler(pot)_temperature(C)  \\\n",
            "0                               0.993735                     72.569104   \n",
            "1                               0.994775                     72.611140   \n",
            "2                               0.995847                     72.655253   \n",
            "3                               0.997028                     72.702093   \n",
            "4                               0.998110                     72.747633   \n",
            "...                                  ...                           ...   \n",
            "1295                            0.999993                    121.671350   \n",
            "1296                            0.999992                    121.670688   \n",
            "1297                            0.999994                    121.671606   \n",
            "1298                            0.999994                    121.671535   \n",
            "1299                            0.999994                    121.671074   \n",
            "\n",
            "      condensor_temperature(C)  upper_product_flow_rate(kg/hr)  \\\n",
            "0                    56.406005                        3.747279   \n",
            "1                    56.392932                        3.174455   \n",
            "2                    56.374529                        2.759391   \n",
            "3                    56.350584                        2.438666   \n",
            "4                    56.325561                        2.184895   \n",
            "...                        ...                             ...   \n",
            "1295                118.009307                        0.654385   \n",
            "1296                118.009292                        0.644054   \n",
            "1297                118.009280                        0.634918   \n",
            "1298                118.009267                        0.625764   \n",
            "1299                118.009254                        0.616490   \n",
            "\n",
            "      condensor_mass_flow_outlet_rate  fraction_over_pressure  \\\n",
            "0                            4.496735                9.937350   \n",
            "1                            4.444238                9.947750   \n",
            "2                            4.415026                9.958470   \n",
            "3                            4.389598                9.970280   \n",
            "4                            4.369790                9.981100   \n",
            "...                               ...                     ...   \n",
            "1295                         8.637884                0.999993   \n",
            "1296                         8.630320                0.999992   \n",
            "1297                         8.634888                0.999994   \n",
            "1298                         8.635548                0.999994   \n",
            "1299                         8.630854                0.999994   \n",
            "\n",
            "      duty_over_frac_multiplyed_by_pressure  reboiler_temp_on_flowrate  \\\n",
            "0                               4696.423091                  19.365811   \n",
            "1                               4691.513156                  22.873574   \n",
            "2                               4686.462880                  26.330177   \n",
            "3                               4680.911669                  29.812244   \n",
            "4                               4675.837333                  33.295714   \n",
            "...                                     ...                        ...   \n",
            "1295                             933.306533                 185.932319   \n",
            "1296                             933.307467                 188.913883   \n",
            "1297                             933.305600                 191.633499   \n",
            "1298                             933.305600                 194.436674   \n",
            "1299                             933.305600                 197.361130   \n",
            "\n",
            "      condensor_temp_on_flowrate  upper_product_precent  aceticindutyoverflow  \\\n",
            "0                      15.052522                99.3735            123.763425   \n",
            "1                      17.764600                99.4775            146.249178   \n",
            "2                      20.430062                99.5847            168.429120   \n",
            "3                      23.107138                99.7028            190.806384   \n",
            "4                      25.779530                99.8110            213.199249   \n",
            "...                          ...                    ...                   ...   \n",
            "1295                  180.336161                99.9993           1426.214297   \n",
            "1296                  183.228959                99.9992           1449.091142   \n",
            "1297                  185.865315                99.9994           1469.944208   \n",
            "1298                  188.584202                99.9994           1491.447112   \n",
            "1299                  191.421338                99.9994           1513.885202   \n",
            "\n",
            "      refluxin_pot_devidedby_cond_temp  daily_work_multip_duty  \\\n",
            "0                             1.995796             36630.86297   \n",
            "1                             4.019897             40672.11161   \n",
            "2                             4.950357             44712.80021   \n",
            "3                             5.555937             48753.81550   \n",
            "4                             6.002119             52791.70390   \n",
            "...                                ...                     ...   \n",
            "1295                          8.724562            287583.32880   \n",
            "1296                          8.745249            291519.98820   \n",
            "1297                          8.766613            295459.44750   \n",
            "1298                          8.786966            299399.84010   \n",
            "1299                          8.806720            303337.43280   \n",
            "\n",
            "      daily_work_multip_fraction_over_duty  \n",
            "0                                 0.167125  \n",
            "1                                 0.185757  \n",
            "2                                 0.204432  \n",
            "3                                 0.223172  \n",
            "4                                 0.241918  \n",
            "...                                    ...  \n",
            "1295                              0.330155  \n",
            "1296                              0.334674  \n",
            "1297                              0.339198  \n",
            "1298                              0.343721  \n",
            "1299                              0.348242  \n",
            "\n",
            "[1300 rows x 20 columns]\n",
            "condensor_pressure(atm)                  0\n",
            "reboiler(pot)_heat_duty(Watt)            0\n",
            "reflux_ratio                             0\n",
            "input_mass_fraction_of_acetic_acid       0\n",
            "pot_pressure(atm)                        0\n",
            "daily_work(min)                          0\n",
            "produced_acetic_acid_mass_fraction       0\n",
            "reboiler(pot)_temperature(C)             0\n",
            "condensor_temperature(C)                 0\n",
            "upper_product_flow_rate(kg/hr)           0\n",
            "condensor_mass_flow_outlet_rate          0\n",
            "fraction_over_pressure                   0\n",
            "duty_over_frac_multiplyed_by_pressure    0\n",
            "reboiler_temp_on_flowrate                0\n",
            "condensor_temp_on_flowrate               0\n",
            "upper_product_precent                    0\n",
            "aceticindutyoverflow                     0\n",
            "refluxin_pot_devidedby_cond_temp         0\n",
            "daily_work_multip_duty                   0\n",
            "daily_work_multip_fraction_over_duty     0\n",
            "dtype: int64\n",
            "condensor_pressure(atm)                  0\n",
            "reboiler(pot)_heat_duty(Watt)            0\n",
            "reflux_ratio                             0\n",
            "input_mass_fraction_of_acetic_acid       0\n",
            "pot_pressure(atm)                        0\n",
            "daily_work(min)                          0\n",
            "produced_acetic_acid_mass_fraction       0\n",
            "reboiler(pot)_temperature(C)             0\n",
            "condensor_temperature(C)                 0\n",
            "upper_product_flow_rate(kg/hr)           0\n",
            "condensor_mass_flow_outlet_rate          0\n",
            "fraction_over_pressure                   0\n",
            "duty_over_frac_multiplyed_by_pressure    0\n",
            "reboiler_temp_on_flowrate                0\n",
            "condensor_temp_on_flowrate               0\n",
            "upper_product_precent                    0\n",
            "aceticindutyoverflow                     0\n",
            "refluxin_pot_devidedby_cond_temp         0\n",
            "daily_work_multip_duty                   0\n",
            "daily_work_multip_fraction_over_duty     0\n",
            "dtype: int64\n",
            "[[1.00000000e-01 9.93735000e-01 7.25691044e+01]\n",
            " [1.00000000e-01 9.94775000e-01 7.26111401e+01]\n",
            " [1.00000000e-01 9.95847000e-01 7.26552526e+01]\n",
            " ...\n",
            " [1.00000000e+00 9.99994000e-01 1.21671606e+02]\n",
            " [1.00000000e+00 9.99994000e-01 1.21671535e+02]\n",
            " [1.00000000e+00 9.99994000e-01 1.21671074e+02]]\n",
            "[[2.00000e-01 7.84891e+01]\n",
            " [4.00000e-01 8.71483e+01]\n",
            " [6.00000e-01 9.58063e+01]\n",
            " ...\n",
            " [1.26000e+01 3.16575e+02]\n",
            " [1.28000e+01 3.20797e+02]\n",
            " [1.30000e+01 3.25016e+02]]\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "                   ######seprating features and targets#######\n",
        "# \n",
        "# from keras.src.engine.training import potentially_ragged_\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "# import xgboost as xgb\n",
        "\n",
        "df_1 = pd.read_csv('Data_for_project_kam.csv')\n",
        "print(df_1)\n",
        "\n",
        "#seeking for NaNs\n",
        "print(df_1.isnull().sum())\n",
        "\n",
        "\n",
        "  #cleaning NaNs\n",
        "df_1 = df_1.replace('',np.nan)\n",
        "df_1 = df_1.dropna(axis=\"rows\", how=\"any\")\n",
        "df_1 = df_1.replace('',np.nan)\n",
        "print(df_1.isnull().sum())\n",
        "df_1.shape\n",
        " #declaring fetures and outputs\n",
        "features = ['condensor_pressure(atm)', 'produced_acetic_acid_mass_fraction', 'reboiler(pot)_temperature(C)']  # 'condenser_heat_removal(Watt)']\n",
        "targets = ['reflux_ratio', 'daily_work(min)']\n",
        "# scale = StandardScaler()\n",
        "X = df_1[features]\n",
        "Y = df_1[targets]\n",
        "X_1 = df_1[['condensor_pressure(atm)', 'produced_acetic_acid_mass_fraction']]\n",
        "X_2 = df_1['reboiler(pot)_temperature(C)']\n",
        "\n",
        "# x = scale.fit_transform(X)\n",
        "# y = scale.fit_transform(Y)\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "# print(x)\n",
        "# print(y)\n",
        "print(X)\n",
        "print(Y)\n",
        "# print(type(x))\n",
        "print(type(X))\n",
        "\n",
        "# model_1 = RandomForestRegressor()\n",
        "# # model_1 = xgb.XGBRegressor()\n",
        "# # model_1.fit(np.array(X_1).reshape(-1,1),np.array(X_2).reshape(-1,1))\n",
        "# model_1.fit(X_1,X_2)\n",
        "# X_2 = model_1.predict(X_1)\n",
        "# new_X_2 = pd.DataFrame(X_2,columns=[\"new_reboiler(pot)_temperature(C)\"])\n",
        "# df_1.__delitem__('reboiler(pot)_temperature(C)')\n",
        "# df_1.insert(2, 'new_reboiler(pot)_temperature(C)', new_X_2)\n",
        "# print(df_1)\n",
        "X = df_1[['condensor_pressure(atm)', 'produced_acetic_acid_mass_fraction', 'reboiler(pot)_temperature(C)','condensor_temperature(C)', 'upper_product_flow_rate(kg/hr)', 'condensor_mass_flow_outlet_rate',\n",
        "          'aceticindutyoverflow',\n",
        "          'pot_pressure(atm)', 'fraction_over_pressure', 'duty_over_frac_multiplyed_by_pressure', 'reboiler_temp_on_flowrate', 'condensor_temp_on_flowrate', 'reboiler(pot)_heat_duty(Watt)']]# 'condenser_mass_flow_outlet_rate']]\n",
        "Y = df_1[['reflux_ratio', 'daily_work(min)']]\n",
        "def pressure_to_boiler_temp(inps):\n",
        "  df_1 = pd.read_csv('Data_for_project_kam.csv')\n",
        "  X_1 = df_1[['condensor_pressure(atm)', 'reboiler(pot)_heat_duty(Watt)', 'produced_acetic_acid_mass_fraction']]\n",
        "  X_2 = df_1['reboiler(pot)_temperature(C)']\n",
        "  model = RandomForestRegressor()\n",
        "  model.fit(X_1,X_2)\n",
        "  input_data_as_numpy_array = np.asarray(inps)\n",
        "  input_data_reshaped = input_data_as_numpy_array.reshape(1, -1)\n",
        "  boiler_temp = model.predict(input_data_reshaped)\n",
        "  return boiler_temp\n",
        "\n",
        "    ## این جا نیاز نیست یه بار رگرسیون بگیری. با رگرسیون مرتبه 5 که توی اکسله بیا اینجا اول فشار هارو\n",
        "    ## تبدیل به np.array کن و سپس ببر توی حلقه فوذ ورگرسیون بگیر.\n",
        "    ## و سپس دوباره اون هارو به دیتا فریم تبدیل کن و بدش به df_1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1300, 20)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>condensor_pressure(atm)</th>\n",
              "      <th>reboiler(pot)_heat_duty(Watt)</th>\n",
              "      <th>reflux_ratio</th>\n",
              "      <th>input_mass_fraction_of_acetic_acid</th>\n",
              "      <th>pot_pressure(atm)</th>\n",
              "      <th>daily_work(min)</th>\n",
              "      <th>produced_acetic_acid_mass_fraction</th>\n",
              "      <th>reboiler(pot)_temperature(C)</th>\n",
              "      <th>condensor_temperature(C)</th>\n",
              "      <th>upper_product_flow_rate(kg/hr)</th>\n",
              "      <th>condensor_mass_flow_outlet_rate</th>\n",
              "      <th>fraction_over_pressure</th>\n",
              "      <th>duty_over_frac_multiplyed_by_pressure</th>\n",
              "      <th>reboiler_temp_on_flowrate</th>\n",
              "      <th>condensor_temp_on_flowrate</th>\n",
              "      <th>upper_product_precent</th>\n",
              "      <th>aceticindutyoverflow</th>\n",
              "      <th>refluxin_pot_devidedby_cond_temp</th>\n",
              "      <th>daily_work_multip_duty</th>\n",
              "      <th>daily_work_multip_fraction_over_duty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.00</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.550000</td>\n",
              "      <td>700.000000</td>\n",
              "      <td>6.600000</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.648692</td>\n",
              "      <td>271.418236</td>\n",
              "      <td>0.999470</td>\n",
              "      <td>102.077392</td>\n",
              "      <td>95.134455</td>\n",
              "      <td>1.270713</td>\n",
              "      <td>6.453542</td>\n",
              "      <td>2.927626</td>\n",
              "      <td>2051.227627</td>\n",
              "      <td>135.412253</td>\n",
              "      <td>126.134234</td>\n",
              "      <td>99.947046</td>\n",
              "      <td>825.845220</td>\n",
              "      <td>7.799327</td>\n",
              "      <td>171216.236216</td>\n",
              "      <td>0.479217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.287339</td>\n",
              "      <td>233.389783</td>\n",
              "      <td>3.753777</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.287339</td>\n",
              "      <td>149.801304</td>\n",
              "      <td>0.001403</td>\n",
              "      <td>15.155106</td>\n",
              "      <td>18.817469</td>\n",
              "      <td>1.189411</td>\n",
              "      <td>2.151374</td>\n",
              "      <td>2.630502</td>\n",
              "      <td>2059.134067</td>\n",
              "      <td>87.011913</td>\n",
              "      <td>83.266327</td>\n",
              "      <td>0.140319</td>\n",
              "      <td>409.777199</td>\n",
              "      <td>1.767608</td>\n",
              "      <td>74888.475017</td>\n",
              "      <td>0.371286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>466.700000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.198692</td>\n",
              "      <td>54.253100</td>\n",
              "      <td>0.992886</td>\n",
              "      <td>72.548530</td>\n",
              "      <td>56.273718</td>\n",
              "      <td>0.301740</td>\n",
              "      <td>4.224361</td>\n",
              "      <td>0.992886</td>\n",
              "      <td>466.702800</td>\n",
              "      <td>9.687442</td>\n",
              "      <td>7.530771</td>\n",
              "      <td>99.288600</td>\n",
              "      <td>123.763425</td>\n",
              "      <td>0.461985</td>\n",
              "      <td>36630.862970</td>\n",
              "      <td>0.057763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.300000</td>\n",
              "      <td>466.700000</td>\n",
              "      <td>3.400000</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.398692</td>\n",
              "      <td>152.528500</td>\n",
              "      <td>0.999874</td>\n",
              "      <td>90.996683</td>\n",
              "      <td>82.763228</td>\n",
              "      <td>0.566231</td>\n",
              "      <td>4.307012</td>\n",
              "      <td>1.249953</td>\n",
              "      <td>895.751557</td>\n",
              "      <td>67.239050</td>\n",
              "      <td>61.135180</td>\n",
              "      <td>99.987450</td>\n",
              "      <td>475.372632</td>\n",
              "      <td>7.069953</td>\n",
              "      <td>106717.488525</td>\n",
              "      <td>0.195249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.550000</td>\n",
              "      <td>700.000000</td>\n",
              "      <td>6.600000</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.648692</td>\n",
              "      <td>244.712000</td>\n",
              "      <td>0.999978</td>\n",
              "      <td>104.808722</td>\n",
              "      <td>99.541050</td>\n",
              "      <td>0.846593</td>\n",
              "      <td>6.473134</td>\n",
              "      <td>1.826531</td>\n",
              "      <td>1254.071178</td>\n",
              "      <td>117.638821</td>\n",
              "      <td>108.790177</td>\n",
              "      <td>99.997800</td>\n",
              "      <td>824.765502</td>\n",
              "      <td>8.045106</td>\n",
              "      <td>171268.165900</td>\n",
              "      <td>0.315644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.800000</td>\n",
              "      <td>933.300000</td>\n",
              "      <td>9.800000</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.898692</td>\n",
              "      <td>351.414000</td>\n",
              "      <td>0.999995</td>\n",
              "      <td>115.132448</td>\n",
              "      <td>110.890872</td>\n",
              "      <td>1.483040</td>\n",
              "      <td>8.609492</td>\n",
              "      <td>3.333290</td>\n",
              "      <td>2333.502334</td>\n",
              "      <td>181.500635</td>\n",
              "      <td>169.670257</td>\n",
              "      <td>99.999500</td>\n",
              "      <td>1177.546899</td>\n",
              "      <td>8.907031</td>\n",
              "      <td>235682.099900</td>\n",
              "      <td>0.752963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>933.300000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0.99</td>\n",
              "      <td>1.098692</td>\n",
              "      <td>632.826000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>121.671606</td>\n",
              "      <td>118.157013</td>\n",
              "      <td>7.488925</td>\n",
              "      <td>8.986710</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9392.416426</td>\n",
              "      <td>394.641083</td>\n",
              "      <td>382.763370</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>1546.695546</td>\n",
              "      <td>11.359648</td>\n",
              "      <td>309337.618500</td>\n",
              "      <td>1.355959</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       condensor_pressure(atm)  reboiler(pot)_heat_duty(Watt)  reflux_ratio  \\\n",
              "count              1300.000000                    1300.000000   1300.000000   \n",
              "mean                  0.550000                     700.000000      6.600000   \n",
              "std                   0.287339                     233.389783      3.753777   \n",
              "min                   0.100000                     466.700000      0.200000   \n",
              "25%                   0.300000                     466.700000      3.400000   \n",
              "50%                   0.550000                     700.000000      6.600000   \n",
              "75%                   0.800000                     933.300000      9.800000   \n",
              "max                   1.000000                     933.300000     13.000000   \n",
              "\n",
              "       input_mass_fraction_of_acetic_acid  pot_pressure(atm)  daily_work(min)  \\\n",
              "count                             1300.00        1300.000000      1300.000000   \n",
              "mean                                 0.99           0.648692       271.418236   \n",
              "std                                  0.00           0.287339       149.801304   \n",
              "min                                  0.99           0.198692        54.253100   \n",
              "25%                                  0.99           0.398692       152.528500   \n",
              "50%                                  0.99           0.648692       244.712000   \n",
              "75%                                  0.99           0.898692       351.414000   \n",
              "max                                  0.99           1.098692       632.826000   \n",
              "\n",
              "       produced_acetic_acid_mass_fraction  reboiler(pot)_temperature(C)  \\\n",
              "count                         1300.000000                   1300.000000   \n",
              "mean                             0.999470                    102.077392   \n",
              "std                              0.001403                     15.155106   \n",
              "min                              0.992886                     72.548530   \n",
              "25%                              0.999874                     90.996683   \n",
              "50%                              0.999978                    104.808722   \n",
              "75%                              0.999995                    115.132448   \n",
              "max                              1.000000                    121.671606   \n",
              "\n",
              "       condensor_temperature(C)  upper_product_flow_rate(kg/hr)  \\\n",
              "count               1300.000000                     1300.000000   \n",
              "mean                  95.134455                        1.270713   \n",
              "std                   18.817469                        1.189411   \n",
              "min                   56.273718                        0.301740   \n",
              "25%                   82.763228                        0.566231   \n",
              "50%                   99.541050                        0.846593   \n",
              "75%                  110.890872                        1.483040   \n",
              "max                  118.157013                        7.488925   \n",
              "\n",
              "       condensor_mass_flow_outlet_rate  fraction_over_pressure  \\\n",
              "count                      1300.000000             1300.000000   \n",
              "mean                          6.453542                2.927626   \n",
              "std                           2.151374                2.630502   \n",
              "min                           4.224361                0.992886   \n",
              "25%                           4.307012                1.249953   \n",
              "50%                           6.473134                1.826531   \n",
              "75%                           8.609492                3.333290   \n",
              "max                           8.986710               10.000000   \n",
              "\n",
              "       duty_over_frac_multiplyed_by_pressure  reboiler_temp_on_flowrate  \\\n",
              "count                            1300.000000                1300.000000   \n",
              "mean                             2051.227627                 135.412253   \n",
              "std                              2059.134067                  87.011913   \n",
              "min                               466.702800                   9.687442   \n",
              "25%                               895.751557                  67.239050   \n",
              "50%                              1254.071178                 117.638821   \n",
              "75%                              2333.502334                 181.500635   \n",
              "max                              9392.416426                 394.641083   \n",
              "\n",
              "       condensor_temp_on_flowrate  upper_product_precent  \\\n",
              "count                 1300.000000            1300.000000   \n",
              "mean                   126.134234              99.947046   \n",
              "std                     83.266327               0.140319   \n",
              "min                      7.530771              99.288600   \n",
              "25%                     61.135180              99.987450   \n",
              "50%                    108.790177              99.997800   \n",
              "75%                    169.670257              99.999500   \n",
              "max                    382.763370             100.000000   \n",
              "\n",
              "       aceticindutyoverflow  refluxin_pot_devidedby_cond_temp  \\\n",
              "count           1300.000000                       1300.000000   \n",
              "mean             825.845220                          7.799327   \n",
              "std              409.777199                          1.767608   \n",
              "min              123.763425                          0.461985   \n",
              "25%              475.372632                          7.069953   \n",
              "50%              824.765502                          8.045106   \n",
              "75%             1177.546899                          8.907031   \n",
              "max             1546.695546                         11.359648   \n",
              "\n",
              "       daily_work_multip_duty  daily_work_multip_fraction_over_duty  \n",
              "count             1300.000000                           1300.000000  \n",
              "mean            171216.236216                              0.479217  \n",
              "std              74888.475017                              0.371286  \n",
              "min              36630.862970                              0.057763  \n",
              "25%             106717.488525                              0.195249  \n",
              "50%             171268.165900                              0.315644  \n",
              "75%             235682.099900                              0.752963  \n",
              "max             309337.618500                              1.355959  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_1.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>condensor_pressure(atm)</th>\n",
              "      <th>produced_acetic_acid_mass_fraction</th>\n",
              "      <th>reboiler(pot)_temperature(C)</th>\n",
              "      <th>condensor_temperature(C)</th>\n",
              "      <th>upper_product_flow_rate(kg/hr)</th>\n",
              "      <th>condensor_mass_flow_outlet_rate</th>\n",
              "      <th>aceticindutyoverflow</th>\n",
              "      <th>pot_pressure(atm)</th>\n",
              "      <th>fraction_over_pressure</th>\n",
              "      <th>duty_over_frac_multiplyed_by_pressure</th>\n",
              "      <th>reboiler_temp_on_flowrate</th>\n",
              "      <th>condensor_temp_on_flowrate</th>\n",
              "      <th>reboiler(pot)_heat_duty(Watt)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "      <td>1300.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.999470</td>\n",
              "      <td>102.077392</td>\n",
              "      <td>95.134455</td>\n",
              "      <td>1.270713</td>\n",
              "      <td>6.453542</td>\n",
              "      <td>825.845220</td>\n",
              "      <td>0.648692</td>\n",
              "      <td>2.927626</td>\n",
              "      <td>2051.227627</td>\n",
              "      <td>135.412253</td>\n",
              "      <td>126.134234</td>\n",
              "      <td>700.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.287339</td>\n",
              "      <td>0.001403</td>\n",
              "      <td>15.155106</td>\n",
              "      <td>18.817469</td>\n",
              "      <td>1.189411</td>\n",
              "      <td>2.151374</td>\n",
              "      <td>409.777199</td>\n",
              "      <td>0.287339</td>\n",
              "      <td>2.630502</td>\n",
              "      <td>2059.134067</td>\n",
              "      <td>87.011913</td>\n",
              "      <td>83.266327</td>\n",
              "      <td>233.389783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.992886</td>\n",
              "      <td>72.548530</td>\n",
              "      <td>56.273718</td>\n",
              "      <td>0.301740</td>\n",
              "      <td>4.224361</td>\n",
              "      <td>123.763425</td>\n",
              "      <td>0.198692</td>\n",
              "      <td>0.992886</td>\n",
              "      <td>466.702800</td>\n",
              "      <td>9.687442</td>\n",
              "      <td>7.530771</td>\n",
              "      <td>466.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.300000</td>\n",
              "      <td>0.999874</td>\n",
              "      <td>90.996683</td>\n",
              "      <td>82.763228</td>\n",
              "      <td>0.566231</td>\n",
              "      <td>4.307012</td>\n",
              "      <td>475.372632</td>\n",
              "      <td>0.398692</td>\n",
              "      <td>1.249953</td>\n",
              "      <td>895.751557</td>\n",
              "      <td>67.239050</td>\n",
              "      <td>61.135180</td>\n",
              "      <td>466.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.550000</td>\n",
              "      <td>0.999978</td>\n",
              "      <td>104.808722</td>\n",
              "      <td>99.541050</td>\n",
              "      <td>0.846593</td>\n",
              "      <td>6.473134</td>\n",
              "      <td>824.765502</td>\n",
              "      <td>0.648692</td>\n",
              "      <td>1.826531</td>\n",
              "      <td>1254.071178</td>\n",
              "      <td>117.638821</td>\n",
              "      <td>108.790177</td>\n",
              "      <td>700.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.999995</td>\n",
              "      <td>115.132448</td>\n",
              "      <td>110.890872</td>\n",
              "      <td>1.483040</td>\n",
              "      <td>8.609492</td>\n",
              "      <td>1177.546899</td>\n",
              "      <td>0.898692</td>\n",
              "      <td>3.333290</td>\n",
              "      <td>2333.502334</td>\n",
              "      <td>181.500635</td>\n",
              "      <td>169.670257</td>\n",
              "      <td>933.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>121.671606</td>\n",
              "      <td>118.157013</td>\n",
              "      <td>7.488925</td>\n",
              "      <td>8.986710</td>\n",
              "      <td>1546.695546</td>\n",
              "      <td>1.098692</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>9392.416426</td>\n",
              "      <td>394.641083</td>\n",
              "      <td>382.763370</td>\n",
              "      <td>933.300000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       condensor_pressure(atm)  produced_acetic_acid_mass_fraction  \\\n",
              "count              1300.000000                         1300.000000   \n",
              "mean                  0.550000                            0.999470   \n",
              "std                   0.287339                            0.001403   \n",
              "min                   0.100000                            0.992886   \n",
              "25%                   0.300000                            0.999874   \n",
              "50%                   0.550000                            0.999978   \n",
              "75%                   0.800000                            0.999995   \n",
              "max                   1.000000                            1.000000   \n",
              "\n",
              "       reboiler(pot)_temperature(C)  condensor_temperature(C)  \\\n",
              "count                   1300.000000               1300.000000   \n",
              "mean                     102.077392                 95.134455   \n",
              "std                       15.155106                 18.817469   \n",
              "min                       72.548530                 56.273718   \n",
              "25%                       90.996683                 82.763228   \n",
              "50%                      104.808722                 99.541050   \n",
              "75%                      115.132448                110.890872   \n",
              "max                      121.671606                118.157013   \n",
              "\n",
              "       upper_product_flow_rate(kg/hr)  condensor_mass_flow_outlet_rate  \\\n",
              "count                     1300.000000                      1300.000000   \n",
              "mean                         1.270713                         6.453542   \n",
              "std                          1.189411                         2.151374   \n",
              "min                          0.301740                         4.224361   \n",
              "25%                          0.566231                         4.307012   \n",
              "50%                          0.846593                         6.473134   \n",
              "75%                          1.483040                         8.609492   \n",
              "max                          7.488925                         8.986710   \n",
              "\n",
              "       aceticindutyoverflow  pot_pressure(atm)  fraction_over_pressure  \\\n",
              "count           1300.000000        1300.000000             1300.000000   \n",
              "mean             825.845220           0.648692                2.927626   \n",
              "std              409.777199           0.287339                2.630502   \n",
              "min              123.763425           0.198692                0.992886   \n",
              "25%              475.372632           0.398692                1.249953   \n",
              "50%              824.765502           0.648692                1.826531   \n",
              "75%             1177.546899           0.898692                3.333290   \n",
              "max             1546.695546           1.098692               10.000000   \n",
              "\n",
              "       duty_over_frac_multiplyed_by_pressure  reboiler_temp_on_flowrate  \\\n",
              "count                            1300.000000                1300.000000   \n",
              "mean                             2051.227627                 135.412253   \n",
              "std                              2059.134067                  87.011913   \n",
              "min                               466.702800                   9.687442   \n",
              "25%                               895.751557                  67.239050   \n",
              "50%                              1254.071178                 117.638821   \n",
              "75%                              2333.502334                 181.500635   \n",
              "max                              9392.416426                 394.641083   \n",
              "\n",
              "       condensor_temp_on_flowrate  reboiler(pot)_heat_duty(Watt)  \n",
              "count                 1300.000000                    1300.000000  \n",
              "mean                   126.134234                     700.000000  \n",
              "std                     83.266327                     233.389783  \n",
              "min                      7.530771                     466.700000  \n",
              "25%                     61.135180                     466.700000  \n",
              "50%                    108.790177                     700.000000  \n",
              "75%                    169.670257                     933.300000  \n",
              "max                    382.763370                     933.300000  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_new = pd.read_csv('min_max_duty.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Difine Dict with the key-value pair to remap.\n",
        "# dict = {0.1 : 1, 0.2 : 2, 0.3 : 3, 0.4 : 4, 0.5 : 5, 0.6 : 6, 0.7 : 7, 0.8 : 8, 0.9 : 9, 1 : 10}\n",
        "# df_5 = df_1.replace({\"condensor_pressure(atm)\": dict})\n",
        "# print(\"After replacing a column values with a dictionary values:\\n\", df_5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from keras import optimizers\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, LSTM\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from keras.utils import to_categorical\n",
        "# import xgboost as xgb\n",
        "# from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "# X_aval = df_5[['reboiler(pot)_heat_duty(Watt)', 'produced_acetic_acid_mass_fraction', 'daily_work(min)', 'pot_pressure(atm)']]\n",
        "# # X_aval = df_1[['daily_work(min)', 'condensor_pressure(atm)']]\n",
        "# Y_aval = df_5[['condensor_pressure(atm)']]\n",
        "# # num_classes = 10\n",
        "\n",
        "# X_aval = np.array(X_aval)\n",
        "# Y_aval = np.array(Y_aval)\n",
        "# X_train, X_test, Y_train, Y_test = train_test_split(X_aval, Y_aval , test_size=0.2, random_state=6)\n",
        "\n",
        "# n_inputs_first = X_aval.shape[1]\n",
        "# n_outputs_first = Y_aval.shape[1]\n",
        "\n",
        "# # regressor_xgb = xgb.XGBRegressor(n_estimators=50001)\n",
        "# regressor_xgb = xgb.XGBRFRegressor()#n_estimators=50001, early_stop_rounds=5000, subsample=0.64, learning_rate=0.0099, min_child_weight=3)#n_estimators=30001,\n",
        "#                                 #   early_stop_rounds=50,#,\n",
        "#                                 #   max_depth=4)\n",
        "# #                                   min_child_weight=7,\n",
        "# #                                   gamma=0,\n",
        "# #                                   subsample=0.9,\n",
        "# #                                   colsample_bytree=1,\n",
        "# #                                   reg_alpha=0.05,\n",
        "# #                                   nthread=5,\n",
        "# #                                   scale_pos_weight=1,\n",
        "# #                                   objective='reg:squarederror',\n",
        "# #                                   seed=32,\n",
        "# #                                   learning_rate=0.00299)\n",
        "\n",
        "# # # regressor_main = RandomForestRegressor()\n",
        "# regressor_xgb.fit(X_train, Y_train, eval_set=[(X_train, Y_train),(X_test, Y_test)],verbose=500)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      condensor_pressure(atm)  produced_acetic_acid_mass_fraction  \\\n",
            "0                   -1.566699                           -4.089015   \n",
            "1                   -1.566699                           -3.347562   \n",
            "2                   -1.566699                           -2.583295   \n",
            "3                   -1.566699                           -1.741319   \n",
            "4                   -1.566699                           -0.969923   \n",
            "...                       ...                                 ...   \n",
            "1295                 1.566699                            0.372534   \n",
            "1296                 1.566699                            0.371822   \n",
            "1297                 1.566699                            0.373247   \n",
            "1298                 1.566699                            0.373247   \n",
            "1299                 1.566699                            0.373247   \n",
            "\n",
            "      reboiler(pot)_temperature(C)  condensor_temperature(C)  \\\n",
            "0                        -1.947835                 -2.058904   \n",
            "1                        -1.945060                 -2.059599   \n",
            "2                        -1.942148                 -2.060577   \n",
            "3                        -1.939056                 -2.061850   \n",
            "4                        -1.936050                 -2.063180   \n",
            "...                            ...                       ...   \n",
            "1295                      1.293392                  1.216086   \n",
            "1296                      1.293349                  1.216085   \n",
            "1297                      1.293409                  1.216084   \n",
            "1298                      1.293405                  1.216084   \n",
            "1299                      1.293374                  1.216083   \n",
            "\n",
            "      upper_product_flow_rate(kg/hr)  condensor_mass_flow_outlet_rate  \\\n",
            "0                           2.082981                        -0.909912   \n",
            "1                           1.601192                        -0.934323   \n",
            "2                           1.252091                        -0.947906   \n",
            "3                           0.982337                        -0.959730   \n",
            "4                           0.768896                        -0.968941   \n",
            "...                              ...                              ...   \n",
            "1295                       -0.518379                         1.015715   \n",
            "1296                       -0.527068                         1.012197   \n",
            "1297                       -0.534752                         1.014322   \n",
            "1298                       -0.542451                         1.014628   \n",
            "1299                       -0.550252                         1.012446   \n",
            "\n",
            "      aceticindutyoverflow  pot_pressure(atm)  fraction_over_pressure  \\\n",
            "0                -1.713985          -1.566699                2.665812   \n",
            "1                -1.659091          -1.566699                2.669767   \n",
            "2                -1.604943          -1.566699                2.673844   \n",
            "3                -1.550314          -1.566699                2.678335   \n",
            "4                -1.495646          -1.566699                2.682450   \n",
            "...                    ...                ...                     ...   \n",
            "1295              1.465675           1.566699               -0.733082   \n",
            "1296              1.521524           1.566699               -0.733083   \n",
            "1297              1.572432           1.566699               -0.733082   \n",
            "1298              1.624927           1.566699               -0.733082   \n",
            "1299              1.679705           1.566699               -0.733082   \n",
            "\n",
            "      duty_over_frac_multiplyed_by_pressure  reboiler_temp_on_flowrate  \\\n",
            "0                                  1.285110                  -1.334198   \n",
            "1                                  1.282724                  -1.293869   \n",
            "2                                  1.280271                  -1.254128   \n",
            "3                                  1.277574                  -1.214094   \n",
            "4                                  1.275109                  -1.174044   \n",
            "...                                     ...                        ...   \n",
            "1295                              -0.543117                   0.580834   \n",
            "1296                              -0.543117                   0.615114   \n",
            "1297                              -0.543118                   0.646381   \n",
            "1298                              -0.543118                   0.678610   \n",
            "1299                              -0.543118                   0.712233   \n",
            "\n",
            "      condensor_temp_on_flowrate  reboiler(pot)_heat_duty(Watt)  reflux_ratio  \\\n",
            "0                      -1.334567                           -1.0     -1.705606   \n",
            "1                      -1.301983                           -1.0     -1.652306   \n",
            "2                      -1.269959                           -1.0     -1.599005   \n",
            "3                      -1.237796                           -1.0     -1.545705   \n",
            "4                      -1.205689                           -1.0     -1.492405   \n",
            "...                          ...                            ...           ...   \n",
            "1295                    0.651197                            1.0      1.492405   \n",
            "1296                    0.685952                            1.0      1.545705   \n",
            "1297                    0.717626                            1.0      1.599005   \n",
            "1298                    0.750291                            1.0      1.652306   \n",
            "1299                    0.784377                            1.0      1.705606   \n",
            "\n",
            "      daily_work(min)  \n",
            "0           -1.288396  \n",
            "1           -1.230569  \n",
            "2           -1.172750  \n",
            "3           -1.114927  \n",
            "4           -1.057148  \n",
            "...               ...  \n",
            "1295         0.245204  \n",
            "1296         0.273372  \n",
            "1297         0.301560  \n",
            "1298         0.329755  \n",
            "1299         0.357930  \n",
            "\n",
            "[1300 rows x 15 columns]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Lenovo\\python\\lib\\site-packages\\sklearn\\utils\\validation.py:757: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\Lenovo\\python\\lib\\site-packages\\sklearn\\utils\\validation.py:595: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if is_sparse(pd_dtype):\n",
            "c:\\Users\\Lenovo\\python\\lib\\site-packages\\sklearn\\utils\\validation.py:604: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
            "c:\\Users\\Lenovo\\python\\lib\\site-packages\\sklearn\\utils\\validation.py:757: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if not hasattr(array, \"sparse\") and array.dtypes.apply(is_sparse).any():\n",
            "c:\\Users\\Lenovo\\python\\lib\\site-packages\\sklearn\\utils\\validation.py:595: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if is_sparse(pd_dtype):\n",
            "c:\\Users\\Lenovo\\python\\lib\\site-packages\\sklearn\\utils\\validation.py:604: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
            "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "data= df_1[['condensor_pressure(atm)', 'produced_acetic_acid_mass_fraction', 'reboiler(pot)_temperature(C)','condensor_temperature(C)', 'upper_product_flow_rate(kg/hr)', 'condensor_mass_flow_outlet_rate',\n",
        "            'aceticindutyoverflow',\n",
        "          'pot_pressure(atm)', 'fraction_over_pressure', 'duty_over_frac_multiplyed_by_pressure', 'reboiler_temp_on_flowrate', 'condensor_temp_on_flowrate', 'reboiler(pot)_heat_duty(Watt)', 'reflux_ratio','daily_work(min)']]\n",
        "\n",
        "# scale = StandardScaler()\n",
        "scale = StandardScaler()\n",
        "normalized_data = scale.fit_transform(data)# axis=0)\n",
        "# normalized_data = preprocessing.minmax_scale(data ,axis=0)\n",
        "scaled_data = pd.DataFrame(normalized_data, columns=data.columns)\n",
        "print(scaled_data)\n",
        "\n",
        "# X = scaled_data[['condensor_pressure(atm)', 'produced_acetic_acid_mass_fraction', 'new_reboiler(pot)_temperature(C)','condensor_temperature(C)', 'upper_product_flow_rate(kg/hr)', 'condensor_mass_flow_outlet_rate',\n",
        "#                  'produced_acetic_acid_multip_duty_over_upper_flow',\n",
        "#           'pot_pressure(atm)', 'fraction_over_pressure', 'duty_over_frac_multiplyed_by_pressure', 'reboiler_temp_on_flowrate', 'condensor_temp_on_flowrate', 'reboiler(pot)_heat_duty(Watt)']]# 'condenser_mass_flow_outlet_rate']]\n",
        "# Y = scaled_data[['reflux_ratio', 'daily_work(min)']]\n",
        "# print(Y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# atm_pressure = float(input(\"please enter the atmosophere or condenser peresure in atm (a number between 0.1 and 1: )\"))\n",
        "# heat_duty_select = float(input(\"please enter the heat_duty of the heater\"+ '\\n'+ \"insert 1 if this is 466.7 watt \"+ '\\n'+ \"insert 2 if this is 933.3 watt: \" + '\\n'))\n",
        "# if heat_duty_select == 1:\n",
        "#   heat_duty = 466.7\n",
        "# elif heat_duty_select == 2:\n",
        "#   heat_duty = 933.3\n",
        "\n",
        "# acetic_acid_mf = float(input(\"please insert the acetic acid mass fraction that you prefer in distillate receiver: \"))\n",
        "# inputs = (atm_pressure, heat_duty, acetic_acid_mf)\n",
        "# boil_temp = pressure_to_boiler_temp(inputs)\n",
        "# print(boil_temp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-rmse:0.28594\tvalidation_1-rmse:0.28751\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2000]\tvalidation_0-rmse:0.03601\tvalidation_1-rmse:0.08252\n",
            "[4000]\tvalidation_0-rmse:0.02966\tvalidation_1-rmse:0.07737\n",
            "[6000]\tvalidation_0-rmse:0.02694\tvalidation_1-rmse:0.07636\n",
            "[8000]\tvalidation_0-rmse:0.02539\tvalidation_1-rmse:0.07577\n",
            "[10000]\tvalidation_0-rmse:0.02438\tvalidation_1-rmse:0.07538\n",
            "[12000]\tvalidation_0-rmse:0.02367\tvalidation_1-rmse:0.07524\n",
            "[14000]\tvalidation_0-rmse:0.02316\tvalidation_1-rmse:0.07516\n",
            "[16000]\tvalidation_0-rmse:0.02278\tvalidation_1-rmse:0.07513\n",
            "[18000]\tvalidation_0-rmse:0.02247\tvalidation_1-rmse:0.07525\n",
            "[20000]\tvalidation_0-rmse:0.02224\tvalidation_1-rmse:0.07520\n",
            "[22000]\tvalidation_0-rmse:0.02204\tvalidation_1-rmse:0.07523\n",
            "[24000]\tvalidation_0-rmse:0.02188\tvalidation_1-rmse:0.07533\n",
            "[26000]\tvalidation_0-rmse:0.02175\tvalidation_1-rmse:0.07525\n",
            "[28000]\tvalidation_0-rmse:0.02163\tvalidation_1-rmse:0.07525\n",
            "[30000]\tvalidation_0-rmse:0.02154\tvalidation_1-rmse:0.07528\n",
            "[32000]\tvalidation_0-rmse:0.02145\tvalidation_1-rmse:0.07535\n",
            "[34000]\tvalidation_0-rmse:0.02137\tvalidation_1-rmse:0.07540\n",
            "[36000]\tvalidation_0-rmse:0.02130\tvalidation_1-rmse:0.07546\n",
            "[38000]\tvalidation_0-rmse:0.02124\tvalidation_1-rmse:0.07552\n",
            "[40000]\tvalidation_0-rmse:0.02120\tvalidation_1-rmse:0.07557\n",
            "[42000]\tvalidation_0-rmse:0.02114\tvalidation_1-rmse:0.07546\n",
            "[44000]\tvalidation_0-rmse:0.02110\tvalidation_1-rmse:0.07544\n",
            "[46000]\tvalidation_0-rmse:0.02106\tvalidation_1-rmse:0.07538\n",
            "[48000]\tvalidation_0-rmse:0.02103\tvalidation_1-rmse:0.07546\n",
            "[50000]\tvalidation_0-rmse:0.02099\tvalidation_1-rmse:0.07547\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "             gamma=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=0.0051, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
              "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=50001, n_jobs=None, nthread=2,\n",
              "             num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "             gamma=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=0.0051, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
              "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=50001, n_jobs=None, nthread=2,\n",
              "             num_parallel_tree=None, ...)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
              "             colsample_bylevel=None, colsample_bynode=None,\n",
              "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "             gamma=None, grow_policy=None, importance_type=None,\n",
              "             interaction_constraints=None, learning_rate=0.0051, max_bin=None,\n",
              "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "             max_delta_step=None, max_depth=9, max_leaves=None,\n",
              "             min_child_weight=3, missing=nan, monotone_constraints=None,\n",
              "             multi_strategy=None, n_estimators=50001, n_jobs=None, nthread=2,\n",
              "             num_parallel_tree=None, ...)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "import xgboost as xgb\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "X_aval = df_1[['reboiler(pot)_heat_duty(Watt)', 'produced_acetic_acid_mass_fraction', 'daily_work(min)']]\n",
        "# X_aval = df_1[['reboiler(pot)_heat_duty(Watt)', 'daily_work(min)']]\n",
        "\n",
        "# X_aval = df_1[['daily_work(min)', 'condensor_pressure(atm)']]\n",
        "Y_aval = df_1[['condensor_pressure(atm)']]\n",
        "# num_classes = 10\n",
        "\n",
        "X_aval = np.array(X_aval)\n",
        "Y_aval = np.array(Y_aval)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_aval, Y_aval , test_size=0.2, random_state=6)\n",
        "\n",
        "n_inputs_first = X_aval.shape[1]\n",
        "n_outputs_first = Y_aval.shape[1]\n",
        "\n",
        "# regressor_xgb = xgb.XGBRegressor(n_estimators=50001)\n",
        "regressor_xgb = xgb.XGBRegressor(n_estimators=50001, subsample=0.5, learning_rate=0.0051, min_child_weight=3, seed=32, max_depth=9, nthread=2)#n_estimators=30001,\n",
        "                                #   early_stop_rounds=50,#,\n",
        "                                #   max_depth=4)\n",
        "#                                   min_child_weight=7,\n",
        "#                                   gamma=0,\n",
        "#                                   subsample=0.9,\n",
        "#                                   colsample_bytree=1,\n",
        "#                                   reg_alpha=0.05,\n",
        "#                                   nthread=5,\n",
        "#                                   scale_pos_weight=1,\n",
        "#                                   objective='reg:squarederror',\n",
        "#                                   seed=32,\n",
        "#                                   learning_rate=0.00299)\n",
        "\n",
        "# # regressor_main = RandomForestRegressor()\n",
        "regressor_xgb.fit(X_train, Y_train, eval_set=[(X_train, Y_train),(X_test, Y_test)],verbose=2000)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x1999e2b7af0>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x700 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "results = regressor_xgb.evals_result()\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(results[\"validation_0\"][\"rmse\"], label=\"Training loss\")\n",
        "plt.plot(results[\"validation_1\"][\"rmse\"], label=\"Validation loss\")\n",
        "plt.axvline(1200, color=\"gray\", label=\"Optimal tree number\")\n",
        "# plt.xlim([500,3000])\n",
        "# plt.ylim([22.5,27.5])\n",
        "plt.xlabel(\"Number of trees\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "xgboost regressor r2 socre =  0.9313677128730904\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score\n",
        "# regressor_xgb.fit(X_train,Y_train)\n",
        "predicted_reboiler_temp_xgb = regressor_xgb.predict(X_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(\"neural network regressor r2 socre =\", r2_score(Y_test_first_reg,Y_predicted_reboiler_temp))\n",
        "# print(\"random forest regressor r2 socre = \", r2_score(Y_test_first_reg,predicted_reboiler_temp))\n",
        "# print(\"decision tree regressor r2 socre = \", r2_score(Y_test_first_reg,predicted_reboiler_temp_tree))\n",
        "# print(\"linear regression r2 socre = \", r2_score(Y_test_first_reg,predicted_reboiler_temp_lin))\n",
        "print(\"xgboost regressor r2 socre = \", r2_score(Y_test,predicted_reboiler_temp_xgb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>real reboiler duty</th>\n",
              "      <th>predicted reboiler duty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.011030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.1</td>\n",
              "      <td>0.121939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.3</td>\n",
              "      <td>0.264102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.3</td>\n",
              "      <td>0.301316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.8</td>\n",
              "      <td>0.763637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>0.8</td>\n",
              "      <td>0.798799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>0.3</td>\n",
              "      <td>0.295420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.498664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>0.7</td>\n",
              "      <td>0.728263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>0.3</td>\n",
              "      <td>0.343431</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>260 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     real reboiler duty  predicted reboiler duty\n",
              "0                   1.0                 1.011030\n",
              "1                   0.1                 0.121939\n",
              "2                   0.3                 0.264102\n",
              "3                   0.3                 0.301316\n",
              "4                   0.8                 0.763637\n",
              "..                  ...                      ...\n",
              "255                 0.8                 0.798799\n",
              "256                 0.3                 0.295420\n",
              "257                 0.5                 0.498664\n",
              "258                 0.7                 0.728263\n",
              "259                 0.3                 0.343431\n",
              "\n",
              "[260 rows x 2 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame({'real reboiler duty': Y_test.squeeze(),\n",
        "              'predicted reboiler duty': predicted_reboiler_temp_xgb.squeeze()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "file_name = \"xgb_reg_pressure.pkl\"\n",
        "\n",
        "# save\n",
        "# pickle.dump(regressor_xgb, open(file_name, \"wb\"))\n",
        "\n",
        "# load\n",
        "xgb_pressure_model_loaded = pickle.load(open(file_name, \"rb\"))\n",
        "\n",
        "# test\n",
        "ind = 1\n",
        "# test = X_val[ind]\n",
        "xgb_pressure_model_loaded.predict(X_test)[0] == regressor_xgb.predict(X_test)[0]\n",
        "\n",
        "Out[1]: True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "predicted_reboiler_duty_xgb = xgb_pressure_model_loaded.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>real daily work</th>\n",
              "      <th>predicted daily work(min)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.011030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.1</td>\n",
              "      <td>0.121939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.3</td>\n",
              "      <td>0.264102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.3</td>\n",
              "      <td>0.301316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.8</td>\n",
              "      <td>0.763637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>0.8</td>\n",
              "      <td>0.798799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>0.3</td>\n",
              "      <td>0.295420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.498664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>0.7</td>\n",
              "      <td>0.728263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>0.3</td>\n",
              "      <td>0.343431</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>260 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     real daily work  predicted daily work(min)\n",
              "0                1.0                   1.011030\n",
              "1                0.1                   0.121939\n",
              "2                0.3                   0.264102\n",
              "3                0.3                   0.301316\n",
              "4                0.8                   0.763637\n",
              "..               ...                        ...\n",
              "255              0.8                   0.798799\n",
              "256              0.3                   0.295420\n",
              "257              0.5                   0.498664\n",
              "258              0.7                   0.728263\n",
              "259              0.3                   0.343431\n",
              "\n",
              "[260 rows x 2 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame({'real daily work': Y_test.squeeze(),\n",
        "              'predicted daily work(min)': predicted_reboiler_temp_xgb.squeeze()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from keras import optimizers\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, LSTM\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from keras.utils import to_categorical\n",
        "\n",
        "# from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# # mlp = MLPClassifier(hidden_layer_sizes=(), \n",
        "# #                     solver='lbfgs')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # X_min_max = df_new[['duty', 'pressure']]\n",
        "# # Y_min = df_new[['min_daily_work']]\n",
        "# # Y_max = df_new[['max_daily_work']]\n",
        "\n",
        "# X_min_max = df_1[['daily_work(min)','produced_acetic_acid_mass_fraction', 'reboiler(pot)_heat_duty(Watt)']]\n",
        "# Y_min = df_1[['condensor_pressure(atm)']]\n",
        "# num_classes = 10\n",
        "\n",
        "# X_min_max = np.array(X_min_max)\n",
        "# Y_min = np.array(Y_min)\n",
        "# # Y_max = np.array(Y_max)\n",
        "# X_train, X_test, Y_train, Y_test = train_test_split(X_min_max, Y_min , test_size=0.2, random_state=6)\n",
        "# Y_train = to_categorical(Y_train, num_classes)\n",
        "# Y_test = to_categorical(Y_test, num_classes)\n",
        "# n_inputs_first = X_min_max.shape[1]\n",
        "# n_outputs_first = Y_min.shape[1]\n",
        "\n",
        "# n_inputs_second = X_min_max.shape[1]\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Dense(350, input_shape=(n_inputs_first,), activation='relu'))\n",
        "# model.add(Dense(50, activation='relu'))\n",
        "# model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# # Configure the model and start training\n",
        "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# model.fit(X_train, Y_train, epochs=1000, batch_size=32, verbose=1, validation_split=0.2)\n",
        "\n",
        "# # Test the model after training\n",
        "# test_results = model.evaluate(X_test, Y_test, verbose=1)\n",
        "# print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]}%')\n",
        "\n",
        "\n",
        "# # model = tf.keras.models.Sequential([\n",
        "# #     tf.keras.layers.Flatten(),\n",
        "# #     tf.keras.layers.Dense(200, activation=tf.nn.softmax)\n",
        "# # ])\n",
        "# # model.compile(optimizer='adam',\n",
        "# # loss='mae')\n",
        "\n",
        "# # model.fit(X_train, Y_train, epochs=1000)\n",
        "\n",
        "# # mlp.fit(X_train,Y_train)\n",
        "# # prob = clf.predict_proba(X_test)\n",
        "\n",
        "# # prob_mlp = mlp.predict_proba(X_test)\n",
        "# # take the second probability \n",
        "# # (to be in category 1) for each example\n",
        "# # and reshape it to a 1D array of size 100\n",
        "# # prob_mlp = prob_mlp[:,1].reshape(len(X_test))\n",
        "# # plt.plot(X_test, prob, color='red', label='regression')\n",
        "# # plt.plot(X_test, prob_mlp, color='blue', label='MLP')\n",
        "# # plt.scatter(x0, y0)\n",
        "# # plt.scatter(x1, y1)\n",
        "# # plt.legend()\n",
        "# # plt.xlabel('x')\n",
        "# # plt.ylabel('category probability')\n",
        "\n",
        "\n",
        "\n",
        "# # n_outputs_second = Y_max.shape[1]\n",
        "\n",
        "# # min_reg_model = Sequential()\n",
        "\n",
        "\n",
        "# # min_reg_model.add(LSTM(44, recurrent_dropout=0.2, activation='relu', input_shape=(n_inputs_first,1), return_sequences=True))\n",
        "# # min_reg_model.add(Dense(96, kernel_initializer='uniform', activation='relu'))\n",
        "\n",
        "# # # first_reg_model.add(LSTM(13, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "# # # first_reg_model.add(LSTM(14, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "# # min_reg_model.add(LSTM(50, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "# # min_reg_model.add(Dense(96, kernel_initializer='uniform', activation='relu'))\n",
        "\n",
        "# # # first_reg_model.add(LSTM(40, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "# # # first_reg_model.add(LSTM(10, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "# # # first_reg_model.add(LSTM(25, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "# # min_reg_model.add(LSTM(30, recurrent_dropout=0.2, activation='relu'))\n",
        "# # # first_reg_model.add(Dense(117, activation='relu'))\n",
        "\n",
        "\n",
        "# # min_reg_model.add(Dense(120, input_dim=n_inputs_first, kernel_initializer='uniform', activation='relu'))\n",
        "# # # first_reg_model.add(Dense(96, kernel_initializer='uniform', activation='relu'))\n",
        "# # min_reg_model.add(Dense(84, kernel_initializer='uniform', activation='relu'))\n",
        "# # min_reg_model.add(Dense(84, kernel_initializer='uniform', activation='relu'))\n",
        "# # min_reg_model.add(Dense(84, kernel_initializer='uniform', activation='relu'))\n",
        "# # min_reg_model.add(Dense(84, kernel_initializer='uniform', activation='relu'))\n",
        "# # min_reg_model.add(Dense(32, kernel_initializer='uniform', activation='relu'))\n",
        "\n",
        "# # # first_reg_model.add(Dense(96, kernel_initializer='uniform', activation='relu'))\n",
        "# # # first_reg_model.add(Dense(96, kernel_initializer='uniform', activation='relu'))\n",
        "# # # first_reg_model.add(Dense(96, kernel_initializer='uniform', activation='relu'))\n",
        "# # # first_reg_model.add(Dense(48, kernel_initializer='uniform', activation='relu'))\n",
        "\n",
        "# # # first_reg_model.add(GRU(120, recurrent_dropout=0.2, activation='relu', input_shape=(n_inputs_first_reg,1), return_sequences=True))\n",
        "# # #     # model.add(GRU(n2, recurrent_dropout=0.2, activation='relu'))\n",
        "# # # first_reg_model.add(Dense(43, activation='relu'))\n",
        "# # # first_reg_model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "# # # first_reg_model.add(Dense(65, kernel_initializer='uniform', activation='relu'))\n",
        "# # # first_reg_model.add(Dense(52, kernel_initializer='uniform', activation='relu'))\n",
        "# # # first_reg_model.add(Dense(39, kernel_initializer='uniform', activation='relu'))\n",
        "# # # first_reg_model.add(Dense(26, kernel_initializer='uniform', activation='relu'))\n",
        "# # min_reg_model.add(Dense(n_outputs_first, activation='linear'))\n",
        "# # opt = optimizers.Adam(learning_rate=0.001)#, beta_1=0.8, beta_2=0.75, epsilon=1e-7, amsgrad=False, name='Adam')\n",
        "\n",
        "# # min_reg_model.compile(loss='mae', optimizer='adam')\n",
        "# # min_reg_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7AI7D-FQSMT",
        "outputId": "cc6ccb1c-6b21-4121-c670-7a57a8a7ed1a"
      },
      "outputs": [],
      "source": [
        "# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "# data= df_1[['condensor_pressure(atm)', 'produced_acetic_acid_mass_fraction', 'new_reboiler(pot)_temperature(C)','condensor_temperature(C)', 'upper_product_flow_rate(kg/hr)', 'condensor_mass_flow_outlet_rate',\n",
        "#             'aceticindutyoverflow',\n",
        "#           'pot_pressure(atm)', 'fraction_over_pressure', 'duty_over_frac_multiplyed_by_pressure', 'reboiler_temp_on_flowrate', 'condensor_temp_on_flowrate', 'reboiler(pot)_heat_duty(Watt)', 'reflux_ratio', 'daily_work(min)']]\n",
        "\n",
        "# # scale = StandardScaler()\n",
        "# scale = MinMaxScaler()\n",
        "# normalized_data = scale.fit_transform(data)# axis=0)\n",
        "# # normalized_data = preprocessing.minmax_scale(data ,axis=0)\n",
        "# scaled_data = pd.DataFrame(normalized_data, columns=data.columns)\n",
        "# print(scaled_data)\n",
        "\n",
        "# X = scaled_data[['condensor_pressure(atm)', 'produced_acetic_acid_mass_fraction', 'new_reboiler(pot)_temperature(C)','condensor_temperature(C)', 'upper_product_flow_rate(kg/hr)', 'condensor_mass_flow_outlet_rate',\n",
        "#                  'produced_acetic_acid_multip_duty_over_upper_flow',\n",
        "#           'pot_pressure(atm)', 'fraction_over_pressure', 'duty_over_frac_multiplyed_by_pressure', 'reboiler_temp_on_flowrate', 'condensor_temp_on_flowrate', 'reboiler(pot)_heat_duty(Watt)']]# 'condenser_mass_flow_outlet_rate']]\n",
        "# Y = scaled_data[['reflux_ratio', 'daily_work(min)']]\n",
        "# print(Y)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # atm_pressure = float(input(\"please enter the atmosophere or condenser peresure in atm (a number between 0.1 and 1: )\"))\n",
        "# # heat_duty_select = float(input(\"please enter the heat_duty of the heater\"+ '\\n'+ \"insert 1 if this is 466.7 watt \"+ '\\n'+ \"insert 2 if this is 933.3 watt: \" + '\\n'))\n",
        "# # if heat_duty_select == 1:\n",
        "# #   heat_duty = 466.7\n",
        "# # elif heat_duty_select == 2:\n",
        "# #   heat_duty = 933.3\n",
        "\n",
        "# # acetic_acid_mf = float(input(\"please insert the acetic acid mass fraction that you prefer in distillate receiver: \"))\n",
        "# # inputs = (atm_pressure, heat_duty, acetic_acid_mf)\n",
        "# # boil_temp = pressure_to_boiler_temp(inputs)\n",
        "# # print(boil_temp)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# scaled_data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CEbXRTFLK9Lj"
      },
      "outputs": [],
      "source": [
        "# from keras.src.engine.training import potentially_ragged_concat\n",
        "# from sklearn.ensemble import RandomForestRegressor\n",
        "# model_1 = RandomForestRegressor()\n",
        "# model_1.fit(X[:,0].reshape(-1,1),X[:,2].ravel())\n",
        "# model_1.score(X[:,0].reshape(-1,1),X[:,2].ravel())\n",
        "# # print(X[:,0].reshape(-1,1))\n",
        "# pot_temperature = model_1.predict(X[:,0].reshape(-1,1))\n",
        "# X = pd.DataFrame(X)\n",
        "# Y = pd.DataFrame(Y)\n",
        "# pot_temperature = pd.DataFrame(pot_temperature)\n",
        "\n",
        "\n",
        "\n",
        "# # model_2 = RandomForestRegressor()\n",
        "# # model_2.fit(X[:,0].reshape(-1,1),X[:,5].ravel())\n",
        "# # model_2.score(X[:,0].reshape(-1,1),X[:,5].ravel())\n",
        "# # # print(X[:,0].reshape(-1,1))\n",
        "# # cond_temperature = model_1.predict(X[:,0].reshape(-1,1))\n",
        "# # print(cond_temperature)\n",
        "# # cond_temperature = pd.DataFrame(cond_temperature)\n",
        "\n",
        "# ###در اینجا به دنبال این باش که این دمای جدید پات را به جای دمای بدست آمده در دیتا فریم قرار بدی. تازه وقتی توان 933.3 را وارد کردی هم یه بار دیگه باید مدل فیت کنی. و همچنین باید برای دمای کندانسورهم این کار رو بکنی\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1h5TcDDf7lv"
      },
      "outputs": [],
      "source": [
        "   ###design a class or function for your neural network\n",
        "   ## gggrelu bashe activation\n",
        "# from keras import optimizers\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# def main_network(n_inputs, n_outputs):\n",
        "#   main_model = Sequential()\n",
        "#   main_model.add(Dense(120, input_dim=n_inputs, kernel_initializer='uniform', activation='relu'))\n",
        "#   main_model.add(Dense(60, kernel_initializer='uniform', activation='relu'))\n",
        "#   main_model.add(Dense(60, kernel_initializer='uniform', activation='relu'))\n",
        "#   main_model.add(Dense(60, kernel_initializer='uniform', activation='relu'))\n",
        "#   main_model.add(Dense(60, kernel_initializer='uniform', activation='relu'))\n",
        "#   main_model.add(Dense(24, kernel_initializer='uniform', activation='relu'))\n",
        "#   # main_model.add(Dense(12, kernel_initializer='uniform', activation='relu'))\n",
        "# #   main_model.add(Dense(20, kernel_initializer='random_normal', activation='relu'))\n",
        "# #   main_model.add(Dense(20, kernel_initializer='random_normal', activation='relu'))\n",
        "#   opt = optimizers.Adam(learning_rate=0.01, beta_1=0.75, beta_2=0.75, epsilon=1e-7, amsgrad=False, name='Adam')\n",
        "#   main_model.add(Dense(n_outputs))\n",
        "#   main_model.compile(loss='mae', optimizer=opt)\n",
        "  \n",
        "  \n",
        "#   mylayers = main_model.layers\n",
        "#   for layer in mylayers:\n",
        "#       if hasattr(layer, 'get_weights'):\n",
        "#           weights, biases = layer.get_weights()\n",
        "#           print('Layer Name:', layer.name)\n",
        "#           print('Weights:', weights)\n",
        "#           print('Biases:', biases)\n",
        " \n",
        "  # return main_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import sys\n",
        "# !{sys.executable} -m pip install opytimizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Dropout, GRU, LSTM, Conv1D, Flatten #CuDNNLSTM\n",
        "# from keras import optimizers\n",
        "# from opytimizer import Opytimizer\n",
        "# from opytimizer.core import Function\n",
        "# from opytimizer.optimizers.swarm import PSO\n",
        "# from opytimizer.spaces import SearchSpace\n",
        "\n",
        "\n",
        "# def main_network(n_inputs, n_outputs):\n",
        "#     main_model = Sequential()\n",
        "    \n",
        "#     # main_model.add(LSTM(63, input_shape=n_inputs, activation='relu', return_sequences=True))\n",
        "#     main_model.add(GRU(72,input_shape=n_inputs,activation='relu', return_sequences=True,))\n",
        "#     # main_model.add(GRU(14,input_shape=n_inputs,activation='relu', return_sequences=True))\n",
        "#     main_model.add(Dropout(0.2))\n",
        "    \n",
        "#     # main_model.add(LSTM(63, activation='relu'))\n",
        "#     main_model.add(GRU(72,activation='relu'))\n",
        "#     # main_model.add(GRU(14,activation='relu'))\n",
        "#     main_model.add(Dropout(0.2))\n",
        "    \n",
        " \n",
        "    \n",
        "#     main_model.add(Dense(18, activation='relu'))\n",
        "#     # main_model.add(Dense(5, activation='relu'))\n",
        "#     main_model.add(Dropout(0.2))\n",
        "    \n",
        "\n",
        "    \n",
        "#     main_model.add(Dense(n_outputs))\n",
        "    \n",
        "#     opt = optimizers.Adam(learning_rate=0.01, beta_1=0.8, beta_2=0.7, epsilon=1e-7, amsgrad=False, name='Adam')\n",
        "#     # opt = PSO()\n",
        "#     main_model.compile(loss='mae', optimizer=opt)\n",
        " \n",
        "#     return main_model\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Conv1D, Flatten #CuDNNLSTM\n",
        "# from keras import optimizers\n",
        "\n",
        "# def main_network(n_inputs, n_outputs):\n",
        "#     main_model = Sequential()\n",
        "#     main_model.add(Conv1D(72, input_shape=n_inputs, activation=\"relu\", kernel_size=3))\n",
        "#     main_model.add(Flatten())\n",
        "#     main_model.add(Dense(64, activation=\"relu\"))\n",
        "#     main_model.add(Dense(n_outputs))\n",
        "    \n",
        "#     opt = optimizers.Adam(learning_rate=0.01, beta_1=0.8, beta_2=0.7, epsilon=1e-7, amsgrad=False, name='Adam')\n",
        "#     main_model.compile(loss='mae', optimizer=opt)\n",
        "#     return main_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # evaluate a model using repeated k-fold cross-validation\n",
        "# from sklearn.model_selection import RepeatedKFold\n",
        "# from numpy import mean\n",
        "# from numpy import std\n",
        "# from keras.callbacks import EarlyStopping\n",
        "\n",
        "# def evaluate_model(X, Y):\n",
        "#     results = list()\n",
        "#     # n_inputs = X.shape[1:]\n",
        "#     n_inputs = X.shape[1]\n",
        "#     n_outputs = Y.shape[1]\n",
        " \t\n",
        "# \t# define evaluation procedure\n",
        "#     cv = RepeatedKFold(n_splits=10, n_repeats=1, random_state=0)\n",
        "# \t# enumerate folds\t\n",
        "#     num_of_stages = 0\n",
        "#     stages = []\n",
        "#     for train_ix, test_ix in cv.split(X):\n",
        "#         X_train, X_test = X[train_ix], X[test_ix]\n",
        "#         Y_train, Y_test = Y[train_ix], Y[test_ix]\n",
        "        \n",
        "#         model = main_network(n_inputs, n_outputs)\n",
        "#         es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=25)\n",
        "#         model.fit(X_train, Y_train, verbose=0, epochs=100,callbacks=es)\n",
        "#         mae = model.evaluate(X_test, Y_test, verbose=0)\n",
        "#         num_of_stages += 1\n",
        "#         print(num_of_stages, '>', 'mean absolute error=', '%.3f' %  mae)\n",
        "#         results.append(mae)\n",
        "#         stages.append(num_of_stages)\n",
        "    \n",
        "#     stage_min = results.index(min(results))\n",
        "#     stage_min +=1\n",
        "#     print('MAE: %.3f (%.3f)' % (mean(results), std(results)))\n",
        "#     print('minimum mae: ', '%.3f' %  min(results), 'its stage number is', '%.3f' % stage_min)\n",
        "#     # print(model.predict(X[5][:][0]))\n",
        "#     plt.plot(stages , results)\n",
        "#     plt.title(\"evaluation of network\")\n",
        "#     plt.xlabel(\"number of stages\")\n",
        "#     plt.ylabel(\"mean absolute errors\")\n",
        "#     # plt.ylim([0,0.1])\n",
        "#     plt.show()\n",
        "    \n",
        "#     return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqhPcZgKJArO",
        "outputId": "52bb5b79-b1ed-4a85-e88f-36c54ca0a66c"
      },
      "outputs": [],
      "source": [
        "# # mlp for multi-output regression\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# X = np.array(X)\n",
        "# Y = np.array(Y)\n",
        "# X_n = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "\n",
        "# results = evaluate_model(X, Y)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from tensorflow import keras\n",
        "# from keras import optimizers\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Dropout, GRU\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Xgru = np.array(X)\n",
        "# Ygru = np.array(Y)\n",
        "# X_n = Xgru.reshape((Xgru.shape[0], Xgru.shape[1], 1))\n",
        "# Xgru_train, Xgru_test, Ygru_train, Ygru_test = train_test_split(X_n, Y , test_size=0.2, random_state=6)\n",
        "# n_inputs = Xgru_train.shape[1:]\n",
        "# n_outputs = Ygru_train.shape[1]\n",
        "\n",
        "# reg_model = Sequential()\n",
        "# # Add a GRU layer with 120 units.\n",
        "# reg_model.add(GRU(120, activation = \"tanh\", recurrent_activation = \"sigmoid\", input_shape=n_inputs))\n",
        "\n",
        "# # Add a dropout layer (penalizing more complex models) -- prevents overfitting\n",
        "# reg_model.add(Dropout(rate=0.2))\n",
        "\n",
        "# # reg_model.add(GRU(120,activation='relu'))\n",
        "# #     # main_model.add(GRU(14,activation='relu')) \n",
        "# # reg_model.add(Dropout(0.2))\n",
        "\n",
        "# reg_model.add(Dense(48, activation='relu'))\n",
        "#     # main_model.add(Dense(5, activation='relu'))\n",
        "# reg_model.add(Dropout(0.2))\n",
        "\n",
        "# # Add a Dense layer with 1 units (Since we are doing a regression task.\n",
        "# reg_model.add(Dense(n_outputs))\n",
        "# # Evaluating loss function of MSE using the adam optimizer.\n",
        "# opt = optimizers.Adam(learning_rate=0.01, beta_1=0.8, beta_2=0.75, epsilon=1e-7, amsgrad=False, name='Adam')\n",
        "# reg_model.compile(loss='mean_squared_error', optimizer = opt)\n",
        "\n",
        "# # Print out architecture.\n",
        "# reg_model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# type(Xgru_test)\n",
        "# Xgru_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Fitting the data\n",
        "# history_a = reg_model.fit(Xgru_train,\n",
        "#                     Ygru_train,\n",
        "#                     shuffle = False, # Since this is time series data\n",
        "#                     epochs=3000,\n",
        "#                     batch_size=60,\n",
        "#                     validation_split=0.2,\n",
        "#                     verbose=1) # Verbose outputs data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Plotting the loss iteration\n",
        "# plt.plot(history.history['loss'], label = 'training loss')\n",
        "# plt.plot(history.history['val_loss'], label ='validation loss')\n",
        "# # plt.ylim([0,5000])\n",
        "# plt.legend()\n",
        "# # Note:\n",
        "# # if training loss >> validation loss -> Underfitting\n",
        "# # if training loss << validation loss -> Overfitting (i.e model is smart enough to have mapped the entire dataset..)\n",
        "# # Several ways to address overfitting:\n",
        "# # Reduce complexity of model (hidden layers, neurons, parameters input etc)\n",
        "# # Add dropout and tune rate\n",
        "# # More data :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Xgru_test_new = pd.DataFrame(Xgru_test[1:].reshape(-1))\n",
        "# Y_pred_general = reg_model.predict(Xgru_test_new.tail(260))\n",
        "\n",
        "# Ygru_predicted_reflux_ratio = pd.DataFrame(Y_pred_general.transpose()[0])\n",
        "# Ygru_predicted_daily_work = pd.DataFrame(Y_pred_general.transpose()[1])\n",
        "# Ygru_test_new = pd.DataFrame(Ygru_test).tail(260)\n",
        "# Ygru_test_reflux_ratio = pd.DataFrame(Ygru_test_new.values.transpose()[0])\n",
        "# Ygru_test_daily_work = pd.DataFrame(Ygru_test_new.values.transpose()[1])\n",
        "# pd.DataFrame({'real reflux ratio': Ygru_test_reflux_ratio.squeeze(),\n",
        "#               'predicted reflux ratio': Ygru_predicted_reflux_ratio.squeeze(),\n",
        "#               'real daily work time': Ygru_test_daily_work.squeeze(),\n",
        "#               'predicted daily work time' : Ygru_predicted_daily_work.squeeze()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_dense = np.array(X)\n",
        "Y_dense = np.array(Y)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_dense, Y_dense , test_size=0.2, random_state=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # python implementation of Grey wolf optimization (GWO)\n",
        "# # minimizing rastrigin and sphere function\n",
        "\n",
        "# import random\n",
        "# import math # cos() for Rastrigin\n",
        "# import copy # array-copying convenience\n",
        "# import sys\t # max float\n",
        "\n",
        "\n",
        "# #-------fitness functions---------\n",
        "\n",
        "# # rastrigin function\n",
        "# def fitness_rastrigin(position):\n",
        "#     fitness_value = 0.0\n",
        "#     for i in range(len(position)):\n",
        "#         xi = position[i]\n",
        "#         fitness_value += (xi * xi) - (10 * math.cos(2 * math.pi * xi)) + 10\n",
        "#     return fitness_value\n",
        "\n",
        "# #sphere function\n",
        "# def fitness_sphere(position):\n",
        "# \tfitness_value = 0.0\n",
        "# \tfor i in range(len(position)):\n",
        "# \t\txi = position[i]\n",
        "# \t\tfitness_value += (xi*xi);\n",
        "# \treturn fitness_value;\n",
        "# #-------------------------\n",
        "\n",
        "\n",
        "# # wolf class \n",
        "# class wolf:\n",
        "#     def __init__(self, fitness, dim, minx, maxx, seed):\n",
        "#         self.rnd = random.Random(seed)\n",
        "#         self.position = [0.0 for i in range(dim)]\n",
        "\n",
        "#         for i in range(dim):\n",
        "#             self.position[i] = ((maxx - minx) * self.rnd.random() + minx)\n",
        "\n",
        "#         self.fitness = fitness(self.position) # curr fitness\n",
        "\n",
        "\n",
        "\n",
        "# # grey wolf optimization (GWO)\n",
        "# def gwo(fitness, max_iter, n, dim, minx, maxx):\n",
        "# \trnd = random.Random(0)\n",
        "\n",
        "# \t# create n random wolves \n",
        "# \tpopulation = [ wolf(fitness, dim, minx, maxx, i) for i in range(n)]\n",
        "\n",
        "# \t# On the basis of fitness values of wolves \n",
        "# \t# sort the population in asc order\n",
        "# \tpopulation = sorted(population, key = lambda temp: temp.fitness)\n",
        "\n",
        "# \t# best 3 solutions will be called as \n",
        "# \t# alpha, beta and gaama\n",
        "# \talpha_wolf, beta_wolf, gamma_wolf = copy.copy(population[: 3])\n",
        "\n",
        "\n",
        "# \t# main loop of gwo\n",
        "# \tIter = 0\n",
        "# \twhile Iter < max_iter:\n",
        "\n",
        "# \t\t# after every 10 iterations \n",
        "# \t\t# print iteration number and best fitness value so far\n",
        "# \t\tif Iter % 10 == 0 and Iter > 1:\n",
        "# \t\t\tprint(\"Iter = \" + str(Iter) + \" best fitness = %.3f\" % alpha_wolf.fitness)\n",
        "\n",
        "# \t\t# linearly decreased from 2 to 0\n",
        "# \t\ta = 2*(1 - Iter/max_iter)\n",
        "\n",
        "# \t\t# updating each population member with the help of best three members \n",
        "# \t\tfor i in range(n):\n",
        "# \t\t\tA1, A2, A3 = a * (2 * rnd.random() - 1), a * (\n",
        "# \t\t\t2 * rnd.random() - 1), a * (2 * rnd.random() - 1)\n",
        "# \t\t\tC1, C2, C3 = 2 * rnd.random(), 2*rnd.random(), 2*rnd.random()\n",
        "\n",
        "# \t\t\tX1 = [0.0 for i in range(dim)]\n",
        "# \t\t\tX2 = [0.0 for i in range(dim)]\n",
        "# \t\t\tX3 = [0.0 for i in range(dim)]\n",
        "# \t\t\tXnew = [0.0 for i in range(dim)]\n",
        "# \t\t\tfor j in range(dim):\n",
        "# \t\t\t\tX1[j] = alpha_wolf.position[j] - A1 * abs(\n",
        "# \t\t\t\tC1 * alpha_wolf.position[j] - population[i].position[j])\n",
        "# \t\t\t\tX2[j] = beta_wolf.position[j] - A2 * abs(\n",
        "# \t\t\t\tC2 * beta_wolf.position[j] - population[i].position[j])\n",
        "# \t\t\t\tX3[j] = gamma_wolf.position[j] - A3 * abs(\n",
        "# \t\t\t\tC3 * gamma_wolf.position[j] - population[i].position[j])\n",
        "# \t\t\t\tXnew[j]+= X1[j] + X2[j] + X3[j]\n",
        "\t\t\t\n",
        "# \t\t\tfor j in range(dim):\n",
        "# \t\t\t\tXnew[j]/=3.0\n",
        "\t\t\t\n",
        "# \t\t\t# fitness calculation of new solution\n",
        "# \t\t\tfnew = fitness(Xnew)\n",
        "\n",
        "# \t\t\t# greedy selection\n",
        "# \t\t\tif fnew < population[i].fitness:\n",
        "# \t\t\t\tpopulation[i].position = Xnew\n",
        "# \t\t\t\tpopulation[i].fitness = fnew\n",
        "\t\t\t\t\n",
        "# \t\t# On the basis of fitness values of wolves \n",
        "# \t\t# sort the population in asc order\n",
        "# \t\tpopulation = sorted(population, key = lambda temp: temp.fitness)\n",
        "\n",
        "# \t\t# best 3 solutions will be called as \n",
        "# \t\t# alpha, beta and gaama\n",
        "# \t\talpha_wolf, beta_wolf, gamma_wolf = copy.copy(population[: 3])\n",
        "\t\t\n",
        "# \t\tIter+= 1\n",
        "# \t# end-while\n",
        "\n",
        "# \t# returning the best solution\n",
        "# \treturn alpha_wolf.position\n",
        "\t\t\n",
        "# #----------------------------\n",
        "\n",
        "\n",
        "# # Driver code for rastrigin function\n",
        "\n",
        "# print(\"\\nBegin grey wolf optimization on rastrigin function\\n\")\n",
        "# dim = 3\n",
        "# fitness = fitness_rastrigin\n",
        "\n",
        "\n",
        "# print(\"Goal is to minimize Rastrigin's function in \" + str(dim) + \" variables\")\n",
        "# print(\"Function has known min = 0.0 at (\", end=\"\")\n",
        "# for i in range(dim-1):\n",
        "#     print(\"0, \", end=\"\")\n",
        "# print(\"0)\")\n",
        "\n",
        "# num_particles = 50\n",
        "# max_iter = 100\n",
        "\n",
        "# print(\"Setting num_particles = \" + str(num_particles))\n",
        "# print(\"Setting max_iter = \" + str(max_iter))\n",
        "# print(\"\\nStarting GWO algorithm\\n\")\n",
        "\n",
        "\n",
        "\n",
        "# best_position = gwo(fitness, max_iter, num_particles, dim, -10.0, 10.0)\n",
        "\n",
        "# print(\"\\nGWO completed\\n\")\n",
        "# print(\"\\nBest solution found:\")\n",
        "# print([\"%.6f\"%best_position[k] for k in range(dim)])\n",
        "# err = fitness(best_position)\n",
        "# print(\"fitness of best solution = %.6f\" % err)\n",
        "\n",
        "# print(\"\\nEnd GWO for rastrigin\\n\")\n",
        "\n",
        "\n",
        "# print()\n",
        "# print()\n",
        "\n",
        "\n",
        "# # Driver code for Sphere function \n",
        "# print(\"\\nBegin grey wolf optimization on sphere function\\n\")\n",
        "# dim = 3\n",
        "# fitness = fitness_sphere\n",
        "\n",
        "\n",
        "# print(\"Goal is to minimize sphere function in \" + str(dim) + \" variables\")\n",
        "# print(\"Function has known min = 0.0 at (\", end=\"\")\n",
        "# for i in range(dim-1):\n",
        "#     print(\"0, \", end=\"\")\n",
        "# print(\"0)\")\n",
        "\n",
        "# num_particles = 50\n",
        "# max_iter = 100\n",
        "\n",
        "# print(\"Setting num_particles = \" + str(num_particles))\n",
        "# print(\"Setting max_iter = \" + str(max_iter))\n",
        "# print(\"\\nStarting GWO algorithm\\n\")\n",
        "\n",
        "\n",
        "\n",
        "# best_position = gwo(fitness, max_iter, num_particles, dim, -10.0, 10.0)\n",
        "\n",
        "# print(\"\\nGWO completed\\n\")\n",
        "# print(\"\\nBest solution found:\")\n",
        "# print([\"%.6f\"%best_position[k] for k in range(dim)])\n",
        "# err = fitness(best_position)\n",
        "# print(\"fitness of best solution = %.6f\" % err)\n",
        "\n",
        "# print(\"\\nEnd GWO for sphere\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_dense = np.array(X)\n",
        "Y_dense = np.array(Y)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_dense, Y_dense , test_size=0.2, random_state=6)\n",
        "n_inputs_sequ = X_train.shape[1]\n",
        "n_outputs_sequ = Y_train.shape[1]\n",
        "\n",
        "main_model = Sequential()\n",
        "main_model.add(Dense(108, input_dim=n_inputs_sequ, kernel_initializer='uniform', activation='relu'))\n",
        "main_model.add(Dense(84, kernel_initializer='uniform', activation='relu'))\n",
        "main_model.add(Dense(60, kernel_initializer='uniform', activation='relu'))\n",
        "main_model.add(Dense(48, kernel_initializer='uniform', activation='relu'))\n",
        "main_model.add(Dense(36, kernel_initializer='uniform', activation='relu'))\n",
        "main_model.add(Dense(18, kernel_initializer='uniform', activation='relu'))\n",
        "main_model.add(Dense(n_outputs_sequ))\n",
        "opt = optimizers.Adam(learning_rate=0.01, beta_1=0.8, beta_2=0.75, epsilon=1e-7, amsgrad=False, name='Adam')\n",
        "\n",
        "main_model.compile(loss='mae', optimizer='adam')\n",
        "main_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fitting the data\n",
        "history = main_model.fit(X_train,\n",
        "                    Y_train,\n",
        "                    #shuffle = False, # Since this is time series data\n",
        "                    epochs=650,\n",
        "                    batch_size=65,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1) # Verbose outputs data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plotting the loss iteration\n",
        "plt.plot(history.history['loss'], label = 'training loss')\n",
        "plt.plot(history.history['val_loss'], label ='validation loss')\n",
        "# plt.ylim([-2,6])\n",
        "plt.legend()\n",
        "# Note:\n",
        "# if training loss >> validation loss -> Underfitting\n",
        "# if training loss << validation loss -> Overfitting (i.e model is smart enough to have mapped the entire dataset..)\n",
        "# Several ways to address overfitting:\n",
        "# Reduce complexity of model (hidden layers, neurons, parameters input etc)\n",
        "# Add dropout and tune rate\n",
        "# More data :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predictions using the 'sliding/rolling window approach'\n",
        "# Multi step forecast.\n",
        "# Using self predictions for making future predictions\n",
        "X_test_newa = pd.DataFrame(X_test)\n",
        "Y_pred_general = main_model.predict(X_test_newa.tail(260))\n",
        "\n",
        "Y_predicted_reflux_ratio = pd.DataFrame(Y_pred_general.transpose()[0])\n",
        "Y_predicted_daily_work = pd.DataFrame(Y_pred_general.transpose()[1])\n",
        "Y_test_new = pd.DataFrame(Y_test).tail(260)\n",
        "Y_test_reflux_ratio = pd.DataFrame(Y_test_new.values.transpose()[0])\n",
        "Y_test_daily_work = pd.DataFrame(Y_test_new.values.transpose()[1])\n",
        "pd.DataFrame({'real reflux ratio': Y_test_reflux_ratio.squeeze(),\n",
        "              'predicted reflux ratio': Y_predicted_reflux_ratio.squeeze(),\n",
        "              'real daily work time': Y_test_daily_work.squeeze(),\n",
        "              'predicted daily work time' : Y_predicted_daily_work.squeeze()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_dense = np.array(X)\n",
        "Y_dense = np.array(Y)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_dense, Y_dense , test_size=0.2, random_state=6)\n",
        "n_inputs_sequ = X_train.shape[1]\n",
        "n_outputs_sequ = Y_train.shape[1]\n",
        "\n",
        "main_model_new = Sequential()\n",
        "main_model_new.add(Dense(108, input_dim=n_inputs_sequ, kernel_initializer='uniform', activation='relu'))\n",
        "main_model_new.add(Dense(84, kernel_initializer='uniform', activation='relu'))\n",
        "main_model_new.add(Dense(60, kernel_initializer='uniform', activation='relu'))\n",
        "main_model_new.add(Dense(48, kernel_initializer='uniform', activation='relu'))\n",
        "main_model_new.add(Dense(36, kernel_initializer='uniform', activation='relu'))\n",
        "main_model_new.add(Dense(18, kernel_initializer='uniform', activation='relu'))\n",
        "main_model_new.add(Dense(n_outputs_sequ))\n",
        "# opt = optimizers.Adam(learning_rate=0.01, beta_1=0.8, beta_2=0.75, epsilon=1e-7, amsgrad=False, name='Adam')\n",
        "\n",
        "# main_model.compile(loss='mae', optimizer='adam')\n",
        "main_model_new.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install PyYAML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##serialize model to YAML\n",
        "from keras.models import model_from_json, load_model\n",
        "\n",
        "model_json = main_model.to_json()\n",
        "with open(\"main_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "    \n",
        "##serialize weights to HDF5\n",
        "main_model.save_weights(\"main_model.h5\")\n",
        "print(\"Saved model to disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ]
        }
      ],
      "source": [
        "from keras.models import model_from_json, load_model\n",
        "\n",
        "##load YAMl and create model\n",
        "json_file = open('main_model.json', 'r')\n",
        "loaded_model_yaml = json_file.read()\n",
        "json_file.close()\n",
        "loaded_model = model_from_json(loaded_model_yaml)\n",
        "##load weights into new model\n",
        "loaded_model.load_weights(\"main_model.h5\")\n",
        "print(\"Loaded model from disk\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "## evaluate loaded model on test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_dense = np.array(X)\n",
        "Y_dense = np.array(Y)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_dense, Y_dense , test_size=0.2, random_state=6)\n",
        "loaded_model.compile(loss='mae',optimizer='rmsprop', metrics=['accuracy'])\n",
        "score = loaded_model.evaluate(X_test,Y_test, verbose=0)\n",
        "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##save model and architecture to single file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer Name: dense_79\n",
            "Weights: [[-0.10979091  0.29034242  0.00806625 ... -0.32547805  0.0280409\n",
            "  -0.00660197]\n",
            " [ 1.0808388   0.13176773 -0.0021444  ...  0.15447743  0.0152758\n",
            "  -0.09494355]\n",
            " [ 0.8782757   0.16494843 -0.02105323 ...  0.03860381  0.03287188\n",
            "  -0.10707491]\n",
            " ...\n",
            " [ 0.09349094  0.24843855  0.04670514 ...  0.09624357  0.0210353\n",
            "  -0.02199644]\n",
            " [ 0.07739411  0.23198132 -0.00799726 ...  0.05891927 -0.02680534\n",
            "  -0.0411574 ]\n",
            " [-0.12004768 -0.01308071 -0.00836325 ... -0.06243174 -0.03101786\n",
            "  -0.03825019]]\n",
            "Biases: [ 1.07711196e+00  9.30707008e-02  0.00000000e+00  1.87199199e+00\n",
            "  3.64961147e-01  1.57196522e-01  0.00000000e+00  0.00000000e+00\n",
            "  4.33511525e-01  1.96776509e-01  8.78424793e-02  1.78905800e-01\n",
            "  8.72397959e-01  1.44224942e-01  7.33502656e-02  0.00000000e+00\n",
            "  8.89890343e-02  7.68271238e-02  7.85629749e-02 -3.16129774e-01\n",
            "  0.00000000e+00  2.07492620e-01  9.97516289e-02  0.00000000e+00\n",
            " -4.21487239e-05 -1.07221123e-04  0.00000000e+00  1.18623488e-01\n",
            "  1.93086132e-01 -3.48209813e-02  1.20248258e-01  0.00000000e+00\n",
            " -1.64288946e-03  1.90731823e-01  1.13030389e-01  1.18684962e-01\n",
            "  9.84520689e-02  2.08609954e-01  9.13517922e-02  8.48129392e-02\n",
            "  1.20119438e-01  5.85830919e-02  1.83642998e-01  1.32076934e-01\n",
            " -7.59171396e-02  0.00000000e+00  2.66307533e-01  1.22154325e-01\n",
            "  1.16333045e-01  3.75245251e-02  0.00000000e+00 -2.97780484e-02\n",
            " -6.73168749e-02  0.00000000e+00  2.10236400e-01  1.98085442e-01\n",
            "  1.44801930e-01  4.52783734e-01 -1.55329774e-03  9.63337868e-02\n",
            " -1.07699737e-01 -3.89035158e-02  5.38530767e-01 -7.60160945e-03\n",
            "  1.69576779e-01  1.24411657e-01  0.00000000e+00  0.00000000e+00\n",
            "  0.00000000e+00  4.23777014e-01  1.45082012e-01  3.53181586e-02\n",
            "  0.00000000e+00  2.21579537e-01  1.48790166e-01 -1.33047150e-02\n",
            " -7.79711362e-03  9.06462148e-02  2.74035513e-01  1.49656177e-01\n",
            "  0.00000000e+00  0.00000000e+00  4.63260524e-02  6.99395239e-02\n",
            "  3.33468542e-02  0.00000000e+00  1.72209784e-01  1.40497997e-01\n",
            "  0.00000000e+00  0.00000000e+00 -1.28882574e-02  3.56195539e-01\n",
            "  0.00000000e+00  1.76884398e-01  1.35192230e-01 -3.93282762e-03\n",
            " -1.06126837e-01  2.32804403e-01 -5.74708171e-03  5.16012236e-02\n",
            "  2.40481690e-01  6.55407906e-02  9.00243521e-02  4.26700503e-01\n",
            "  1.02909759e-01  1.57882184e-01  0.00000000e+00 -1.30302668e-01]\n",
            "Layer Name: dense_80\n",
            "Weights: [[ 0.45865214 -0.06226337  0.2277702  ... -0.02454748  0.01101251\n",
            "  -0.03463593]\n",
            " [-0.23340856 -0.05649386 -0.06968815 ...  0.03403181  0.03009118\n",
            "   0.04242983]\n",
            " [ 0.01582578 -0.0331265  -0.01647462 ... -0.04997633  0.0353764\n",
            "   0.04481945]\n",
            " ...\n",
            " [-0.04167451  0.05435015 -0.05062414 ... -0.03198691 -0.07199591\n",
            "  -0.02620376]\n",
            " [-0.04226403  0.04215503 -0.03960004 ... -0.04665541  0.04108289\n",
            "  -0.0060956 ]\n",
            " [-0.02637687  0.00983461  0.05991124 ... -0.04781313 -0.01063107\n",
            "   0.03011163]]\n",
            "Biases: [ 1.5543838e-01  3.2599699e-01  1.1948558e-01  2.3648760e-01\n",
            " -4.6263285e-02 -3.4375217e-02 -3.0983355e-02 -9.5230544e-01\n",
            "  4.9265334e-01 -4.5799315e-02 -2.4586389e-02  1.9916119e-01\n",
            "  1.7913054e-01  4.4977486e-01  0.0000000e+00  2.4605930e-01\n",
            "  2.3394398e-01  2.3569249e-01 -5.5249918e-02  2.7836621e-01\n",
            " -3.0700445e-02  1.6256157e-01 -4.6215273e-02  1.8322299e-01\n",
            "  4.3335944e-01  1.2458491e-01 -2.8553918e-01  2.2625618e-01\n",
            " -9.8756840e-03 -4.7764771e-02 -4.0484324e-02  4.6370199e-01\n",
            " -2.0568807e-02  4.1896051e-01  1.4928442e-01 -6.2890584e-03\n",
            " -2.6006751e-02 -7.5260699e-01 -5.5257529e-03  1.8030712e-01\n",
            " -3.3976723e-02  4.1275719e-01 -9.8093897e-03 -1.4092294e-02\n",
            "  3.8036430e-01 -2.0853624e-02 -3.1867050e-02 -1.2386937e-02\n",
            "  4.1746619e-01 -3.8714703e-02 -2.7650390e-02  2.0742056e-01\n",
            "  1.4305747e-01 -5.8618272e-03 -2.9520100e-02  1.8046527e-01\n",
            " -3.4006193e-02  2.1364044e-01  2.5738019e-01 -4.5893289e-02\n",
            "  2.1547480e-01  2.3809282e-01 -3.2025620e-02 -2.9377382e-02\n",
            " -2.2966677e-02 -5.9910595e-02 -3.0245284e-02  1.7355953e-01\n",
            " -2.1270823e-02 -3.8886726e-02  6.0617572e-01 -2.9574385e-02\n",
            "  2.0254567e-01  4.5439786e-01 -4.5857444e-02  2.2439943e-01\n",
            " -1.6201951e-02 -2.3060910e-02  1.5752470e+00 -8.7882914e-03\n",
            " -6.8553150e-02 -1.4113346e-03 -3.1384584e-02 -5.7919980e-03]\n",
            "Layer Name: dense_81\n",
            "Weights: [[ 0.21073465  0.15038563 -0.00364035 ... -0.08424804  0.00513189\n",
            "  -0.01768073]\n",
            " [-0.01864051  0.04464529 -0.01957469 ... -0.03305919  0.0173496\n",
            "  -0.02164278]\n",
            " [-0.15884423 -0.1835265  -0.17803362 ... -0.05764721 -0.01834915\n",
            "  -0.20427181]\n",
            " ...\n",
            " [ 0.00229378  0.00552067 -0.02473308 ...  0.00867059 -0.004705\n",
            "  -0.03817075]\n",
            " [-0.01950083 -0.00197546  0.01640373 ... -0.02623411  0.01813528\n",
            "  -0.04442758]\n",
            " [ 0.03034927 -0.02538881  0.01740651 ... -0.02890672 -0.00986382\n",
            "  -0.00864053]]\n",
            "Biases: [ 0.26412496  0.92261404  0.4170231  -0.02944172  0.21126303  0.40980068\n",
            "  0.5129364   0.23588112  0.         -0.00394369  0.14473096  0.55586904\n",
            " -0.02849287 -0.03165283  0.          0.3249365   0.8217583  -0.02934522\n",
            " -0.00617058  0.30429262  0.5074597  -0.04444283  0.27682444  0.08263832\n",
            "  0.33355865  0.30019477 -0.03125756 -0.03011546  1.048641    0.59113795\n",
            "  0.         -0.02674794  0.45332715  0.10108633 -0.00745668  0.\n",
            " -0.03078607  0.32101604 -0.02874899 -0.01036874 -0.018814    0.26642963\n",
            " -0.0069027  -0.03710176 -0.03446284 -0.03249512 -0.02284066  0.23749453\n",
            " -0.01317095 -0.0078821   0.25969547 -0.0075038   0.7248539  -0.03460784\n",
            " -0.0020359   0.21392947 -0.02780543 -0.03234127  0.          0.21446526]\n",
            "Layer Name: dense_82\n",
            "Weights: [[ 0.00232887  0.00848588 -0.04571378 ... -0.15898173 -0.00866507\n",
            "   0.00306016]\n",
            " [-0.09575075  0.11756612  0.00279881 ... -0.06637667 -0.0682647\n",
            "  -0.04203733]\n",
            " [-0.00467552  0.00882754 -0.00797313 ... -0.00256454 -0.04549698\n",
            "   0.02407457]\n",
            " ...\n",
            " [-0.00850618 -0.02454681  0.02339581 ...  0.02620087 -0.0394273\n",
            "  -0.01605078]\n",
            " [-0.01114513 -0.04047892 -0.0009087  ... -0.02953185  0.00812443\n",
            "   0.04785582]\n",
            " [ 0.15726574 -0.07865145  0.04241153 ... -0.04175594 -0.07617249\n",
            "   0.03917332]]\n",
            "Biases: [-4.6553826e+00  1.0379678e+00  0.0000000e+00  3.3945435e-01\n",
            " -7.1909875e-03  0.0000000e+00  0.0000000e+00  1.9199060e-01\n",
            " -2.6943667e-02  0.0000000e+00  5.4626238e-01  4.2635444e-01\n",
            "  0.0000000e+00 -5.8691287e-03 -4.0402763e-02  6.0467201e-01\n",
            "  0.0000000e+00  3.6200494e-01  1.1478078e+00 -6.8818848e-03\n",
            "  7.0281756e-01 -3.2623466e-02  1.1018398e+00  7.0918822e-01\n",
            " -3.5349794e-02 -3.1886030e-02 -1.9356793e-02  1.8553944e-01\n",
            "  4.4475767e-01 -5.0858995e-03  1.1005694e+00  6.1428934e-01\n",
            " -1.2056854e-02  1.9993319e-01 -3.0490108e-02  3.8826177e-01\n",
            "  1.1238070e+00 -2.8979215e-03  4.0937093e-04  1.0989063e+00\n",
            " -3.9695784e-02  4.2894053e-01 -1.4603289e-02 -1.1888163e-02\n",
            " -2.8312586e-02  5.5742437e-01 -1.4788527e-02  0.0000000e+00]\n",
            "Layer Name: dense_83\n",
            "Weights: [[-0.05056361 -0.2920301  -0.16639318 ...  0.00733337 -0.8662435\n",
            "  -0.07973894]\n",
            " [ 0.01344973 -0.03700716 -0.02053514 ... -0.02707575 -0.01306638\n",
            "  -0.04421979]\n",
            " [-0.01642818  0.00844805 -0.04285777 ...  0.03937975 -0.02355797\n",
            "  -0.0068333 ]\n",
            " ...\n",
            " [-0.00247641 -0.00196322 -0.01273025 ... -0.04594301  0.00476616\n",
            "  -0.05128816]\n",
            " [-0.00930711  0.04407867  0.0576885  ... -0.02170148  0.0762035\n",
            "  -0.00156365]\n",
            " [ 0.0158562   0.04005971  0.04686073 ... -0.00095751  0.02183331\n",
            "   0.02736899]]\n",
            "Biases: [-0.00609481  1.2169678   1.0089468  -0.00611853  0.20634095  0.48043042\n",
            " -0.00555504 -0.00554339  0.5866997   0.19675325 -0.00600492 -0.03614848\n",
            "  0.         -0.02835857 -0.02928036  0.          0.24629429  0.16566311\n",
            "  1.3800071  -0.00745978  1.2903186  -0.03684498  0.26515934 -0.01121637\n",
            "  0.          0.          0.9430951   0.2619724   0.6803336  -0.00859722\n",
            " -0.04298327  0.44916052  1.1919432  -0.02463489  1.7892584   1.0327735 ]\n",
            "Layer Name: dense_84\n",
            "Weights: [[-1.98616870e-02 -2.29631737e-03 -3.23314741e-02 -3.32914665e-03\n",
            "   2.09703706e-02  1.70845911e-03  4.59792465e-02 -2.85659935e-02\n",
            "  -6.62350655e-03 -3.73454243e-02 -6.93058642e-03 -5.13583561e-03\n",
            "   1.04592703e-02 -1.72022637e-02  2.47528460e-02  3.07152905e-02\n",
            "  -2.31644325e-02  4.76847552e-02]\n",
            " [-3.25870067e-02 -6.85774758e-02 -5.27443066e-02  1.70122385e-02\n",
            "   2.05690339e-02  1.12180077e-02  1.16386805e-02 -3.06269489e-02\n",
            "  -1.73568521e-02  2.30945423e-02 -9.08805206e-02  1.59462690e-02\n",
            "   1.80626642e-02 -1.38806239e-01 -2.38863956e-02  1.31063946e-02\n",
            "   2.06366666e-02 -5.88375144e-02]\n",
            " [ 4.12443914e-02 -3.71166244e-02 -6.03120215e-02 -2.38818210e-02\n",
            "  -7.51324557e-03 -1.33300424e-02 -1.15681672e-02  3.40255955e-03\n",
            "  -6.67508692e-02 -5.10804467e-02 -6.34375960e-02  4.27669510e-02\n",
            "  -4.48656967e-03 -1.10556073e-01  3.82885076e-02 -2.06678156e-02\n",
            "   4.84413691e-02 -8.49881023e-03]\n",
            " [ 1.25649832e-02  3.64109315e-02  4.79566380e-02 -2.10189223e-02\n",
            "   1.18034361e-02 -4.36991341e-02 -1.97824333e-02  2.78785396e-02\n",
            "   2.49778368e-02 -2.17422526e-02 -1.79809018e-03  3.35217640e-02\n",
            "   3.87538038e-02 -4.21190858e-02  3.04254889e-02 -3.43545079e-02\n",
            "   3.45912091e-02 -4.02338505e-02]\n",
            " [ 4.28543128e-02  1.61429755e-02 -3.23293433e-02 -2.61123534e-02\n",
            "  -9.29347426e-03 -4.62470315e-02  3.78451906e-02 -3.66250388e-02\n",
            "   1.72563232e-02 -2.25768890e-02 -6.79731369e-04  4.37049307e-02\n",
            "  -4.79210168e-04 -9.38798673e-03 -4.81539853e-02  2.30373479e-02\n",
            "  -3.24874697e-03  3.44978832e-02]\n",
            " [ 9.04079527e-03 -1.27017982e-02 -3.99200059e-03 -3.76961567e-02\n",
            "  -3.98193151e-02 -1.71780214e-02 -1.79988816e-02 -6.16717990e-03\n",
            "  -9.17109312e-04  4.83184643e-02 -5.02040721e-02 -1.42821763e-02\n",
            "  -4.10078503e-02  8.01695790e-03  3.36572248e-03  7.51696527e-04\n",
            "  -4.56371903e-03  1.68693997e-02]\n",
            " [-2.10503694e-02 -3.59645002e-02 -4.21253256e-02 -2.87523996e-02\n",
            "   2.78924294e-02  8.84905457e-05 -4.40209433e-02 -4.33099596e-03\n",
            "   3.45575325e-02 -6.61736540e-03  2.97664683e-02 -3.78856547e-02\n",
            "   1.35252513e-02 -3.62503864e-02 -1.32925399e-02 -2.70226132e-02\n",
            "   2.22821198e-02 -2.88448334e-02]\n",
            " [ 3.49939205e-02 -4.18377630e-02 -1.21518476e-02  4.30339836e-02\n",
            "  -5.25878975e-03  3.77617814e-02 -4.09341715e-02 -3.49776223e-02\n",
            "   3.22564580e-02 -1.29025038e-02 -2.45872736e-02 -3.37091833e-02\n",
            "  -1.79349780e-02  3.73047628e-02  2.60315649e-02  3.20037045e-02\n",
            "  -3.41988914e-02 -3.90670449e-03]\n",
            " [ 1.71567090e-02 -3.92716900e-02  1.70711167e-02 -2.90199742e-02\n",
            "  -6.13969155e-02  2.58951671e-02  5.56858350e-03  6.83451816e-03\n",
            "   2.34578364e-02 -4.41956287e-03 -3.78887877e-02 -2.78647244e-02\n",
            "  -1.64295677e-02  2.58565582e-02 -3.81284244e-02  5.60505316e-03\n",
            "   6.15535043e-02  4.21341397e-02]\n",
            " [-3.51163372e-02  3.83146144e-02  1.31829118e-03 -6.02237843e-02\n",
            "   2.20510494e-02 -4.99786027e-02  3.14720795e-02  1.94778293e-02\n",
            "  -1.37098031e-02 -3.12810615e-02 -2.77913529e-02  3.82097461e-03\n",
            "  -2.87986305e-02  5.65334223e-03  3.96126248e-02 -1.08816400e-02\n",
            "   2.65133213e-02 -3.68627682e-02]\n",
            " [-2.35333331e-02 -3.66754755e-02 -2.73568258e-02  3.46245877e-02\n",
            "   3.13254111e-02  4.95813228e-02  1.84765570e-02  3.06022894e-02\n",
            "   5.14789972e-05 -2.43521854e-02 -2.61168610e-02  4.22644317e-02\n",
            "   3.82289812e-02  4.19235528e-02  2.77501792e-02 -4.72249649e-02\n",
            "   1.11918254e-02 -1.68787949e-02]\n",
            " [ 9.93592665e-03 -3.22680622e-02 -2.76124589e-02 -1.59906633e-02\n",
            "  -3.12204026e-02 -4.07249108e-02 -2.47752797e-02 -2.20253374e-02\n",
            "  -2.10285955e-03  1.25938533e-02 -3.39392573e-02  2.45509967e-02\n",
            "  -9.73558985e-03 -6.25906959e-02  9.87901818e-03 -1.07210167e-02\n",
            "  -1.95392445e-02 -2.52250191e-02]\n",
            " [-1.74157508e-02 -5.39616495e-03  4.04914059e-02  3.94441746e-02\n",
            "  -2.73435954e-02  1.89531706e-02  4.81375344e-02 -2.00073794e-03\n",
            "   2.84552686e-02  3.84513028e-02  2.62260325e-02  3.39795686e-02\n",
            "  -1.45449638e-02 -3.29892412e-02  4.68095876e-02  3.52477692e-02\n",
            "  -4.83597293e-02 -1.71922557e-02]\n",
            " [ 2.12281942e-03  4.22034524e-02 -1.44105190e-02  7.85446167e-03\n",
            "  -1.36384256e-02 -7.64131546e-03  1.40897022e-03 -9.56996810e-05\n",
            "  -1.91557407e-02  7.74669647e-03 -1.09993927e-02 -9.77040455e-03\n",
            "   3.96325253e-02  1.17866509e-02  3.66841443e-02  3.43479961e-03\n",
            "   5.23605458e-02  2.62876861e-02]\n",
            " [ 3.72020863e-02  2.05997117e-02 -1.41944289e-02  8.94177705e-04\n",
            "   2.28003971e-02  2.66023763e-02 -2.48583816e-02  1.35964304e-02\n",
            "   4.99012582e-02  4.95214202e-02  1.14827976e-02  4.62401547e-02\n",
            "  -1.38537176e-02 -2.64091082e-02 -3.16536576e-02  3.81448604e-02\n",
            "  -5.42815179e-02 -4.85868827e-02]\n",
            " [ 2.32095644e-03  1.44323371e-02 -9.91160795e-03 -4.06852961e-02\n",
            "  -1.22035742e-02  1.17008798e-02  1.44520067e-02  4.43970673e-02\n",
            "   4.16046120e-02  4.68982495e-02 -4.76601832e-02  2.30551697e-02\n",
            "  -7.96203688e-03 -1.26801841e-02  3.89914252e-02  3.73755731e-02\n",
            "  -4.34114337e-02  9.03153419e-03]\n",
            " [-2.24927813e-03  5.21295145e-03 -2.56452803e-02  8.60053580e-03\n",
            "   2.17310991e-02 -6.84776902e-02 -3.36118564e-02 -2.65685227e-02\n",
            "  -6.14406578e-02  5.32849459e-03  1.83718745e-02  2.31345147e-02\n",
            "   2.79731713e-02 -7.00124167e-03 -5.29064126e-02 -9.39452648e-03\n",
            "  -3.97934318e-02  2.62404941e-02]\n",
            " [ 1.45240165e-02 -4.39134613e-02 -3.45197879e-02 -2.31636502e-02\n",
            "  -3.57936732e-02  2.00940482e-02  5.68598658e-02  1.58858784e-02\n",
            "  -7.83094729e-04  1.41448071e-02 -1.33740138e-02 -2.99849268e-03\n",
            "   2.17874851e-02  1.81060806e-02 -3.03620044e-02  1.66561119e-02\n",
            "  -2.48189848e-02  3.73429060e-03]\n",
            " [-4.44156304e-02 -2.20304518e-03  1.49917584e-02  1.72393955e-02\n",
            "  -2.44352147e-02 -5.25265299e-02  2.02437058e-01  2.09333166e-01\n",
            "  -4.11669578e-04 -1.24641717e-03  6.22514449e-03  3.15280771e-03\n",
            "  -3.16239558e-02  3.15625593e-02 -4.85639013e-02 -4.66453806e-02\n",
            "   2.58936942e-01 -3.30632441e-02]\n",
            " [ 2.97202207e-02 -3.59911323e-02  3.19956765e-02 -2.40987670e-02\n",
            "   3.63386609e-02 -1.39552467e-02  4.40639481e-02 -2.49349568e-02\n",
            "   3.48925479e-02 -1.29750678e-02  1.61072873e-02 -1.86713189e-02\n",
            "  -2.35483479e-02 -1.93207711e-02 -2.50366796e-03 -3.67021561e-03\n",
            "   1.98224187e-02 -4.92081307e-02]\n",
            " [ 7.80018419e-03 -5.26410043e-02 -7.32462853e-02 -3.53850871e-02\n",
            "  -3.72654572e-02 -2.45119701e-03  1.25727922e-01  1.55066594e-01\n",
            "  -2.09076479e-02 -5.06767668e-02 -3.98804843e-02 -4.25810255e-02\n",
            "  -2.92418711e-02 -7.73777664e-02 -2.78954152e-02 -1.25317946e-02\n",
            "   1.96923569e-01 -3.82249616e-02]\n",
            " [ 3.25185172e-02 -1.93129908e-02  9.54407174e-03  3.64076532e-02\n",
            "  -4.22730781e-02 -1.86264887e-02  6.69894135e-03 -3.98921743e-02\n",
            "   3.93608361e-02  4.50661145e-02 -5.27502783e-02  1.39919203e-02\n",
            "  -5.58690280e-02  4.96199541e-02 -3.60934772e-02 -1.72050819e-02\n",
            "  -3.70963104e-02  1.38188936e-02]\n",
            " [-2.07302719e-03  3.73249166e-02 -3.70297395e-02 -2.30236501e-02\n",
            "  -4.46135998e-02 -2.73456294e-02 -8.40369053e-03 -1.47663383e-02\n",
            "  -3.04984078e-02 -4.48738821e-02  1.79970935e-02  1.80171095e-02\n",
            "  -5.55283315e-02 -4.47899774e-02  2.19634883e-02 -8.76920298e-03\n",
            "  -4.50845733e-02 -2.32879054e-02]\n",
            " [-4.71810810e-02 -3.58705148e-02 -2.31328811e-02 -2.67913826e-02\n",
            "   2.90886816e-02 -4.63199876e-02 -3.66527066e-02 -2.74330229e-02\n",
            "  -5.46221100e-02  2.76495796e-02  7.46044237e-03  1.22401416e-02\n",
            "  -3.44331078e-02  3.95958452e-03 -2.13603396e-02 -5.62102720e-03\n",
            "  -3.84798236e-02 -3.61682884e-02]\n",
            " [-2.72605568e-03 -1.72257535e-02  3.17823328e-02  1.16392486e-02\n",
            "  -2.15014573e-02  9.97356325e-03 -6.82372972e-03  7.96116889e-04\n",
            "  -1.23759359e-03  2.84934752e-02  5.98268583e-03 -4.52058390e-03\n",
            "   4.09486145e-03 -4.43679355e-02  4.42262404e-02  3.47526409e-02\n",
            "  -2.31555700e-02 -3.27280760e-02]\n",
            " [-3.99134271e-02  3.89617197e-02  1.08072162e-02  3.55617292e-02\n",
            "  -4.67241183e-02 -2.66180281e-02 -4.71907258e-02  3.20018791e-02\n",
            "  -2.98517942e-03  1.03853121e-02  8.07801634e-03 -1.50067210e-02\n",
            "   4.82147075e-02  2.12960951e-02 -4.16033268e-02  4.82689776e-02\n",
            "   1.24128684e-02 -2.92614102e-02]\n",
            " [ 3.60519029e-02 -9.62903351e-03 -6.23164922e-02 -3.64176221e-02\n",
            "   2.77674925e-02 -5.14365211e-02  2.92122029e-02  1.38021717e-02\n",
            "  -6.83180839e-02 -2.88826525e-02 -9.42751486e-03 -4.74635065e-02\n",
            "  -4.97426875e-02 -8.13546404e-02 -4.04059403e-02  3.48809250e-02\n",
            "   2.65143253e-02  7.88719580e-03]\n",
            " [ 3.30365635e-02 -2.16769576e-02 -5.60829043e-02 -4.35313657e-02\n",
            "  -3.00507955e-02 -5.08001931e-02 -2.27611773e-02 -2.88069323e-02\n",
            "   2.01041028e-02 -2.23527360e-03 -4.33705337e-02 -5.47090657e-02\n",
            "  -3.07032894e-02 -4.45846468e-03 -5.36942855e-02 -2.00382601e-02\n",
            "   3.82946581e-02 -3.75849009e-02]\n",
            " [-2.91738752e-02  2.07790770e-02 -3.74138355e-02 -4.96659353e-02\n",
            "   3.96275241e-03 -4.36351672e-02  5.00066113e-03 -1.44584710e-02\n",
            "   1.77810178e-03 -8.27286616e-02 -2.88565148e-04 -2.18548793e-02\n",
            "   3.67859291e-04 -1.82786267e-02 -8.42808373e-03  4.03201319e-02\n",
            "   4.00217809e-02 -1.36063322e-02]\n",
            " [-2.23002434e-02 -7.91024417e-04  2.91570518e-02  1.59304477e-02\n",
            "  -3.98359867e-03  3.99423279e-02 -2.37233769e-02 -3.95592786e-02\n",
            "  -1.65627133e-02  4.12779488e-02  3.67722549e-02  3.55638191e-03\n",
            "   6.00514561e-03  2.29662377e-02 -1.90650709e-02  2.90809609e-02\n",
            "  -2.23737489e-02  4.30089943e-02]\n",
            " [-3.42508554e-02 -3.78422253e-02  6.70679137e-02 -1.33617036e-02\n",
            "  -5.43108061e-02 -3.23065296e-02 -9.19628330e-03  1.91916451e-02\n",
            "  -5.71945384e-02  3.71458493e-02  2.60637980e-02 -6.44307211e-03\n",
            "   4.86584343e-02 -9.30811919e-04  3.25783007e-02  3.81562598e-02\n",
            "   2.71972120e-02  2.92807259e-02]\n",
            " [-4.59744930e-02 -1.90635081e-02  2.27442048e-02 -5.80766425e-02\n",
            "  -2.05042120e-02 -4.00964133e-02 -4.90156002e-03  2.52147224e-02\n",
            "   1.54024428e-02 -1.94452133e-03  1.74210349e-03  2.30399352e-02\n",
            "  -4.30109985e-02 -4.83372360e-02 -4.80735302e-03  5.73371723e-03\n",
            "   2.83839850e-04  4.29371707e-02]\n",
            " [-2.21282244e-02 -3.68137881e-02 -7.88960382e-02 -6.51770234e-02\n",
            "   9.57995933e-03 -5.87274954e-02  4.36928272e-02  2.95312181e-02\n",
            "  -1.74937714e-02 -3.76994610e-02 -2.45521758e-02 -4.09982130e-02\n",
            "   3.06670126e-02 -1.25230342e-01 -4.19646688e-02 -1.82471871e-02\n",
            "   8.85346010e-02 -5.23921922e-02]\n",
            " [-3.54764685e-02  4.19731475e-02 -1.39341606e-02  4.72980849e-02\n",
            "   3.77207138e-02 -3.83342020e-02 -6.26538531e-05  3.29962447e-02\n",
            "  -3.34355831e-02  6.29986450e-02 -4.68586683e-02 -1.81608591e-02\n",
            "  -2.07810979e-02  4.94711921e-02 -2.09472012e-02 -1.47135854e-02\n",
            "  -1.13652227e-02  1.42879523e-02]\n",
            " [-2.85509713e-02 -1.30266771e-02  2.60621998e-02 -4.84464578e-02\n",
            "  -6.88103214e-02 -3.29208411e-02  1.67183250e-01 -1.39319792e-01\n",
            "  -1.90147571e-02 -7.48872990e-03 -5.98531915e-03 -3.79821248e-02\n",
            "   3.44712399e-02 -1.84085935e-01  2.28350293e-02  6.58436865e-03\n",
            "   3.54260504e-02 -5.61673008e-02]\n",
            " [-3.55393179e-02 -5.25097288e-02 -9.94597971e-02 -7.07805753e-02\n",
            "   2.12276224e-02 -6.45595836e-03 -1.58193465e-02  7.57154357e-03\n",
            "  -9.12648290e-02 -2.75023133e-02 -3.73082608e-02 -4.65528779e-02\n",
            "   1.16204116e-02 -1.37553632e-01  2.14778706e-02 -4.70840596e-02\n",
            "   5.00024036e-02 -3.59599814e-02]]\n",
            "Biases: [ 0.         -0.03174653  1.5807184  -0.03060508 -0.02291248 -0.0286526\n",
            "  2.1291072   0.6590742  -0.04463447  1.2078129  -0.03996422 -0.00600545\n",
            " -0.00600546  0.706314   -0.0060046   0.          1.701047   -0.03927023]\n",
            "Layer Name: dense_85\n",
            "Weights: [[-0.47662592  0.21920568]\n",
            " [ 0.3670346  -0.26978835]\n",
            " [ 0.03351852 -0.01742757]\n",
            " [ 0.15827869 -0.4579936 ]\n",
            " [ 0.21493244 -0.3618732 ]\n",
            " [-0.47296238  0.4506969 ]\n",
            " [-0.06860949  0.32503477]\n",
            " [ 0.12456566  0.33052266]\n",
            " [-0.10562371 -0.3827956 ]\n",
            " [-0.01970658 -0.00782068]\n",
            " [-0.4892991  -0.35649982]\n",
            " [-0.3262552  -0.3781115 ]\n",
            " [-0.5362198  -0.3298511 ]\n",
            " [ 0.04193021  0.00761383]\n",
            " [-0.22045471  0.1836945 ]\n",
            " [ 0.16489184 -0.10382977]\n",
            " [-0.00798559  0.3910643 ]\n",
            " [ 0.4117896  -0.12946717]]\n",
            "Biases: [-1.4765517  1.8303205]\n"
          ]
        }
      ],
      "source": [
        "mylayers = loaded_model.layers\n",
        "for layer in mylayers:\n",
        "    if hasattr(layer, 'get_weights'):\n",
        "        weights, biases = layer.get_weights()\n",
        "        print('Layer Name:', layer.name)\n",
        "        print('Weights:', weights)\n",
        "        print('Biases:', biases)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# regressor_main.fit(X,Y)\n",
        "\n",
        "#1\t466.7\t0.99\t1.098692327\t\t0.99899\t121.6209234\t118.0392264\t1.444240492\t4.332721476\t0.99899\t467.1718436\t84.21099119\t81.73100468\t99.899\t322.8192504\n",
        "# 2   155.804\n",
        "\n",
        "inputs = (1, 0.99899, 121.6209234, 118.0392264, 1.444240492, 4.332721476,322.8192504 , 1.098692327, 0.99899, 467.1718436, 84.21099119, 81.73100468, 466.7)\n",
        "input_data_as_numpy_array = np.asarray(inputs)\n",
        "input_data_reshaped = input_data_as_numpy_array.reshape(1, -1)\n",
        "main_model.predict(input_data_reshaped)\n",
        "# print(results)\n",
        "#'atmosphere_pressure', 'reboiler(pot)_heat_duty(Watt)', 'produced_acetic_acid_mass_fraction', 'new_reboiler(pot)_temperature(C)', 'upper_product_flow_rate(kg/hr)', 'pot_pressure(atm)', 'condenser_mass_flow_outlet_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##condensor_pressure(atm)\tproduced_acetic_acid_mass_fraction\tnew_reboiler(pot)_temperature(C)\tcondensor_temperature(C)\tupper_product_flow_rate(kg/hr)\tcondensor_mass_flow_outlet_rate\taceticindutyoverflow\t\n",
        "# pot_pressure(atm)\tfraction_over_pressure\tduty_over_frac_multiplyed_by_pressure\treboiler_temp_on_flowrate\tcondensor_temp_on_flowrate\treboiler(pot)_heat_duty(Watt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# regressor_main.fit(X,Y)\n",
        "\n",
        "## 2\t2.098692327\t466.7\t0.99\t3.972966667\t165.749064\t163.0687495\t0.499823\t233.4326352\t99.9646\t535.1616894\t\t0.999646\t144.4940959\t0.871764174\t3.030305306\t142.1574937\t1.000000751\t4.358820871\n",
        "## 4  238.378\n",
        "\n",
        "inputs = (2, 0.999646, 144.4940959, 142.1574937, 0.871764174, 4.358820871 ,535.1616894 , 2.098692327, 0.499823, 233.4326352, 165.749064, 163.0687495, 466.7)\n",
        "input_data_as_numpy_array = np.asarray(inputs)\n",
        "input_data_reshaped = input_data_as_numpy_array.reshape(1, -1)\n",
        "main_model.predict(input_data_reshaped)\n",
        "# print(results)\n",
        "#'atmosphere_pressure', 'reboiler(pot)_heat_duty(Watt)', 'produced_acetic_acid_mass_fraction', 'new_reboiler(pot)_temperature(C)', 'upper_product_flow_rate(kg/hr)', 'pot_pressure(atm)', 'condenser_mass_flow_outlet_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_1 = pd.read_csv('Data_for_project_kam.csv')\n",
        "X_first_reg = df_1[['produced_acetic_acid_mass_fraction', 'reboiler(pot)_heat_duty(Watt)', 'daily_work(min)',\n",
        "                    'daily_work_multip_duty', 'daily_work_multip_fraction_over_duty', 'condensor_pressure(atm)' ]]\n",
        "Y_first_reg = df_1[['upper_product_flow_rate(kg/hr)']]\n",
        "# Y_first_reg = df_1[['upper_product_flow_rate(kg/hr)']]\n",
        "\n",
        "X_py = np.array(X_first_reg)\n",
        "Y_py = np.array(Y_first_reg)\n",
        "X_n = X_py.reshape((X_py.shape[0], X_py.shape[1], 1))\n",
        "\n",
        "X_train_first_reg, X_test_first_reg, Y_train_first_reg, Y_test_first_reg = train_test_split(X_py, Y_py , test_size=0.2, random_state=6)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,GRU,Dropout,LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train_first_reg, X_test_first_reg, Y_train_first_reg, Y_test_first_reg = train_test_split(X_py, Y_py , test_size=0.2, random_state=6)\n",
        "n_inputs_first_reg = X_train_first_reg.shape[1]\n",
        "n_outputs_first_reg = Y_train_first_reg.shape[1]\n",
        "\n",
        "first_reg_model = Sequential()\n",
        "\n",
        "\n",
        "first_reg_model.add(LSTM(24, recurrent_dropout=0.2, activation='relu', input_shape=(n_inputs_first_reg,1), return_sequences=True))\n",
        "# first_reg_model.add(LSTM(13, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "# first_reg_model.add(LSTM(14, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "first_reg_model.add(LSTM(30, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "first_reg_model.add(LSTM(40, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "first_reg_model.add(LSTM(10, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "first_reg_model.add(LSTM(25, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "first_reg_model.add(LSTM(10, recurrent_dropout=0.2, activation='relu'))\n",
        "# first_reg_model.add(Dense(117, activation='relu'))\n",
        "\n",
        "\n",
        "# first_reg_model.add(Dense(120, input_dim=n_inputs_first_reg, kernel_initializer='uniform', activation='relu'))\n",
        "# first_reg_model.add(Dense(96, kernel_initializer='uniform', activation='relu'))\n",
        "# first_reg_model.add(Dense(96, kernel_initializer='uniform', activation='relu'))\n",
        "# first_reg_model.add(Dense(96, kernel_initializer='uniform', activation='relu'))\n",
        "# first_reg_model.add(Dense(96, kernel_initializer='uniform', activation='relu'))\n",
        "# first_reg_model.add(Dense(96, kernel_initializer='uniform', activation='relu'))\n",
        "# first_reg_model.add(Dense(48, kernel_initializer='uniform', activation='relu'))\n",
        "\n",
        "# first_reg_model.add(GRU(120, recurrent_dropout=0.2, activation='relu', input_shape=(n_inputs_first_reg,1), return_sequences=True))\n",
        "#     # model.add(GRU(n2, recurrent_dropout=0.2, activation='relu'))\n",
        "# first_reg_model.add(Dense(43, activation='relu'))\n",
        "# first_reg_model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "# first_reg_model.add(Dense(65, kernel_initializer='uniform', activation='relu'))\n",
        "# first_reg_model.add(Dense(52, kernel_initializer='uniform', activation='relu'))\n",
        "# first_reg_model.add(Dense(39, kernel_initializer='uniform', activation='relu'))\n",
        "# first_reg_model.add(Dense(26, kernel_initializer='uniform', activation='relu'))\n",
        "first_reg_model.add(Dense(n_outputs_first_reg, activation='linear'))\n",
        "opt = optimizers.Adam(learning_rate=0.001)#, beta_1=0.8, beta_2=0.75, epsilon=1e-7, amsgrad=False, name='Adam')\n",
        "\n",
        "first_reg_model.compile(loss='mae', optimizer='adam')\n",
        "first_reg_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import pygad\n",
        "# import torch.nn as nn\n",
        "# from pygad import torchga\n",
        "\n",
        "\n",
        "# def fitness_func(solution, sol_idx):\n",
        "#     global data_inputs, data_outputs, torch_ga, model, loss_function\n",
        "\n",
        "#     model_weights_dict = torchga.model_weights_as_dict(model=model,\n",
        "#                                                        weights_vector=solution)\n",
        "\n",
        "#     # Use the current solution as the model parameters.\n",
        "#     model.load_state_dict(model_weights_dict)\n",
        "\n",
        "#     predictions = model(data_inputs)\n",
        "#     abs_error = loss_function(predictions, data_outputs).detach().numpy() + 0.00000001\n",
        "\n",
        "#     solution_fitness = 1.0 / abs_error\n",
        "\n",
        "#     return solution_fitness\n",
        "\n",
        "# def callback_generation(ga_instance):\n",
        "#     print(\"Generation = {generation}\".format(generation=ga_instance.generations_completed))\n",
        "#     print(\"Fitness    = {fitness}\".format(fitness=ga_instance.best_solution()[1]))\n",
        "    \n",
        "    \n",
        "\n",
        "# X_train_torch = torch.tensor(X_train_first_reg, dtype=torch.float32)\n",
        "# Y_train_torch = torch.tensor(Y_train_first_reg, dtype=torch.float32)#.reshape(-1,1)\n",
        "# X_test_torch = torch.tensor(X_test_first_reg, dtype=torch.float32)\n",
        "# Y_test_torch = torch.tensor(Y_test_first_reg, dtype=torch.float32)#.reshape(-1,1)\n",
        "# n_inputs_sequ = X_train.shape[1]\n",
        "# n_outputs_sequ = Y_train.shape[1]\n",
        "\n",
        "# # Create the PyTorch model.\n",
        "# model = nn.Sequential(\n",
        "#     nn.Linear(n_inputs_first_reg, 108),\n",
        "#     nn.ReLU(),\n",
        "#     nn.Linear(108, 84),\n",
        "#     nn.ReLU(),\n",
        "#     nn.Linear(84, 60),\n",
        "#     nn.ReLU(),\n",
        "#     nn.Linear(60, 48),\n",
        "#     nn.ReLU(),\n",
        "#     nn.Linear(48, 36),\n",
        "#     nn.ReLU(),\n",
        "#     nn.Linear(36, 18),\n",
        "#     nn.ReLU(),\n",
        "#     nn.Linear(18, n_outputs_first_reg),\n",
        "#     nn.Sigmoid())\n",
        "# # print(model)\n",
        "\n",
        "# # Create an instance of the pygad.torchga.TorchGA class to build the initial population.\n",
        "# torch_ga = torchga.TorchGA(model=model,\n",
        "#                            num_solutions=10)\n",
        "\n",
        "# loss_function = torch.nn.L1Loss()\n",
        "\n",
        "# # Data inputs\n",
        "# data_inputs = X_train_torch\n",
        "\n",
        "# # Data outputs\n",
        "# data_outputs = Y_train_torch\n",
        "\n",
        "# # Prepare the PyGAD parameters. Check the documentation for more information: https://pygad.readthedocs.io/en/latest/README_pygad_ReadTheDocs.html#pygad-ga-class\n",
        "# num_generations = 250 # Number of generations.\n",
        "# num_parents_mating = 5 # Number of solutions to be selected as parents in the mating pool.\n",
        "# initial_population = torch_ga.population_weights # Initial population of network weights\n",
        "# parent_selection_type = \"sss\" # Type of parent selection.\n",
        "# crossover_type = \"single_point\" # Type of the crossover operator.\n",
        "# mutation_type = \"random\" # Type of the mutation operator.\n",
        "# mutation_percent_genes = 10 # Percentage of genes to mutate. This parameter has no action if the parameter mutation_num_genes exists.\n",
        "# keep_parents = -1 # Number of parents to keep in the next population. -1 means keep all parents and 0 means keep nothing.\n",
        "\n",
        "# ga_instance = pygad.GA(num_generations=num_generations,\n",
        "#                        num_parents_mating=num_parents_mating,\n",
        "#                        initial_population=initial_population,\n",
        "#                        fitness_func=fitness_func,\n",
        "#                        parent_selection_type=parent_selection_type,\n",
        "#                        crossover_type=crossover_type,\n",
        "#                        mutation_type=mutation_type,\n",
        "#                        mutation_percent_genes=mutation_percent_genes,\n",
        "#                        keep_parents=keep_parents,\n",
        "#                        on_generation=callback_generation)\n",
        "\n",
        "# ga_instance.run()\n",
        "\n",
        "# # After the generations complete, some plots are showed that summarize how the outputs/fitness values evolve over generations.\n",
        "# ga_instance.plot_result(title=\"PyGAD & PyTorch - Iteration vs. Fitness\", linewidth=4)\n",
        "\n",
        "# # Returning the details of the best solution.\n",
        "# solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
        "# print(\"Fitness value of the best solution = {solution_fitness}\".format(solution_fitness=solution_fitness))\n",
        "# print(\"Index of the best solution : {solution_idx}\".format(solution_idx=solution_idx))\n",
        "\n",
        "# # Fetch the parameters of the best solution.\n",
        "# best_solution_weights = torchga.model_weights_as_dict(model=model,\n",
        "#                                                       weights_vector=solution)\n",
        "# model.load_state_dict(best_solution_weights)\n",
        "# predictions = model(data_inputs)\n",
        "# print(\"Predictions : n\", predictions.detach().numpy())\n",
        "\n",
        "# abs_error = loss_function(predictions, data_outputs)\n",
        "# print(\"Absolute Error : \", abs_error.detach().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test_newer = pd.DataFrame(X_test_first_reg)\n",
        "Y_pred_general = first_reg_model.predict(X_test_newer.tail(260))\n",
        "\n",
        "Y_predicted_reboiler_temp = pd.DataFrame(Y_pred_general.transpose()[0])\n",
        "Y_test_newer = pd.DataFrame(Y_test_first_reg).tail(260)\n",
        "Y_test_reboiler_temp = pd.DataFrame(Y_test_newer.values.transpose()[0])\n",
        "\n",
        "pd.DataFrame({'real upper_product_flow_rate(kg/hr)': Y_test_reboiler_temp.squeeze(),\n",
        "              'predicted upper_product_flow_rate(kg/hr)': Y_predicted_reboiler_temp.squeeze()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.ensemble import RandomForestRegressor\n",
        "# first_model = RandomForestRegressor()\n",
        "\n",
        "# first_model.fit(X_train_first_reg,Y_train_first_reg)\n",
        "# predicted_reboiler_temp = first_model.predict(X_test_first_reg)\n",
        "# pd.DataFrame({'real reboiler temperature': Y_test_first_reg.squeeze(),\n",
        "#               'predicted reboiler temperature': predicted_reboiler_temp.squeeze()})\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.tree import DecisionTreeRegressor\n",
        "# first_model_1 = DecisionTreeRegressor()\n",
        "\n",
        "# first_model_1.fit(X_train_first_reg,Y_train_first_reg)\n",
        "# predicted_reboiler_temp_tree = first_model_1.predict(X_test_first_reg)\n",
        "# pd.DataFrame({'real reboiler temperature': Y_test_first_reg.squeeze(),\n",
        "#               'predicted reboiler temperature': predicted_reboiler_temp_tree.squeeze()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.linear_model import LinearRegression\n",
        "# first_model_2 = LinearRegression()\n",
        "\n",
        "# first_model_2.fit(X_train_first_reg,Y_train_first_reg)\n",
        "# predicted_reboiler_temp_lin = first_model_2.predict(X_test_first_reg)\n",
        "# pd.DataFrame({'real reboiler temperature': Y_test_first_reg.squeeze(),\n",
        "#               'predicted reboiler temperature': predicted_reboiler_temp_lin.squeeze()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import xgboost as xgb\n",
        "# regressor_xgb = xgb.XGBRegressor(n_estimators=30001,\n",
        "#                                   early_stop_rounds=50,\n",
        "#                                   max_depth=4,\n",
        "#                                   min_child_weight=7,\n",
        "#                                   gamma=0,\n",
        "#                                   subsample=0.9,\n",
        "#                                   colsample_bytree=1,\n",
        "#                                   reg_alpha=0.05,\n",
        "#                                   nthread=5,\n",
        "#                                   scale_pos_weight=1,\n",
        "#                                   objective='reg:squarederror',\n",
        "#                                   seed=32,\n",
        "#                                   learning_rate=0.00299)\n",
        "\n",
        "# # regressor_main = RandomForestRegressor()\n",
        "# regressor_xgb.fit(X_train_first_reg, Y_train_first_reg, eval_set=[(X_train_first_reg, Y_train_first_reg),(X_test_first_reg, Y_test_first_reg)],verbose=500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# results = regressor_xgb.evals_result()\n",
        "\n",
        "# plt.figure(figsize=(10,7))\n",
        "# plt.plot(results[\"validation_0\"][\"rmse\"], label=\"Training loss\")\n",
        "# plt.plot(results[\"validation_1\"][\"rmse\"], label=\"Validation loss\")\n",
        "# plt.axvline(1200, color=\"gray\", label=\"Optimal tree number\")\n",
        "# # plt.xlim([500,3000])\n",
        "# # plt.ylim([0,1])\n",
        "# plt.xlabel(\"Number of trees\")\n",
        "# plt.ylabel(\"Loss\")\n",
        "# plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# regressor_xgb.fit(X_train_first_reg,Y_train_first_reg)\n",
        "# predicted_reboiler_temp_xgb = regressor_xgb.predict(X_test_first_reg)\n",
        "# pd.DataFrame({'real reboiler temperature': Y_test_first_reg.squeeze(),\n",
        "#               'predicted reboiler temperature': predicted_reboiler_temp_xgb.squeeze()})\n",
        "\n",
        "# from sklearn.metrics import r2_score\n",
        "\n",
        "# print(\"neural network regressor r2 socre =\", r2_score(Y_test_first_reg,Y_predicted_reboiler_temp))\n",
        "# # print(\"random forest regressor r2 socre = \", r2_score(Y_test_first_reg,predicted_reboiler_temp))\n",
        "# # print(\"decision tree regressor r2 socre = \", r2_score(Y_test_first_reg,predicted_reboiler_temp_tree))\n",
        "# # print(\"linear regression r2 socre = \", r2_score(Y_test_first_reg,predicted_reboiler_temp_lin))\n",
        "# # print(\"xgboost regressor r2 socre = \", r2_score(Y_test_first_reg,predicted_reboiler_temp_xgb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.metrics import r2_score\n",
        "\n",
        "# print(\"neural network regressor r2 socre =\", r2_score(Y_test_first_reg,Y_predicted_reboiler_temp))\n",
        "# # print(\"random forest regressor r2 socre = \", r2_score(Y_test_first_reg,predicted_reboiler_temp))\n",
        "# # print(\"decision tree regressor r2 socre = \", r2_score(Y_test_first_reg,predicted_reboiler_temp_tree))\n",
        "# # print(\"linear regression r2 socre = \", r2_score(Y_test_first_reg,predicted_reboiler_temp_lin))\n",
        "# # print(\"xgboost regressor r2 socre = \", r2_score(Y_test_first_reg,predicted_reboiler_temp_xgb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # regressor_main.fit(X,Y)\n",
        "\n",
        "# #1\t466.7\t0.99\t1.098692327\t\t0.99899\t121.6209234\t118.0392264\t1.444240492\t4.332721476\t0.99899\t467.1718436\t84.21099119\t81.73100468\t99.899\t322.8192504\n",
        "# # 2   155.804\n",
        "\n",
        "# # inputs = (1, 0.99899, 121.6209234, 118.0392264, 1.444240492, 4.332721476,322.8192504 , 1.098692327, 0.99899, 467.1718436, 84.21099119, 81.73100468, 466.7)\n",
        "  \n",
        "# ##(0.99899, 4667, 1, 1.098692327, 0.99899, 467.1718436)\n",
        "# ##121.6209234\n",
        "# inputs_middle = (0.99899, 466.7, 1, 1.098692327, 0.99899, 467.1718436)\n",
        "\n",
        "# input_data_as_numpy_array = np.asarray(inputs_middle)\n",
        "# input_data_reshaped = input_data_as_numpy_array.reshape(1, -1)\n",
        "# print(\"neural network predict =\", first_reg_model.predict(input_data_reshaped))\n",
        "# # print(\"random forest predict =\", first_model.predict(input_data_reshaped))\n",
        "# # print(\"decision tree predict =\", first_model_1.predict(input_data_reshaped))\n",
        "# # print(\"linear reg predict =\", first_model_2.predict(input_data_reshaped))\n",
        "# # print(\"xgb regressor predict =\", regressor_xgb.predict(input_data_reshaped))\n",
        "\n",
        "# # print(results)\n",
        "# #'atmosphere_pressure', 'reboiler(pot)_heat_duty(Watt)', 'produced_acetic_acid_mass_fraction', 'new_reboiler(pot)_temperature(C)', 'upper_product_flow_rate(kg/hr)', 'pot_pressure(atm)', 'condenser_mass_flow_outlet_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # regressor_main.fit(X,Y)\n",
        "\n",
        "# ## 2\t2.098692327\t466.7\t0.99\t3.972966667\t165.749064\t163.0687495\t0.499823\t233.4326352\t99.9646\t535.1616894\t\t0.999646\t144.4940959\t0.871764174\t3.030305306\t142.1574937\t1.000000751\t4.358820871\n",
        "# ## 4  238.378\n",
        "\n",
        "# # inputs = (2, 0.999646, 144.4940959, 142.1574937, 0.871764174, 4.358820871 ,535.1616894 , 2.098692327, 0.499823, 233.4326352, 165.749064, 163.0687495, 466.7)\n",
        "# ##(0.999646, 466.7, 2, 2.098692327, 0.499823, 233.4326352)\n",
        "# ##  0.871764174\n",
        "# inputs_outter = (0.999646, 466.7, 238.378, 238.378*466.7, 238.378*0.999646/466.7, 2)\n",
        "# input_data_as_numpy_array_outter = np.asarray(inputs_outter)\n",
        "# input_data_reshaped_outter = input_data_as_numpy_array_outter.reshape(1, -1)\n",
        "\n",
        "# print(\"neural network predict =\", first_reg_model.predict(input_data_reshaped_outter))\n",
        "# print(\"random forest predict =\", first_model.predict(input_data_reshaped_outter))\n",
        "# print(\"decision tree predict =\", first_model_1.predict(input_data_reshaped_outter))\n",
        "# print(\"linear reg predict =\", first_model_2.predict(input_data_reshaped_outter))\n",
        "# # print(\"xgb regressor predict =\", regressor_xgb.predict(input_data_reshaped_outter))\n",
        "\n",
        "# # print(results)\n",
        "# #'atmosphere_pressure', 'reboiler(pot)_heat_duty(Watt)', 'produced_acetic_acid_mass_fraction', 'new_reboiler(pot)_temperature(C)', 'upper_product_flow_rate(kg/hr)', 'pot_pressure(atm)', 'condenser_mass_flow_outlet_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ##serialize model to YAML\n",
        "# from keras.models import model_from_json, load_model\n",
        "\n",
        "# model_neural_json = first_reg_model.to_json()\n",
        "# with open(\"first_regression_model_LSTM.json\", \"w\") as json_file:\n",
        "#     json_file.write(model_neural_json)\n",
        "    \n",
        "# ##serialize weights to HDF5\n",
        "# first_reg_model.save_weights(\"first_regression_model_LSTM.h5\")\n",
        "# print(\"Saved model to disk\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Injaaaaaaa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ]
        }
      ],
      "source": [
        "from keras.models import model_from_json, load_model\n",
        "\n",
        "##load YAMl and create model\n",
        "json_file = open('first_regression_model_LSTM.json', 'r')\n",
        "loaded_model_yaml = json_file.read()\n",
        "json_file.close()\n",
        "loaded_first_model = model_from_json(loaded_model_yaml)\n",
        "##load weights into new model\n",
        "loaded_first_model.load_weights(\"first_regression_model_LSTM.h5\")\n",
        "print(\"Loaded model from disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer Name: lstm_70\n",
            "Weights: [[ 0.45901623 -0.12439454  0.11801443 -0.0019652   0.16539267  0.22350366\n",
            "   0.05975538 -0.02709177  0.23366842  0.18492454 -0.17486468  0.23755312\n",
            "   0.11308366 -0.17391182  0.21730493 -0.13918465  0.23262706 -0.08550993\n",
            "   0.07923885 -0.105064    0.28653124 -0.1966384  -0.1264682  -0.08410012\n",
            "  -0.21163161  0.11483707 -0.16217096 -0.0725612   0.19720727 -0.2199276\n",
            "  -0.09066409 -0.1268039  -0.1836562  -0.20924939  0.13138476 -0.23806913\n",
            "  -0.01317733 -0.1284809   0.2588184  -0.17522296 -0.14286773 -0.04107932\n",
            "  -0.4833628  -0.263515    0.29696915  0.22936305  0.16382615 -0.04497731\n",
            "  -0.02232312 -0.11014356  0.07256072 -0.1413341   0.08478655  0.19572826\n",
            "  -0.15869887  0.7620996  -0.00644172 -0.36890522  0.1552258  -0.37333348\n",
            "  -0.12578543  0.01497791  0.03955132  0.33114702  0.04878916  0.26313594\n",
            "   0.07581703 -0.3728855  -0.2389294  -0.16899377  0.00801092 -0.23150866\n",
            "   0.30563802  0.1147145   0.02675402 -0.09849118  0.44663677 -0.01808654\n",
            "  -0.0699407   0.47885883  0.6473051   0.07429244 -0.11469296  0.13199179\n",
            "  -0.17889121  0.11920109  0.15106682  0.01330109  0.29221082  0.03771632\n",
            "   0.21388274  0.23498881 -0.08872644  0.22146854  0.29842782 -0.05511022]]\n",
            "Biases: [[ 0.09976517 -0.02567386  0.00242118 ...  0.14928016  0.07244447\n",
            "   0.02202794]\n",
            " [ 0.1129332  -0.06224506  0.03799653 ... -0.09686502 -0.07312019\n",
            "  -0.12136828]\n",
            " [ 0.1937661   0.16257542 -0.1126224  ... -0.02061668 -0.03735508\n",
            "   0.00360081]\n",
            " ...\n",
            " [-0.05914314 -0.0845094   0.08293305 ... -0.00049919 -0.03110225\n",
            "  -0.11509542]\n",
            " [ 0.1133808   0.00170001  0.10275047 ...  0.04857299 -0.00183627\n",
            "  -0.06897698]\n",
            " [-0.04009395 -0.13269411 -0.10739693 ...  0.139239   -0.04462473\n",
            "  -0.11446218]]\n",
            "Layer Name: lstm_71\n",
            "Weights: [[ 0.09788406 -0.13072912 -0.09612408 ...  0.11207362 -0.0079649\n",
            "  -0.13416657]\n",
            " [-0.17808686  0.18803495  0.2185498  ... -0.2211496  -0.11529554\n",
            "  -0.00608301]\n",
            " [ 0.12233102  0.16018964  0.0179081  ... -0.20460162 -0.03759286\n",
            "   0.029536  ]\n",
            " ...\n",
            " [ 0.00251472  0.01159871  0.13707349 ...  0.13841468 -0.13069466\n",
            "   0.11567613]\n",
            " [-0.21969585  0.0127118   0.1169187  ... -0.247171    0.07450469\n",
            "  -0.02887291]\n",
            " [-0.02709492  0.10886392  0.18383786 ... -0.08953169 -0.09075814\n",
            "   0.08572891]]\n",
            "Biases: [[-0.00984655 -0.08467135  0.07440854 ...  0.15585394 -0.12385087\n",
            "  -0.14489482]\n",
            " [ 0.04488434  0.00396886  0.00534366 ... -0.16257733 -0.13355485\n",
            "  -0.04444066]\n",
            " [ 0.14209622 -0.10520943  0.06535681 ... -0.0172656   0.00472667\n",
            "   0.03879386]\n",
            " ...\n",
            " [ 0.00796069 -0.07406186 -0.02498254 ... -0.00036426 -0.08393528\n",
            "   0.10647509]\n",
            " [-0.14372627 -0.00893424  0.1307162  ...  0.06734234 -0.02859483\n",
            "  -0.00650664]\n",
            " [ 0.19197889 -0.0319646   0.03220942 ... -0.06193806 -0.11053744\n",
            "  -0.02026134]]\n",
            "Layer Name: lstm_72\n",
            "Weights: [[ 0.09554774 -0.04174962 -0.02973383 ... -0.0651596   0.1009351\n",
            "  -0.04368535]\n",
            " [ 0.527334   -0.1374391  -0.01039052 ...  0.06280071 -0.08661386\n",
            "   0.16919985]\n",
            " [-0.11106531 -0.00711619 -0.18003447 ...  0.1357627   0.08473885\n",
            "   0.01096254]\n",
            " ...\n",
            " [-0.00899334  0.02046612 -0.08459967 ...  0.09203407  0.1780524\n",
            "   0.05286209]\n",
            " [ 0.10917599 -0.06932358  0.10647119 ... -0.08146791  0.02762535\n",
            "  -0.19558686]\n",
            " [-0.0155209  -0.17081726 -0.16686164 ... -0.19170676 -0.27106085\n",
            "   0.1748168 ]]\n",
            "Biases: [[-0.0120249  -0.3346556  -0.07675204 ...  0.03681254 -0.25783166\n",
            "  -0.18695384]\n",
            " [ 0.09670879 -0.28277218 -0.03403208 ...  0.06981811  0.05835768\n",
            "   0.06295234]\n",
            " [-0.00281123 -0.00362204 -0.10662108 ... -0.04450986 -0.0176405\n",
            "   0.04531094]\n",
            " ...\n",
            " [ 0.04605674 -0.06649039 -0.02446091 ...  0.08771749  0.06072228\n",
            "  -0.02586163]\n",
            " [-0.14596549 -0.10372768  0.11057585 ...  0.07892565  0.01011837\n",
            "  -0.03555143]\n",
            " [ 0.01544308 -0.0180193   0.04436679 ... -0.0674849  -0.07094138\n",
            "   0.03322761]]\n",
            "Layer Name: lstm_73\n",
            "Weights: [[ 0.24240562  0.50657976 -0.00264466 ... -0.11246879  0.23206775\n",
            "   0.01949285]\n",
            " [-0.08075451 -0.28565243  0.05199263 ...  0.26516753 -0.08495649\n",
            "  -0.20164931]\n",
            " [-0.17899252  0.00322545  0.2589076  ...  0.3342557   0.4136158\n",
            "   0.25260025]\n",
            " ...\n",
            " [-0.094811    0.22667074  0.13099717 ...  0.16155268  0.17692168\n",
            "  -0.13083524]\n",
            " [ 0.30753234  0.12380151 -0.02280435 ... -0.11901578  0.05134833\n",
            "   0.2665603 ]\n",
            " [ 0.17200796  0.0902213   0.18287955 ...  0.18497407 -0.2335892\n",
            "  -0.14217356]]\n",
            "Biases: [[ 1.26625672e-01 -1.59037694e-01 -3.21911067e-01  2.46221006e-01\n",
            "   1.58971474e-01  5.72095752e-01  2.08528452e-02  8.84447396e-02\n",
            "   4.12371576e-01 -8.45090374e-02  4.41725850e-01  1.55754671e-01\n",
            "  -7.72837028e-02 -5.00600412e-02  2.50250429e-01 -2.84414403e-02\n",
            "  -2.31505588e-01 -4.96618934e-02  3.03461514e-02 -2.38960877e-01\n",
            "   1.00510553e-01 -1.73009053e-01 -1.80166528e-01  1.81504443e-01\n",
            "   2.94792414e-01  4.87284400e-02  2.74506032e-01  1.94833372e-02\n",
            "   2.86584139e-01 -1.08493604e-01 -4.90078665e-02 -1.44343048e-01\n",
            "  -5.04953638e-02  4.19012219e-01  3.03774863e-01  1.49960503e-01\n",
            "  -4.17801976e-01  1.54566556e-01 -1.68444186e-01  2.15949535e-01]\n",
            " [-2.09415331e-01 -4.43476051e-01  1.00913621e-01  1.56311952e-02\n",
            "   2.32865423e-01 -2.71272026e-02 -3.31131257e-02 -1.07305489e-01\n",
            "   4.05796468e-02 -2.00063258e-01 -4.03216146e-02  2.85396606e-01\n",
            "   1.49338335e-01 -1.32938251e-01  4.48076785e-01 -5.25103286e-02\n",
            "  -2.09610909e-03 -9.38519910e-02  4.90535468e-01 -1.49266362e-01\n",
            "   1.17034785e-01  1.12276025e-01 -3.99769545e-02  4.36082520e-02\n",
            "   1.23084329e-01  2.71430332e-02  6.73266947e-02 -3.44029456e-01\n",
            "   2.23033324e-01 -4.81637836e-01  7.91208893e-02  2.07159668e-01\n",
            "   1.00350149e-01 -1.21917874e-01  3.13410163e-02  2.85567939e-01\n",
            "   2.74887323e-01 -2.95118019e-02 -1.17933713e-01 -4.76201475e-01]\n",
            " [-1.17204592e-01 -2.26683002e-02  5.38292788e-02  2.29243800e-01\n",
            "  -6.71543851e-02 -1.25377579e-03 -2.76414007e-01 -9.85329598e-02\n",
            "  -2.64761820e-02 -3.14772815e-01  1.76175803e-01  2.27824956e-01\n",
            "  -1.02934591e-01  2.75131613e-01 -1.84414089e-01 -4.45713401e-02\n",
            "   7.09778517e-02 -9.67544969e-03 -2.02099338e-01  1.78494096e-01\n",
            "   4.65066433e-02 -2.42580269e-02 -1.06679261e-01 -1.90325797e-01\n",
            "  -6.20314516e-02  2.93832477e-02 -4.33857322e-01  1.92552537e-01\n",
            "   3.35731125e-03 -2.04397425e-01 -5.91722466e-02  6.42053112e-02\n",
            "  -1.87257141e-01  1.50020555e-01  1.11640103e-01  2.31070578e-01\n",
            "  -8.99552852e-02  6.47852384e-03 -2.61787698e-02 -3.81515250e-02]\n",
            " [ 9.01884362e-02 -5.32201827e-02  2.35652521e-01  2.66966105e-01\n",
            "   1.17643677e-01 -5.13390005e-02  1.07728161e-01  2.04602942e-01\n",
            "   3.54852587e-01 -4.17155266e-01 -1.86199322e-01  2.51565367e-01\n",
            "  -7.38372058e-02 -2.33258665e-01  4.14337218e-01  4.11964580e-02\n",
            "  -5.57547212e-02  5.71097508e-02 -7.97643419e-03 -2.68907428e-01\n",
            "  -3.56834680e-01  7.00632557e-02 -2.50116915e-01  2.09513992e-01\n",
            "   2.59150833e-01 -1.63571790e-01 -7.68124089e-02 -5.35659455e-02\n",
            "   1.79883286e-01 -1.83033735e-01 -3.13501596e-01 -2.22013935e-01\n",
            "   1.31411418e-01  1.48512334e-01  1.38488993e-01  6.37082458e-02\n",
            "  -1.76371142e-01 -9.49794054e-02  2.46576034e-02 -2.82960027e-01]\n",
            " [ 5.96633926e-02 -2.09674865e-01  1.05527118e-01  3.58697996e-02\n",
            "   6.52491508e-05 -2.48748753e-02  2.40739360e-02 -3.33124250e-01\n",
            "  -9.90731083e-03 -8.37372914e-02  2.32781470e-01  1.99623913e-01\n",
            "  -4.01404560e-01 -1.78708181e-01 -1.57776609e-01  1.16692737e-01\n",
            "  -2.93767810e-01  9.27010179e-02  8.25597569e-02  1.11638755e-01\n",
            "   6.46344498e-02  3.94131131e-02  3.99540886e-02  1.64162323e-01\n",
            "   3.25196177e-01  2.20406741e-01 -5.53267561e-02 -1.32714286e-01\n",
            "  -1.23134390e-01  1.05969319e-02  1.27547666e-01  5.76066196e-01\n",
            "   1.16597854e-01  1.73554212e-01 -3.21398792e-03 -1.32222205e-01\n",
            "   7.86165148e-02  8.02981928e-02  1.47033989e-01  1.44565240e-01]\n",
            " [ 1.18989803e-01 -3.69962007e-02 -8.36753473e-02  4.08007681e-01\n",
            "   3.74249607e-01  9.56497621e-03 -2.29478836e-01 -3.42557058e-02\n",
            "   4.16283041e-01  1.99942037e-01 -1.23400114e-01 -6.75481781e-02\n",
            "  -2.28411376e-01 -6.22544438e-02  2.11078554e-01  1.08708188e-01\n",
            "   1.25005588e-01  9.81059968e-02  1.51053026e-01  2.67769210e-02\n",
            "   1.14705324e-01 -7.04540536e-02 -9.70727652e-02  2.13581130e-01\n",
            "   1.37745872e-01 -2.31998935e-01 -3.12573731e-01 -1.46592885e-01\n",
            "  -2.04258189e-02 -6.37157485e-02  4.50212136e-02  2.13566408e-01\n",
            "  -3.64083827e-01 -5.67338951e-02  2.41448328e-01 -1.30503386e-01\n",
            "  -6.68027252e-02  1.52873158e-01  3.79438065e-02  3.27811599e-01]\n",
            " [ 1.86720356e-01 -1.88250452e-01  1.52750269e-01 -1.14610814e-01\n",
            "   4.19667900e-01  2.09819809e-01 -1.60665452e-01  1.42905071e-01\n",
            "   1.60961524e-01  3.72790024e-02 -6.71498328e-02  3.82637739e-01\n",
            "  -6.42630691e-03  9.75225028e-03  8.32025558e-02 -1.72220990e-01\n",
            "   1.80284396e-01  1.89145356e-01  4.21810061e-01  1.20480172e-02\n",
            "   4.41900343e-02  5.88329062e-02  2.38982722e-01 -2.96082348e-02\n",
            "   4.06025440e-01  3.62854838e-01 -3.26378345e-01  2.61963099e-01\n",
            "   1.16063014e-01  9.70977023e-02 -1.50850698e-01  1.41979933e-01\n",
            "   5.06467335e-02  3.68191212e-01  1.81209370e-01  3.20322663e-01\n",
            "   7.25984499e-02  2.32754901e-01  5.36125191e-02  1.67995453e-01]\n",
            " [ 5.01357496e-01 -1.01303525e-01  4.72593270e-02  3.20202827e-01\n",
            "   2.74600208e-01 -1.39604554e-01 -1.15760177e-01  1.35943547e-01\n",
            "  -2.41351360e-03 -4.26694572e-01  8.51967931e-02  2.07272142e-01\n",
            "   1.44091994e-01 -1.11838803e-01  9.50240791e-02  6.97933659e-02\n",
            "  -6.58217013e-01 -4.00786614e-03 -4.52775955e-02 -1.92210197e-01\n",
            "   5.13130948e-02  1.99389100e-01  3.41855958e-02 -1.04169913e-01\n",
            "   2.44686484e-01  3.11598599e-01 -3.18660401e-02 -2.03768145e-02\n",
            "   7.28832930e-02  4.17524278e-02 -4.74158004e-02  1.99365675e-01\n",
            "  -1.79418519e-01  1.29660005e-02  2.88570672e-02 -1.20982431e-01\n",
            "   3.27105433e-01  2.46683553e-01  1.73266798e-01 -4.43933420e-02]\n",
            " [ 3.96551371e-01 -1.67727947e-01 -2.55508602e-01  1.46859558e-03\n",
            "   2.76709497e-01  2.34890804e-01 -1.58703715e-01 -1.20220050e-01\n",
            "   8.65524262e-02 -3.09197176e-02  3.01501095e-01  1.04485184e-01\n",
            "   4.37562540e-02  9.68912244e-02  4.39445764e-01 -1.61044627e-01\n",
            "  -5.71307167e-02 -1.08395234e-01  1.69985846e-01  7.04429299e-02\n",
            "   1.09453149e-01 -7.32071698e-02  2.84451302e-02  1.05071604e-01\n",
            "   2.79857874e-01  1.61144808e-01 -3.30783352e-02 -3.05013895e-01\n",
            "   6.72790855e-02 -2.45641083e-01  3.70440960e-01  5.63695312e-01\n",
            "  -3.17162842e-01  2.43666366e-01 -1.79268956e-01 -5.89986071e-02\n",
            "  -1.05968066e-01  3.62778872e-01 -5.67064295e-03 -3.07780087e-01]\n",
            " [-1.12543955e-01 -1.34520069e-01 -2.14728154e-02 -5.32097220e-02\n",
            "  -1.49068639e-01 -9.17131007e-02 -2.75093410e-02 -5.26817702e-02\n",
            "   4.86807078e-01  1.68644786e-01 -8.50094855e-02 -9.06077400e-02\n",
            "  -2.89710432e-01 -1.27610728e-01  4.31384832e-01 -2.25613683e-01\n",
            "  -9.56595987e-02 -2.79643863e-01 -1.57344550e-01 -8.11786205e-02\n",
            "   2.00792715e-01  2.27779876e-02 -6.69428706e-02  8.25969204e-02\n",
            "   2.22101450e-01  2.40679756e-01 -1.98064715e-01 -8.46003145e-02\n",
            "   1.14497751e-01  6.22918122e-02  4.34358753e-02 -7.42254108e-02\n",
            "  -1.04246452e-01 -6.40629232e-03 -9.38405246e-02  1.26556531e-01\n",
            "   1.29704997e-01 -6.18601404e-02 -5.03440559e-01  1.42616645e-01]]\n",
            "Layer Name: lstm_74\n",
            "Weights: [[ 3.99799764e-01 -1.14785299e-01  4.96046133e-02 -2.82966137e-01\n",
            "  -4.24324013e-02 -1.47904521e-02  1.61141634e-01 -8.18841904e-03\n",
            "   4.03154820e-01 -2.89216101e-01 -5.25277667e-02  8.49101022e-02\n",
            "   4.90610115e-02  5.51800989e-03  3.98891456e-02  5.46768047e-02\n",
            "   2.90965233e-02  2.11577848e-01  1.56929642e-01  6.26461208e-02\n",
            "   2.91094720e-01 -1.48701787e-01  3.18043530e-01  1.91675723e-01\n",
            "  -1.63692638e-01 -3.25140029e-01 -2.39295606e-02  2.37238333e-02\n",
            "  -1.74091101e-01 -6.16308600e-02 -3.19209307e-01 -4.17061821e-02\n",
            "   2.88351685e-01  3.47474456e-01 -1.34206876e-01  1.19231284e-01\n",
            "  -1.22849323e-01 -1.47631526e-01 -9.50010344e-02 -4.69231084e-02\n",
            "  -3.68756708e-03  2.55455285e-01  1.60156831e-01  1.56713784e-01\n",
            "  -4.78767082e-02  1.40144348e-01 -1.72905177e-01  2.58311450e-01\n",
            "  -9.71103832e-02  6.18556738e-02  2.80635536e-01 -1.02020986e-01\n",
            "   4.65959609e-02 -1.45742878e-01 -3.30857515e-01 -2.68870801e-01\n",
            "   1.21703491e-01  4.79249507e-02  6.08770959e-02 -3.73187780e-01\n",
            "  -2.64513828e-02 -1.92344517e-01 -1.43976480e-01  1.46828875e-01\n",
            "   1.78551584e-01 -1.78166956e-01  9.03188288e-02  6.53958414e-03\n",
            "  -9.04161260e-02  9.89746749e-02  1.54631194e-02 -3.98047984e-01\n",
            "   1.60630181e-01  1.62470743e-01 -3.91104370e-01  1.31471694e-01\n",
            "  -1.45787656e-01  2.46884599e-02 -2.32715338e-01 -2.37378016e-01\n",
            "  -8.39654356e-02  4.67184708e-02  4.01455432e-01  1.26216426e-01\n",
            "  -4.59166765e-01  7.26715624e-02 -5.23700453e-02  6.59629842e-03\n",
            "   1.70543209e-01  5.24542779e-02 -5.90675622e-02  3.96644950e-01\n",
            "   7.12143183e-01 -4.16350923e-02  1.00131802e-01  1.72025859e-01\n",
            "  -4.40180480e-01  5.57626411e-02  2.34739110e-01 -6.88864067e-02]\n",
            " [ 4.65901420e-02 -5.28541878e-02  1.52712494e-01 -2.79797584e-01\n",
            "   2.85213828e-01  9.87388343e-02 -2.99707172e-03  2.25711893e-02\n",
            "  -4.59244996e-02  1.30206227e-01 -2.34760776e-01 -1.04806736e-01\n",
            "   5.92037700e-02 -1.52627200e-01 -8.99401158e-02  3.01266879e-01\n",
            "   3.03391933e-01 -8.71264488e-02 -1.47132307e-01 -1.15357235e-01\n",
            "   4.10285801e-01 -2.67488152e-01  4.06202167e-01 -3.22052151e-01\n",
            "   1.42146200e-01  7.01260045e-02  5.54885268e-02  3.76358442e-02\n",
            "  -3.06165386e-02  2.17030738e-02  5.50308339e-02  4.27227885e-01\n",
            "   8.43564034e-01  1.23289242e-01 -1.72076359e-01 -6.53383322e-03\n",
            "  -8.06155521e-03  1.31992087e-01  1.03265032e-01  1.40432924e-01\n",
            "  -1.36309922e-01  2.19927073e-01 -2.11602394e-02 -3.88870537e-02\n",
            "   1.08627602e-03 -6.47403598e-02  9.15053114e-03  7.08024144e-01\n",
            "  -6.64019659e-02  1.17125444e-01 -4.89356108e-02 -5.71580194e-02\n",
            "  -1.06085323e-01 -1.73267230e-01 -1.98619083e-01  1.50417343e-01\n",
            "  -7.22066388e-02  1.73411053e-02  1.60174053e-02 -3.43162775e-01\n",
            "   9.12659764e-02 -2.03874424e-01 -1.26413524e-01 -1.81138963e-01\n",
            "  -5.32269813e-02 -1.60971001e-01 -2.30477694e-02  1.70057610e-01\n",
            "   5.46790138e-02 -1.70047522e-01  9.26272869e-02  1.11409403e-01\n",
            "   1.61036551e-01  6.87030181e-02 -1.34134859e-01  3.66718322e-01\n",
            "   3.86968069e-02  1.51754454e-01 -1.05054878e-01  2.52420813e-01\n",
            "   7.09420294e-02 -5.40608317e-02  1.94574341e-01  1.27481967e-01\n",
            "   7.92401358e-02  1.03997104e-01 -2.51519587e-02 -1.92967236e-01\n",
            "   7.49770328e-02 -9.07815844e-02  1.02823429e-01  4.50707108e-01\n",
            "   2.67055511e-01  3.30194831e-01  2.55234390e-01 -1.45564660e-01\n",
            "  -3.04313123e-01 -5.58777452e-02  4.51923758e-02  7.85115659e-02]\n",
            " [-9.82616842e-02 -3.64526846e-02  2.18222886e-01  2.54173666e-01\n",
            "   1.20608062e-01 -3.29243345e-03 -2.15452790e-01 -2.79088497e-01\n",
            "  -2.29876898e-02  3.83244082e-02  1.53595030e-01  8.30919817e-02\n",
            "   7.78667256e-02  1.88036487e-01 -1.25923604e-01  3.33353966e-01\n",
            "  -4.43026312e-02 -2.70277888e-01 -3.00253984e-02  2.22364441e-02\n",
            "  -2.67797112e-01 -4.72829491e-02  2.12484151e-01  4.35950220e-01\n",
            "   7.38146016e-03 -1.73057660e-01 -7.58599788e-02 -2.50162363e-01\n",
            "   1.40053704e-01  2.31097221e-01 -5.17727375e-01 -3.74169588e-01\n",
            "   3.02853018e-01  3.11311752e-01 -6.95813969e-02  2.06361115e-01\n",
            "  -7.01803491e-02  1.06037937e-01  2.53906876e-01 -4.66801643e-01\n",
            "   1.21428907e-01  1.66848987e-01 -2.72061586e-01 -3.37219387e-02\n",
            "   3.18910740e-02  5.90973496e-01 -1.04923904e-01  5.84145635e-02\n",
            "  -1.98309064e-01 -2.42513224e-01 -9.41334516e-02  2.89669961e-01\n",
            "   2.45785564e-01  1.97042804e-03  3.10454756e-01 -1.76423803e-01\n",
            "  -1.50670871e-01  5.82214035e-02 -5.44464886e-02  2.24337131e-01\n",
            "   1.59724146e-01 -4.86778356e-02 -2.82822698e-02  6.32011071e-02\n",
            "  -9.82553661e-02 -2.38750130e-03 -2.36719459e-01  2.26976991e-01\n",
            "  -1.69911608e-01  2.00863749e-01  2.52267689e-01 -1.72275782e-01\n",
            "   5.42583019e-02 -3.76572162e-02  9.68794897e-02 -1.23486534e-01\n",
            "  -8.10770690e-03  1.37604341e-01  2.32606694e-01 -2.04932779e-01\n",
            "  -7.73108900e-02 -1.04161873e-01  1.17275572e+00  7.04679132e-01\n",
            "   2.98070371e-01 -2.11107612e-01  1.61285475e-01  1.57218263e-01\n",
            "  -2.08119452e-01 -1.95380270e-01  1.97130501e-01  1.10083246e+00\n",
            "   3.88731956e-01 -3.90292332e-02  4.48958427e-02 -2.23228693e-01\n",
            "  -1.30188271e-01 -1.82760149e-01  5.85197881e-02 -5.90160675e-02]\n",
            " [-1.37101233e-01 -1.33864596e-01  3.72871220e-01  3.31367910e-01\n",
            "  -8.00135881e-02  9.79331601e-03 -4.28657532e-01  9.25180167e-02\n",
            "   3.42207193e-01  3.96014482e-01  7.25015476e-02  2.11139828e-01\n",
            "   1.47479936e-01 -6.34016544e-02 -2.42160335e-01  6.63680062e-02\n",
            "   2.56390125e-01 -1.52582839e-01 -1.42533123e-01 -3.77253853e-02\n",
            "  -9.14721712e-02 -7.54439458e-02  4.59449112e-01 -7.39695653e-02\n",
            "   4.25805718e-01  1.34143099e-01  2.40602270e-01 -6.50991127e-02\n",
            "   2.16786146e-01 -1.03872955e-01 -1.97187081e-01 -3.60601276e-01\n",
            "  -4.31569874e-01  2.49989226e-01 -2.13285714e-01  2.26847902e-01\n",
            "  -6.05987338e-03  9.40898657e-02  4.86901477e-02  3.14074345e-02\n",
            "   1.20497279e-01  3.71135026e-02 -2.04475418e-01 -4.32774909e-02\n",
            "  -1.39399499e-01 -2.62764413e-02 -4.11151022e-01 -1.42385855e-01\n",
            "  -2.90857971e-01 -1.09784685e-01  1.54342443e-01  1.89612463e-01\n",
            "   9.55535397e-02  2.81602293e-01 -2.28416115e-01  4.94367331e-02\n",
            "  -1.02899686e-01 -1.34445071e-01  1.29879028e-01  6.74701110e-02\n",
            "  -1.21785745e-01  4.19896483e-01 -6.33044913e-02 -9.74848494e-02\n",
            "  -1.59619357e-02  2.68985592e-02  8.48881379e-02 -4.31777805e-01\n",
            "  -2.51897961e-01 -1.17391683e-01 -1.47847101e-01  1.97510540e-01\n",
            "  -3.86856765e-01 -3.70317876e-01 -6.33814186e-02  2.29285523e-01\n",
            "  -7.24096820e-02  1.84178889e-01  3.72237176e-01 -2.54558742e-01\n",
            "  -1.76358782e-02 -4.17121559e-01  1.55757040e-01 -5.15204389e-03\n",
            "   4.28705037e-01  2.03002349e-01  1.87945321e-01 -1.04040593e-01\n",
            "  -2.05335498e-01  9.27117690e-02  7.35937506e-02 -1.49488658e-01\n",
            "  -5.87229848e-01  7.29360580e-02 -3.40849817e-01 -4.95898962e-01\n",
            "   3.08622401e-02 -3.18950474e-01 -3.45071763e-01  1.74653083e-01]\n",
            " [ 2.41877079e-01 -1.58611342e-01  2.92492688e-01  9.58256349e-02\n",
            "   2.61295289e-01  3.71171981e-01  3.92333753e-02 -5.87243661e-02\n",
            "   4.05999571e-01 -5.10220051e-01 -1.10532001e-01  5.85185103e-02\n",
            "   2.45003000e-01  6.64257556e-02 -2.99744634e-03  1.05229735e-01\n",
            "  -1.23223081e-01  3.66756201e-01 -2.93781515e-02  1.13888651e-01\n",
            "   7.71537870e-02  3.21114510e-02  4.77254510e-01 -1.70763806e-01\n",
            "  -1.93628669e-01 -1.76246926e-01  5.46017550e-02 -1.28932938e-01\n",
            "  -1.22622736e-01  1.99892104e-01 -1.40991867e-01  1.57936454e-01\n",
            "   1.60526216e+00  1.54628956e+00 -2.68062443e-01  1.67691782e-01\n",
            "   1.15814939e-01  5.18523492e-02  8.02908987e-02 -2.70858258e-01\n",
            "   6.67062029e-02  2.06925631e+00  9.53930676e-01  1.04538634e-01\n",
            "   2.27182079e-02 -2.23970550e-04  4.31762666e-01  1.87698901e+00\n",
            "  -2.44772032e-01  2.23532841e-02  2.77365357e-01 -2.76494384e-01\n",
            "  -3.52172762e-01 -3.73918191e-03 -1.77793875e-01  6.60379753e-02\n",
            "   1.66624308e-01 -6.19271770e-02 -2.70016789e-02 -3.83970737e-01\n",
            "  -3.23861651e-02  1.03695951e-01 -2.01562896e-01  1.84202150e-01\n",
            "   5.03124557e-02 -2.59957314e-01  1.02420852e-01 -8.43043625e-02\n",
            "  -1.19546875e-01  3.32504511e-01  1.36552975e-01 -7.83644691e-02\n",
            "   1.82778522e-01  2.97379583e-01 -1.05408184e-01  1.07685067e-01\n",
            "   1.04818396e-01  8.76379758e-02  8.01024958e-03  6.69567287e-01\n",
            "   5.98684400e-02  1.70792341e-01  1.38962209e+00  4.25492436e-01\n",
            "  -3.31624210e-01 -3.73428017e-02  7.67247155e-02  2.21963916e-02\n",
            "   5.75336143e-02 -4.00704816e-02  4.83922474e-02  1.73895884e+00\n",
            "   1.65845644e+00  3.30261956e-03  7.89326876e-02 -4.82444242e-02\n",
            "  -1.49982572e-01 -7.11285546e-02 -1.64043363e-02 -1.05075404e-01]\n",
            " [ 6.66830838e-02 -1.64239198e-01 -2.41392925e-01 -4.80829813e-02\n",
            "  -1.15932994e-01  1.69527858e-01  1.15496889e-02  2.08696678e-01\n",
            "  -1.05073564e-01 -3.43270242e-01 -2.18950026e-02  1.07633984e-02\n",
            "  -9.50419828e-02 -1.08543135e-01 -5.65606169e-03  1.16026416e-01\n",
            "  -1.79546222e-01 -6.47442639e-02 -4.70842905e-02  1.57296240e-01\n",
            "   1.01139560e-01  2.16759965e-02 -5.23127355e-02 -3.78431112e-01\n",
            "  -1.60220280e-01 -8.93055424e-02  1.27520904e-01 -8.50994587e-02\n",
            "  -1.53357148e-01  1.90635487e-01  5.62947318e-02 -1.13289408e-01\n",
            "   2.57520527e-01  4.88091633e-02 -7.34330863e-02 -1.41086310e-01\n",
            "   3.00637543e-01 -5.23603000e-02 -3.13808694e-02 -1.14278914e-02\n",
            "  -2.47754931e-01  2.06958637e-01 -1.51585350e-02  4.44315299e-02\n",
            "  -1.28664672e-01  2.48170495e-01  9.23023820e-02  3.28667611e-01\n",
            "  -8.31390247e-02  1.35075539e-01  1.85697466e-01 -4.73716781e-02\n",
            "   1.32115453e-01  3.06565821e-01  1.44695565e-01  2.24715859e-01\n",
            "  -5.75496862e-03 -1.54417291e-01 -1.33235708e-01 -3.22407246e-01\n",
            "  -1.72717974e-01  1.73177376e-01 -2.02501357e-01 -7.75551796e-02\n",
            "  -7.89483115e-02 -3.65282446e-02  1.21253235e-02 -1.95217859e-02\n",
            "  -2.65813142e-01  1.47166893e-01 -2.87482977e-01 -6.84651956e-02\n",
            "  -2.13329464e-01 -4.63717967e-01  4.09672745e-02 -8.60504955e-02\n",
            "  -1.45923615e-01 -2.65897214e-02 -7.45345131e-02 -2.51263112e-01\n",
            "   2.04828411e-01 -4.50237468e-02  2.40583494e-01 -1.46307796e-01\n",
            "  -2.04159200e-01 -1.03459284e-01  1.29068503e-04  2.75969654e-02\n",
            "   1.85724244e-01  1.59783084e-02  1.62123859e-01  4.79039937e-01\n",
            "   1.88980654e-01  1.32496402e-01 -2.72279587e-02  9.02240649e-02\n",
            "   6.70778146e-03 -2.40434065e-01 -7.22333789e-01  1.90045252e-01]\n",
            " [-1.62872210e-01 -1.74518093e-01  2.66354233e-01  1.14880688e-01\n",
            "   1.65324673e-01 -2.22566590e-01 -2.62252297e-02 -4.10553776e-02\n",
            "  -1.18191138e-01  6.17584810e-02 -2.23272026e-01 -1.52724355e-01\n",
            "  -2.00948253e-01 -5.04130274e-02  1.76440459e-02 -1.54648960e-01\n",
            "  -9.03030932e-02 -2.46085212e-01  3.02394852e-02 -2.63380289e-01\n",
            "  -1.28304496e-01 -1.98127538e-01  7.12556124e-01  2.51307815e-01\n",
            "  -1.71604902e-01 -5.43629043e-02 -1.26643449e-01 -9.33299586e-02\n",
            "   1.94210634e-01 -2.34895959e-01 -2.70485938e-01 -1.74601823e-01\n",
            "   4.07055497e-01 -1.28111258e-01  2.08940785e-02  1.04005747e-02\n",
            "   3.43070269e-01 -1.87204227e-01 -6.14249371e-02  4.82533611e-02\n",
            "   2.02288687e-01  5.10500371e-01 -2.03408614e-01 -5.14998063e-02\n",
            "   1.67556152e-01  5.75248539e-01 -1.02386117e-01 -9.58737582e-02\n",
            "  -3.01752150e-01  1.58923551e-01 -2.24396914e-01 -3.05774182e-01\n",
            "   7.68177360e-02  1.24350525e-01  2.71346748e-01 -3.86283726e-01\n",
            "   6.69537038e-02 -1.32653400e-01 -1.27176791e-01  1.35285974e-01\n",
            "  -2.39465609e-01 -2.41744488e-01 -1.39569893e-01 -1.89441517e-01\n",
            "   2.50798136e-01  1.82889566e-01  2.23899990e-01  2.47923076e-01\n",
            "   4.42395620e-02 -1.90498710e-01  2.21698418e-01 -3.91890526e-01\n",
            "   1.79749057e-01 -9.08379331e-02  4.45241779e-02  5.10389507e-02\n",
            "  -4.06204551e-01  3.47728252e-01  2.11358309e-01 -2.98893638e-02\n",
            "  -3.11950326e-01 -4.22034599e-02  5.93033969e-01  3.36033255e-01\n",
            "   4.97786291e-02  1.74942072e-02  2.27337494e-01  2.87668500e-02\n",
            "   1.92043379e-01  2.45058369e-02  4.66560163e-02  4.08993483e-01\n",
            "   1.47134170e-01  1.00039765e-01 -1.13424305e-02 -1.88861504e-01\n",
            "   7.51305893e-02 -1.73896074e-01 -1.63410857e-01  1.73207775e-01]\n",
            " [-2.79395759e-01  1.57339647e-01 -5.34880981e-02  1.67680636e-01\n",
            "   1.79896533e-01  9.66370851e-02  2.85503864e-01 -8.06279853e-02\n",
            "   3.42132151e-01  2.19864115e-01  4.86869700e-02  3.97052526e-01\n",
            "   1.33470505e-01 -1.04396790e-01  8.22826922e-02  9.58709046e-02\n",
            "  -1.94173798e-01  3.35080624e-02 -1.85080934e-02 -6.05529398e-02\n",
            "   1.80659577e-01  3.20805162e-01  9.91110682e-01 -4.53741223e-01\n",
            "  -2.55117148e-01  8.87860078e-03 -1.25858173e-01  2.79665977e-01\n",
            "   4.98633198e-02  3.45892459e-02  5.35453372e-02  2.47142166e-01\n",
            "   9.86215949e-01 -6.03574887e-02 -1.13375761e-01  3.47485453e-01\n",
            "   1.54762998e-01 -1.67571589e-01 -1.90731585e-01 -2.02274218e-01\n",
            "   3.00110400e-01  1.22385975e-02  3.28722745e-01  4.22298647e-02\n",
            "   2.00322673e-01 -2.61826664e-01  3.99807185e-01  8.02529871e-01\n",
            "  -2.47736350e-02  1.17931120e-01 -3.26700598e-01  3.54274720e-01\n",
            "   2.81898789e-02  2.09617734e-01 -4.37079603e-03 -2.55924221e-02\n",
            "  -2.11413074e-02  9.10490472e-03 -2.26438716e-02 -8.68444666e-02\n",
            "   2.51690656e-01  4.01062705e-02 -1.41511410e-01  3.52387838e-02\n",
            "   1.45579502e-01  2.87137628e-02  1.77897513e-01 -2.40483191e-02\n",
            "  -2.05840301e-02 -1.36697337e-01 -1.10791706e-01 -2.73743838e-01\n",
            "   2.26170365e-02 -2.87312686e-01 -1.05110973e-01  1.57806262e-01\n",
            "   1.51422173e-01 -1.30375668e-01  1.24362826e-01 -3.98381148e-04\n",
            "   4.01805967e-01  4.79633659e-02  1.23288167e+00 -1.96134001e-01\n",
            "  -2.96146303e-01 -2.58220106e-01 -3.77459079e-02  2.42293403e-02\n",
            "  -1.66423351e-01 -2.09817011e-02  1.94521308e-01  1.21127188e+00\n",
            "   9.46402073e-01  6.56014383e-02  9.92119312e-02  4.27407026e-02\n",
            "   3.33442926e-01 -7.77336285e-02  4.53715213e-02  5.43113090e-02]\n",
            " [ 2.29027495e-01 -1.83283120e-01  5.39343283e-02  1.46303073e-01\n",
            "   4.35973883e-01 -1.55188395e-02  4.58817542e-01 -9.43239219e-03\n",
            "  -2.59902999e-02  2.61763453e-01  2.35129207e-01 -3.66074055e-01\n",
            "   2.76869927e-02 -6.59449771e-02 -4.75644618e-02  3.49222541e-01\n",
            "   7.11676404e-02  1.09831594e-01 -2.01441348e-01 -4.41552363e-02\n",
            "   2.96465874e-01  6.56273589e-02  6.02388084e-01  2.55023735e-03\n",
            "  -5.76970398e-01 -4.79582131e-01 -2.53423490e-02 -1.33937195e-01\n",
            "   4.05964106e-02  3.11974913e-01 -3.80025059e-01 -1.69153020e-01\n",
            "   2.88963497e-01 -2.49625780e-02 -3.71580571e-01  2.83989962e-02\n",
            "   2.84004271e-01  2.64445748e-02  1.83138832e-01 -1.69480905e-01\n",
            "  -9.00554806e-02  2.50114560e-01 -2.04141170e-01  6.48918971e-02\n",
            "   7.82031715e-02  3.35918814e-01 -4.89761591e-01  1.08131301e+00\n",
            "  -4.00090776e-02 -1.64966553e-01  1.55089945e-01  1.43564254e-01\n",
            "  -2.03919888e-01  2.30041057e-01 -1.26567602e-01  1.73142761e-01\n",
            "   2.41111025e-01  1.39509648e-01  1.24254085e-01 -1.93752810e-01\n",
            "   1.65663660e-01 -5.10708392e-01  1.22264408e-01  8.41804147e-02\n",
            "  -1.09497160e-02 -2.12255806e-01 -3.13668512e-02  4.96856570e-02\n",
            "  -2.48427168e-01 -2.65872721e-02 -2.04722416e-02 -2.02499360e-01\n",
            "   4.69087213e-01  3.77350032e-01 -6.70753479e-01  6.32404834e-02\n",
            "  -1.62259042e-01  5.76357245e-02  4.70928885e-02  4.85882372e-01\n",
            "  -4.74347994e-02  7.90883839e-01  6.92133188e-01  5.61389387e-01\n",
            "  -1.35658652e-01 -2.37427279e-01 -2.82751769e-01  5.01778871e-02\n",
            "  -2.20517263e-01 -7.51747191e-02  1.90781683e-01  8.95943522e-01\n",
            "   6.81618810e-01 -1.77775517e-01 -1.85021851e-02  3.10321480e-01\n",
            "  -2.70257831e-01  5.60379811e-02  7.29626119e-02 -6.75586224e-01]\n",
            " [ 4.33235839e-02 -1.24669723e-01 -4.92673367e-02 -2.09572554e-01\n",
            "   1.00706674e-01 -1.30996808e-01 -8.60845521e-02 -8.58301222e-02\n",
            "   8.65583047e-02 -1.40456855e-01  1.16345502e-01 -5.69580086e-02\n",
            "  -1.08209796e-01  3.67508605e-02  3.97435427e-02  2.16037169e-01\n",
            "  -2.72100093e-03  2.25264996e-01 -1.89807832e-01 -1.25287652e-01\n",
            "   3.33632886e-01 -2.18210071e-01  1.70771107e-01  1.91881821e-01\n",
            "   7.30011910e-02  2.42959768e-01  6.37694150e-02  8.66837874e-02\n",
            "   3.37396264e-02  5.15361428e-02 -1.31009802e-01  1.21684618e-01\n",
            "   6.81469262e-01  2.22778723e-01 -1.43399879e-01 -2.05120638e-01\n",
            "  -1.25001743e-01 -1.12304516e-01  6.89909384e-02 -4.08222198e-01\n",
            "   1.42358914e-01  1.60968140e-01  1.96849644e-01 -1.44191667e-01\n",
            "  -1.57921419e-01 -2.03076467e-01  3.82787436e-02  3.68601121e-02\n",
            "   4.81715761e-02  1.84445336e-01 -7.42956251e-02 -6.47835433e-02\n",
            "  -2.85769463e-01 -2.92013913e-01 -5.42441290e-03 -2.01622739e-01\n",
            "   2.42162980e-02  1.25267655e-01 -6.97873235e-02  1.26887843e-01\n",
            "  -3.26555111e-02 -4.53978330e-02  1.52565762e-01  8.64478797e-02\n",
            "   2.65461057e-01 -1.05277419e-01 -4.49869856e-02 -2.15329856e-01\n",
            "  -1.91741601e-01 -8.34149048e-02 -2.73847915e-02  6.62053898e-02\n",
            "  -7.23778978e-02 -5.74355796e-02 -1.53873533e-01 -4.53310721e-02\n",
            "  -2.30026647e-01  1.28284082e-01 -1.29634261e-01 -1.63504750e-01\n",
            "  -1.55700475e-01 -9.87883098e-03  1.21576801e-01 -6.04664907e-02\n",
            "  -1.70909107e-01 -1.45559192e-01  1.01687610e-01 -2.37325400e-01\n",
            "  -1.73064753e-01  1.09253973e-01 -1.61662012e-01  1.74341485e-01\n",
            "   3.32369477e-01 -3.69897746e-02  2.49730069e-02  2.06167832e-01\n",
            "   1.07166901e-01 -1.23258464e-01  2.77334869e-01  6.37215376e-02]]\n",
            "Biases: [[ 0.09995206  0.24525145  0.1763636  ... -0.06197969  0.19761497\n",
            "   0.16281365]\n",
            " [ 0.16561721 -0.05478821 -0.03792811 ... -0.1936629   0.07853879\n",
            "   0.23236203]\n",
            " [ 0.2269671   0.29232648  0.08941542 ...  0.19545944  0.24253258\n",
            "  -0.09198027]\n",
            " ...\n",
            " [ 0.2986964  -0.02272822  0.10009474 ...  0.04668258 -0.1785467\n",
            "   0.1240236 ]\n",
            " [ 0.03560422  0.07462832  0.09775057 ... -0.15853177 -0.1217997\n",
            "   0.00469827]\n",
            " [ 0.17074667 -0.00848499  0.0853593  ... -0.09313581 -0.01712287\n",
            "  -0.034461  ]]\n",
            "Layer Name: lstm_75\n",
            "Weights: [[-7.82788098e-02 -2.57031292e-01 -2.57469058e-01 -2.81515092e-01\n",
            "   9.97613147e-02 -2.55747736e-01  5.79982661e-02 -1.24693692e-01\n",
            "  -4.38259423e-01 -5.20054638e-01  4.04314324e-02 -4.65479672e-01\n",
            "  -1.57472759e-01 -2.38696113e-03 -7.27013946e-02 -2.53872633e-01\n",
            "  -1.27095118e-01  7.24426284e-02  3.05501223e-01  3.60291064e-01\n",
            "  -1.96652710e-01 -1.38799086e-01 -1.75049290e-01 -2.11377785e-01\n",
            "  -1.70402303e-01 -1.52652329e-02 -4.34331074e-02 -1.06736742e-01\n",
            "  -4.70687807e-01 -6.35928214e-01  8.99827108e-03 -6.35564506e-01\n",
            "  -2.32454091e-01 -7.14928806e-02 -1.11145742e-01  4.17344756e-02\n",
            "  -3.18645686e-01  1.89373463e-01  4.26920205e-01  2.68996239e-01]\n",
            " [-6.46223947e-02 -5.23024738e-01  2.70519406e-01 -1.80601463e-01\n",
            "  -1.57862902e-01 -1.00134825e-02  1.97075546e-01  1.21328704e-01\n",
            "  -3.66907924e-01  9.67568681e-02  3.87197435e-02  1.65646061e-01\n",
            "   1.35606453e-01 -1.57027289e-01 -2.20011935e-01 -2.58037239e-01\n",
            "  -1.07132033e-01 -7.73484781e-02  3.53509963e-01  4.24674571e-01\n",
            "  -3.72129343e-02 -4.52651531e-01  9.34252981e-03 -5.74297905e-02\n",
            "  -1.55518487e-01 -2.02001035e-02 -7.45040774e-02 -5.30833937e-02\n",
            "   6.89962059e-02 -3.49684685e-01  9.74916220e-02 -4.00407612e-01\n",
            "   1.31830662e-01 -1.08921118e-01 -1.19296975e-01 -1.96971729e-01\n",
            "   2.62982547e-01 -2.28947904e-02  3.64714712e-01  1.24921940e-01]\n",
            " [ 1.01615213e-01 -2.26222932e-01  7.07115186e-03 -1.53953537e-01\n",
            "  -1.29902503e-02  1.51821822e-01 -6.63317963e-02  1.21319257e-01\n",
            "  -6.16299808e-01 -2.34695449e-01  1.00401103e-01 -3.68052691e-01\n",
            "  -1.72767177e-01  2.94308625e-02  6.28070533e-02 -2.19471455e-01\n",
            "  -1.14875615e-01 -8.63596201e-02 -3.75947170e-02 -2.54003316e-01\n",
            "  -1.78835511e-01 -2.92989254e-01 -9.15330872e-02 -8.64462778e-02\n",
            "  -6.57634735e-02 -1.81391150e-01 -1.23087697e-01 -6.08354323e-02\n",
            "   1.65269878e-02 -1.92975387e-01  9.15649161e-02 -4.00487721e-01\n",
            "  -2.48203158e-01 -3.17122102e-01  2.68198311e-01 -2.74979621e-01\n",
            "  -5.83677646e-03  3.40592086e-01 -5.80860637e-02  1.08556911e-01]\n",
            " [-3.00957084e-01 -7.06894994e-02 -5.87649941e-02  4.61275950e-02\n",
            "  -2.82579541e-01 -1.52930215e-01 -1.56635672e-01  1.66914016e-01\n",
            "  -1.89890519e-01 -1.98726580e-01  2.02814460e-01 -9.11151469e-02\n",
            "  -7.04815686e-02 -3.44570987e-02 -1.80396020e-01  9.35806930e-02\n",
            "   2.35818014e-01  1.44362658e-01  3.27450782e-02 -1.15396213e-02\n",
            "  -3.30808461e-01 -1.10370055e-01 -1.61810413e-01 -7.89346248e-02\n",
            "  -7.89716467e-02 -1.53688073e-01 -2.11501032e-01 -6.31803423e-02\n",
            "   9.56156012e-03 -1.81085855e-01  1.68474987e-01  1.20933866e-03\n",
            "   1.40206069e-01  2.31039613e-01 -1.26879558e-01 -9.56514291e-03\n",
            "   5.36825210e-02  3.34887326e-01  3.21007520e-01  3.54621470e-01]\n",
            " [-2.65521318e-01 -1.19617909e-01  2.69469649e-01 -1.52705178e-01\n",
            "  -2.03324348e-01 -1.47525677e-02 -4.78621535e-02 -1.90328628e-01\n",
            "  -2.23149285e-01 -5.08590162e-01 -2.59959579e-01  1.90182060e-01\n",
            "   2.68787503e-01 -1.08677737e-01  1.95070744e-01 -3.48504901e-01\n",
            "  -3.21529388e-01  2.68720537e-01 -9.49162786e-05  1.71437547e-01\n",
            "  -1.03012927e-01 -2.04183534e-01 -1.88710138e-01  2.88094790e-03\n",
            "   7.42333233e-02  1.46687739e-02  5.26663661e-02 -1.51002221e-02\n",
            "  -2.65572757e-01 -3.14824492e-01  1.01232320e-01 -1.43800557e-01\n",
            "   3.07704568e-01  1.40724093e-01  5.90772666e-02  1.61996365e-01\n",
            "   1.66486531e-01  1.30291805e-01  5.33664972e-02  1.14124998e-01]\n",
            " [-7.92689025e-02 -3.71839434e-01 -1.70574069e-01 -2.61276364e-01\n",
            "  -2.32835829e-01 -2.27758691e-01  2.63336271e-01 -1.16962761e-01\n",
            "  -9.05023366e-02 -1.89790562e-01  2.17900515e-01 -1.04824170e-01\n",
            "   1.36909932e-01 -5.54402508e-02 -2.12648243e-01  2.31828794e-01\n",
            "  -3.05229515e-01  1.12063505e-01  7.88377523e-01  4.52599466e-01\n",
            "  -3.31269145e-01 -9.86416414e-02 -3.08307916e-01 -1.83307126e-01\n",
            "   1.07402943e-01 -3.99272382e-01 -7.51411095e-02 -6.55727610e-02\n",
            "  -3.20651650e-01 -5.74130863e-02 -2.83981450e-02 -4.90041077e-02\n",
            "   1.19080722e-01  1.70919269e-01  2.88365066e-01  1.26709804e-01\n",
            "   9.96665359e-02  3.59453321e-01  1.54086024e-01 -1.05742604e-01]\n",
            " [ 9.60362051e-03 -1.31568192e-02  2.94011593e-01 -2.96794415e-01\n",
            "   5.23582660e-02  1.99801009e-02 -1.75499365e-01 -1.90768033e-01\n",
            "  -5.19399419e-02 -1.77288473e-01 -1.30297303e-01  1.21523282e-02\n",
            "  -3.60940062e-02  8.41658860e-02 -8.59508738e-02  3.96201685e-02\n",
            "   3.10326040e-01 -2.04604454e-02  4.38634843e-01  8.33472669e-01\n",
            "  -4.00101393e-01  1.22934483e-01 -1.08793303e-01  1.00179210e-01\n",
            "  -9.79651958e-02  1.72333911e-01 -2.10083532e-03 -2.59240866e-01\n",
            "  -6.24004453e-02  1.03717417e-01  6.93419725e-02 -2.51747459e-01\n",
            "   3.34116854e-02 -1.20668732e-01 -1.54453605e-01  6.33804128e-02\n",
            "   2.36768663e-01 -9.34734847e-03  2.62119472e-01  1.97086498e-01]\n",
            " [-3.13296914e-01 -3.05774987e-01  3.32237110e-02 -1.76812589e-01\n",
            "   2.00563684e-01  5.56511506e-02  1.64721310e-01  1.17072538e-01\n",
            "   3.64404440e-01  3.77606541e-01 -2.15921253e-01 -3.99561465e-01\n",
            "   1.22209087e-01 -8.83235503e-03  1.38558075e-01 -6.35103881e-02\n",
            "   9.55617987e-03  4.35834110e-01  1.29936486e-01  4.18085515e-01\n",
            "  -3.72560054e-01  1.61741346e-01 -1.96890663e-02 -3.04318726e-01\n",
            "  -2.74451226e-01 -1.31024837e-01 -2.50497401e-01 -5.56850918e-02\n",
            "   2.09798530e-01  3.98068219e-01 -9.52675641e-02 -8.77293050e-02\n",
            "   1.49656549e-01  1.83128193e-01 -1.85703471e-01 -1.45499051e-01\n",
            "  -2.10498691e-01  2.93541819e-01 -7.85314143e-01 -4.60347772e-01]\n",
            " [ 4.82901223e-02 -1.29452022e-02  4.01804708e-02 -1.20773632e-03\n",
            "   1.57856688e-01 -3.81040901e-01 -2.43182391e-01 -3.29251111e-01\n",
            "  -1.75028890e-02  1.23010859e-01 -1.45632148e-01 -3.51788163e-01\n",
            "  -2.97434293e-02 -2.75979936e-01  7.70136192e-02 -1.12435147e-01\n",
            "  -1.07745498e-01 -4.49910350e-02 -2.15084851e-01 -1.34365723e-01\n",
            "   1.56247318e-01 -2.10191727e-01 -2.80159056e-01 -3.04297507e-01\n",
            "   1.48464575e-01 -2.44204938e-01 -1.17716506e-01  9.50871035e-02\n",
            "   2.74698168e-01  4.24807400e-01  2.04391927e-01 -2.31181636e-01\n",
            "   3.40265557e-02  7.04264715e-02  2.12710246e-01 -1.61605492e-01\n",
            "  -9.67770144e-02  2.78784037e-01 -8.46080363e-01 -8.56317401e-01]\n",
            " [ 2.50383884e-01 -5.26556015e-01 -2.51177967e-01  3.06802914e-02\n",
            "  -2.80569464e-01 -2.73762017e-01  1.08197287e-01 -2.21303612e-01\n",
            "  -3.52707922e-01 -6.91433787e-01  1.74461320e-01 -2.79070199e-01\n",
            "  -1.06645308e-01  2.69721299e-01 -1.22110933e-01 -4.56338823e-02\n",
            "   1.25440285e-01 -1.17152341e-01 -1.72004998e-01 -4.93786633e-01\n",
            "   1.78143516e-01 -2.82740265e-01 -5.99685721e-02  3.36846546e-03\n",
            "  -1.97905645e-01 -4.87835966e-02 -1.06150180e-01  1.96916834e-02\n",
            "   3.15843076e-02  3.70795093e-03  5.48190735e-02 -3.85422587e-01\n",
            "   2.48565182e-01 -6.52265698e-02  2.51888514e-01 -1.20423011e-01\n",
            "  -1.78499907e-01  2.71412849e-01 -1.36193693e-01 -3.30287695e-01]\n",
            " [-1.29444733e-01 -3.82534787e-02  2.07672596e-01 -3.26358527e-01\n",
            "   2.05512464e-01  2.01172188e-01 -2.24460885e-02  1.03169799e-01\n",
            "   3.24029535e-01 -2.06357941e-01  2.08246429e-02 -1.93781599e-01\n",
            "  -5.86106665e-02 -1.93961337e-01 -1.68798313e-01  6.88775107e-02\n",
            "  -2.31216222e-01 -2.05164075e-01  5.02863586e-01  2.38309875e-01\n",
            "  -1.33569390e-01 -2.00852573e-01  4.79109259e-03  3.26503739e-02\n",
            "  -8.44630525e-02 -3.22290927e-01 -3.13561797e-01 -2.54897833e-01\n",
            "  -2.80887216e-01 -2.19475199e-02 -2.67432809e-01  1.12562381e-01\n",
            "  -4.97779623e-02 -6.75090998e-02  2.81055775e-02  2.08489858e-02\n",
            "   1.01104185e-01  4.22219001e-02  2.62950152e-01  6.05695881e-02]\n",
            " [ 3.51450965e-02 -9.31301415e-02 -1.99659690e-01  1.83054119e-01\n",
            "   2.65826255e-01  1.46468341e-01 -1.60623014e-01 -2.31797606e-01\n",
            "  -4.84652072e-01 -1.22294232e-01  1.45676918e-02 -3.37164909e-01\n",
            "  -8.13449994e-02 -2.71349877e-01  1.40465036e-01 -1.71387538e-01\n",
            "  -2.54733264e-01  3.16502720e-01  4.45367061e-02  8.03115740e-02\n",
            "   6.29664883e-02 -8.35738033e-02 -7.87917748e-02 -2.53164414e-02\n",
            "  -2.32436210e-01 -1.29599184e-01 -4.89158221e-02  9.26626548e-02\n",
            "  -3.66674393e-01 -3.58509272e-01  7.32036009e-02  2.81519406e-02\n",
            "  -1.24250785e-01 -3.86311263e-02 -2.27189466e-01  4.92466502e-02\n",
            "   3.02949518e-01  7.23971725e-02 -6.28294200e-02 -4.47284281e-02]\n",
            " [ 2.86105037e-01 -3.00498307e-01 -1.64488703e-01 -1.04179613e-01\n",
            "  -1.96324363e-02 -1.31457940e-01  2.65729308e-01 -2.50982810e-02\n",
            "  -1.84357420e-01  8.63948837e-02  1.07127782e-02 -1.15368277e-01\n",
            "   1.65898323e-01  8.34170282e-02  1.40396535e-01  1.70842201e-01\n",
            "  -2.95892097e-02  1.06826998e-01  3.88691127e-01 -1.86020751e-02\n",
            "   3.01192194e-01 -7.23925158e-02  2.21480533e-01 -1.86777502e-01\n",
            "  -2.87302017e-01 -1.04992561e-01 -1.45906985e-01 -2.37028316e-01\n",
            "  -3.13601971e-01  3.52217667e-02 -9.60000083e-02 -2.76722997e-01\n",
            "  -9.49027985e-02 -3.16247135e-01 -7.86354095e-02 -1.97182626e-01\n",
            "  -2.86164105e-01 -8.03407356e-02  1.65318891e-01  3.06909293e-01]\n",
            " [ 2.20391795e-01 -3.01811665e-01 -2.59855092e-01  1.04908668e-01\n",
            "  -1.84157372e-01  4.79660882e-03 -1.83185205e-01  3.02074552e-01\n",
            "   2.84607470e-01 -1.91548169e-01 -2.42256358e-01 -1.67714246e-02\n",
            "   2.12290689e-01 -1.08122244e-01  1.12394705e-01 -1.59914345e-01\n",
            "   1.27502784e-01  1.88493341e-01 -4.14417982e-02  3.24753284e-01\n",
            "  -1.21911705e-01 -1.00908756e-01 -1.42175809e-01 -8.50514248e-02\n",
            "  -1.92402780e-01 -1.32182539e-01 -1.49965003e-01 -2.02193414e-03\n",
            "  -2.22614408e-01 -6.80418909e-02 -1.96027774e-02 -2.63746679e-01\n",
            "   7.26175532e-02  2.34371960e-01  2.01118171e-01  2.32609231e-02\n",
            "   8.92865434e-02 -1.20300092e-01  3.22612792e-01  7.96522126e-02]\n",
            " [ 2.14787290e-01  1.34810179e-01  5.54947704e-02  8.20696261e-03\n",
            "   4.13176641e-02 -2.48663619e-01 -3.12085330e-01 -1.09663136e-01\n",
            "  -2.67337024e-01 -1.89961001e-01  4.91622984e-02 -4.18152958e-02\n",
            "  -2.41103694e-02 -2.16331724e-02 -7.23404735e-02 -1.60356089e-01\n",
            "  -1.09118417e-01  1.42171323e-01  2.35422194e-01  3.48330200e-01\n",
            "  -3.44456762e-01  6.24562167e-02 -1.80408895e-01 -1.99401975e-01\n",
            "  -3.29176217e-01 -3.71017978e-02 -2.05578655e-01 -5.48843145e-02\n",
            "  -3.26947480e-01 -4.04849946e-01  3.57455462e-01 -2.34680951e-01\n",
            "   7.17861801e-02  2.81936109e-01  2.64773279e-01 -2.05345694e-02\n",
            "   3.07939947e-02  1.30034283e-01  4.75748688e-01  2.32364669e-01]\n",
            " [ 1.37227297e-01 -3.28990400e-01  1.59347609e-01  1.03552528e-01\n",
            "   1.80033788e-01  1.09057371e-02  1.89341828e-01 -3.71179342e-01\n",
            "  -1.72558531e-01 -8.54079664e-01 -1.85890391e-01 -4.62251246e-01\n",
            "  -2.98418581e-01  2.71770120e-01  1.64307624e-01 -4.75583404e-01\n",
            "  -1.27785712e-01  6.07022569e-02 -8.68329480e-02  7.98391551e-02\n",
            "  -1.18617013e-01 -5.23074627e-01 -2.57092059e-01  6.56405613e-02\n",
            "  -2.05659658e-01 -9.23916921e-02 -2.39692032e-01 -3.39158624e-02\n",
            "   2.45592788e-01 -3.76249224e-01 -1.87270403e-01 -5.07998168e-01\n",
            "   2.09510460e-01 -1.35709226e-01 -2.76429951e-01 -6.52061626e-02\n",
            "   2.92855531e-01  2.08180368e-01 -4.20703515e-02 -3.66691127e-02]\n",
            " [ 7.39287063e-02  1.01962000e-01 -2.29495794e-01 -2.71629363e-01\n",
            "   9.27034467e-02 -2.42710002e-02 -1.49983495e-01  1.08379804e-01\n",
            "   6.28508449e-01 -6.20060153e-02 -9.11103114e-02  2.43676737e-01\n",
            "   2.14641750e-01 -3.42090875e-02 -2.64469475e-01  2.98429102e-01\n",
            "   2.86933929e-02 -8.03229511e-02  5.70515059e-02 -4.58588809e-01\n",
            "   2.09598746e-02  2.09897310e-01 -1.34332880e-01 -1.97750524e-01\n",
            "  -2.68722743e-01 -1.24693722e-01 -2.24934861e-01 -2.73215711e-01\n",
            "   4.08991575e-01  4.02929276e-01  8.37458447e-02  3.04630578e-01\n",
            "   3.56644876e-02  9.34566036e-02 -2.04300717e-01 -1.34509355e-02\n",
            "   2.09622577e-01  7.86382109e-02 -7.90668070e-01 -7.18955815e-01]\n",
            " [ 9.69141722e-02 -1.55942470e-01 -8.48080739e-02 -3.26437920e-01\n",
            "   8.29468071e-02  1.54111102e-01  1.58969387e-01  3.42396170e-01\n",
            "   3.40306848e-01  2.38800451e-01  1.49599284e-01  2.80721903e-01\n",
            "  -5.27414493e-02  1.54998958e-01 -2.61690617e-01 -9.08456519e-02\n",
            "   3.05837509e-03 -2.98950285e-01  6.13903880e-01  2.26362094e-01\n",
            "  -7.99258798e-02 -1.06745526e-01 -9.27136932e-03  4.81923111e-02\n",
            "  -1.76095646e-02  1.89338669e-01 -1.72675818e-01 -2.23233357e-01\n",
            "   1.06427178e-01  3.80039752e-01 -1.72288883e-02  1.12751804e-01\n",
            "   1.68685213e-01 -8.40975791e-02 -2.12950334e-01  8.31526220e-02\n",
            "   1.20078579e-01  1.86758101e-01 -5.54118931e-01 -6.66749775e-01]\n",
            " [ 2.18699058e-03  4.85147864e-01 -3.29384394e-02 -2.92191803e-02\n",
            "   2.11517781e-01 -2.82351851e-01 -4.98273745e-02  2.19945177e-01\n",
            "   4.27993536e-01  2.58450932e-03 -1.10502668e-01  1.75451845e-01\n",
            "  -2.49522582e-01  6.47619516e-02  5.80122620e-02  1.92008257e-01\n",
            "  -2.56872475e-01  3.25203478e-01  1.15505552e+00 -1.68371394e-01\n",
            "  -2.05863845e-02  8.77897218e-02  1.72238033e-02 -2.98832774e-01\n",
            "   1.80214882e-01  2.40632191e-01 -2.96092719e-01 -2.60812007e-02\n",
            "   3.15473646e-01  2.86604345e-01  1.17077880e-01  4.23335373e-01\n",
            "  -2.42764741e-01  2.31240213e-01 -2.41792277e-01 -2.35191420e-01\n",
            "   1.74260259e-01  2.01007500e-01  3.90654087e-01  5.66277616e-02]\n",
            " [ 1.12034827e-01 -2.05511004e-01 -1.48651019e-01  1.67003945e-01\n",
            "   6.70091435e-02 -4.88957539e-02 -6.71384931e-02 -7.26599470e-02\n",
            "  -4.98950370e-02  7.97905251e-02 -2.12531611e-01 -7.63433799e-02\n",
            "  -2.42865816e-01  2.61065692e-01 -7.71700367e-02  1.33408859e-01\n",
            "   7.09272996e-02 -2.01079678e-02  7.36928403e-01  8.76279652e-01\n",
            "  -3.19910683e-02 -3.99284720e-01 -1.55015402e-02 -1.88809216e-01\n",
            "  -9.71819758e-02 -1.05096489e-01 -1.11084476e-01 -1.12924285e-01\n",
            "  -2.58699898e-02 -4.25568223e-01  1.21158183e-01 -2.17772111e-01\n",
            "   1.54964551e-01 -2.02976406e-01 -2.24668086e-01 -2.16908619e-01\n",
            "  -1.78541034e-01  5.33112809e-02 -6.51448406e-03  4.02236342e-01]\n",
            " [-2.10375488e-01 -9.12242010e-02 -1.89578012e-01  1.36108130e-01\n",
            "  -2.82472253e-01 -3.96510959e-01 -2.95813292e-01 -7.00604841e-02\n",
            "  -1.17878774e-02  1.17919743e-01  1.19155735e-01 -1.31705269e-01\n",
            "   1.22480832e-01  2.11665824e-01  8.56273249e-02  3.22471887e-01\n",
            "  -1.25444204e-01 -6.66171834e-02  5.62748194e-01  7.39019334e-01\n",
            "  -1.29306512e-02 -1.96745113e-01  4.25702594e-02 -2.03701615e-01\n",
            "   1.71882570e-01 -3.40483069e-01  1.08449431e-02 -2.66992450e-01\n",
            "   7.10943416e-02  8.79070535e-02  2.28712410e-01  5.37071861e-02\n",
            "   1.29280418e-01 -1.90882921e-01  2.42178500e-01 -3.72189134e-01\n",
            "  -1.55636460e-01  2.25646392e-01 -6.03661425e-02 -2.21583918e-01]\n",
            " [ 2.24559102e-02 -3.78222495e-01 -9.16467085e-02 -7.84745719e-03\n",
            "   8.67279097e-02  3.39198373e-02 -2.41430923e-01  2.22028688e-01\n",
            "   3.50745879e-02  3.64943072e-02 -7.88800344e-02  3.48744750e-01\n",
            "   5.05735539e-02 -2.26562679e-01 -2.65544266e-01  1.51412696e-01\n",
            "   1.46780729e-01  2.60000199e-01  2.69594014e-01 -1.98724791e-01\n",
            "   4.70059961e-02 -2.56791353e-01  3.15219983e-02 -1.78247377e-01\n",
            "  -2.81627059e-01 -1.01604730e-01  2.44095966e-01 -2.97398001e-01\n",
            "   2.16054261e-01  1.91911291e-02  4.67359908e-02 -9.08965841e-02\n",
            "   2.09087357e-01 -1.26239777e-01 -1.94538698e-01 -2.78303951e-01\n",
            "   2.53277540e-01 -2.73441374e-01 -7.08446264e-01 -6.20013118e-01]\n",
            " [-4.52159606e-02  1.12521343e-01 -2.63290461e-02  8.52373540e-02\n",
            "  -5.28819412e-02  1.33507937e-01  1.09097570e-01 -6.00277781e-02\n",
            "  -5.28778397e-02 -1.16097257e-02  1.37969211e-01  1.85673133e-01\n",
            "  -7.48216407e-03  2.92181894e-02 -2.42897362e-01  1.89951226e-01\n",
            "  -4.88294894e-03  6.74438700e-02  6.06731176e-01  2.28319690e-01\n",
            "   1.90295447e-02 -1.60421044e-01 -2.25155009e-03 -2.17494637e-01\n",
            "  -1.91390976e-01  3.95142883e-02 -7.04264641e-02 -6.28477149e-03\n",
            "   2.24640742e-01  4.49800104e-01  9.56761390e-02 -2.69325972e-01\n",
            "   1.33178100e-01 -2.79394925e-01 -1.03415862e-01 -2.15255305e-01\n",
            "   1.94145665e-02 -1.88562870e-01 -4.37835246e-01 -3.29248041e-01]\n",
            " [ 1.47932723e-01 -1.09621882e-01 -1.42608151e-01 -1.19726084e-01\n",
            "  -8.61312672e-02 -2.83181131e-01 -1.88885719e-01 -1.98721245e-01\n",
            "   3.59098673e-01  4.70948927e-02 -2.57512391e-01 -1.43160343e-01\n",
            "   1.23716578e-01  2.90940136e-01  1.81635648e-01  1.89969718e-01\n",
            "  -4.57403101e-02  2.21728325e-01  1.50758564e-01  7.15349019e-01\n",
            "   7.78547674e-02 -3.85727249e-02 -2.94153363e-01 -3.05571914e-01\n",
            "   5.03188185e-02  3.68025243e-01  2.11655691e-01  2.47700308e-02\n",
            "  -7.33962059e-02  1.38800249e-01 -4.76604737e-02  5.05142100e-02\n",
            "  -1.44123897e-01 -2.17117369e-01  4.19836864e-02  2.00906366e-01\n",
            "   2.26484872e-02  7.14695007e-02 -1.36038497e-01 -1.40855595e-01]\n",
            " [ 1.04574030e-02 -1.16381742e-01 -2.53339052e-01 -3.62372220e-01\n",
            "  -2.93228447e-01 -2.79141128e-01  1.34783015e-01 -2.24706501e-01\n",
            "  -3.40221450e-02 -8.61155510e-01  2.58593917e-01 -6.31401360e-01\n",
            "   1.16806656e-01  2.56021261e-01  1.26453027e-01 -2.52216309e-01\n",
            "  -1.20245568e-01  3.24620038e-01 -5.59009835e-02 -2.54400909e-01\n",
            "  -1.03600532e-01 -1.21620320e-01 -2.88909018e-01 -2.81653374e-01\n",
            "   1.38547853e-01  1.59351125e-01  1.83009103e-01 -1.91048846e-01\n",
            "  -1.54464677e-01 -2.68624634e-01  2.76225954e-01 -3.64724666e-01\n",
            "   1.31075397e-01 -1.94881573e-01  5.04846275e-02  1.03384815e-01\n",
            "  -2.51179963e-01 -1.74681962e-01  2.31854349e-01 -1.03475116e-01]]\n",
            "Biases: [[-0.13950613 -0.09613501  0.11080331  0.02610227 -0.12887609  0.03682473\n",
            "  -0.1566824   0.06752008 -0.148964   -0.29390404  0.04137509 -0.1456407\n",
            "  -0.00730335  0.07022744 -0.00808057  0.06817728 -0.15787446  0.16448641\n",
            "   0.40779203  0.3747715  -0.2065625  -0.11414818 -0.37009683 -0.33077887\n",
            "  -0.11717138 -0.07971975  0.05253862  0.1373708  -0.5341725  -0.25088322\n",
            "  -0.01681245 -0.03705276  0.08929298 -0.41275036  0.10360946 -0.16085203\n",
            "  -0.25366822 -0.14788376  0.41799018 -0.02526848]\n",
            " [-0.47028485 -0.08186361 -0.14428931 -0.29092774  0.1814297   0.33927894\n",
            "  -0.1939718  -0.27057958  0.12067892  0.7458696  -0.04535355  0.3689672\n",
            "  -0.06581817 -0.09405031  0.02835025  0.2263333   0.37631652  0.6134475\n",
            "  -0.05451445  0.01826503 -0.01126834 -0.00812971 -0.12803955  0.0675559\n",
            "   0.2721613   0.21898507 -0.09386927  0.38961515  0.20570785  0.21897458\n",
            "   0.13632834  0.16587844  0.07402638 -0.2015406  -0.04272879  0.16923468\n",
            "  -0.03181392  0.551096    0.47802222 -0.16808087]\n",
            " [ 0.19487362  0.12433592 -0.15133776 -0.07428065 -0.14662631 -0.10256191\n",
            "  -0.04887474 -0.16878696 -0.00248919  0.02351988  0.28552565  0.11723506\n",
            "  -0.09958248 -0.1280253   0.07222941  0.18160805  0.22048812 -0.10698035\n",
            "  -0.04887015  0.06735208 -0.06472906  0.00364287 -0.39413157 -0.05194205\n",
            "  -0.03491879 -0.22966199  0.06001662  0.29797342 -0.04182994  0.31663904\n",
            "   0.0140363   0.22541656 -0.03683649  0.29575813  0.06743952  0.0449635\n",
            "  -0.09065152  0.16168617 -0.11302023  0.05263776]\n",
            " [ 0.1030909  -0.13570283 -0.20740056 -0.00359008  0.43630746  0.13292311\n",
            "   0.04579265 -0.06884985  0.12852281  0.15963116  0.10062102  0.1180766\n",
            "   0.01976673  0.20168126  0.06206929  0.18848506 -0.00190025 -0.30468774\n",
            "  -0.0899406   0.12063953  0.13600798 -0.19318047  0.18029526 -0.25653246\n",
            "   0.04170058 -0.03391698  0.01853785 -0.01914153  0.00876446 -0.12432096\n",
            "  -0.05380121  0.04313978  0.14086065  0.04747515  0.3966164  -0.23052669\n",
            "  -0.21780412 -0.08756052 -0.03570671  0.07101843]\n",
            " [-0.16577327  0.34837985  0.01941102  0.03234356 -0.1276212   0.2322974\n",
            "  -0.06333759  0.04766916  0.0176694   0.09406213 -0.07561991 -0.06176662\n",
            "  -0.15728678  0.15672238  0.3360472  -0.00887357 -0.16108179  0.19573548\n",
            "   0.03916115 -0.01392113  0.1262585  -0.16475335  0.11691301 -0.3261022\n",
            "   0.27625644 -0.06801151 -0.09578691  0.01124651  0.20137337  0.04377081\n",
            "   0.07256412  0.15960224 -0.22242276  0.02345846  0.03414217 -0.05923102\n",
            "  -0.1694109  -0.13126211 -0.1652646   0.2199537 ]\n",
            " [ 0.0326391   0.09066412  0.2339274  -0.10067296 -0.08313929  0.28254312\n",
            "  -0.08429138 -0.00297564 -0.03070506  0.2800254   0.22748414  0.17829642\n",
            "   0.2551557  -0.1436498   0.2484209  -0.07204869 -0.1153063   0.29707435\n",
            "  -0.04779427 -0.19684093  0.18259358 -0.04052677 -0.11086804 -0.00155271\n",
            "  -0.21444193 -0.12447095 -0.15862432  0.3315582   0.21878518 -0.14120199\n",
            "  -0.10038923 -0.28208724 -0.21814553 -0.0866529   0.09803675 -0.23709732\n",
            "   0.02105876  0.204289   -0.24014162 -0.17064273]\n",
            " [ 0.24743661 -0.28542742 -0.10574677 -0.07268716 -0.14384924  0.26519433\n",
            "  -0.32192993 -0.01565892  0.12627907 -0.1510287  -0.05024065 -0.13069488\n",
            "   0.12764363 -0.04088352 -0.19767475  0.07393551 -0.30069667  0.08398888\n",
            "  -0.06704145  0.11370791  0.01805855  0.12620313 -0.12316465 -0.08304659\n",
            "  -0.06695867  0.09697697 -0.13660282 -0.04158619  0.07658927 -0.12289265\n",
            "   0.2088488  -0.13721918  0.07491527  0.2474346   0.08411983  0.27590647\n",
            "  -0.02476882 -0.18648748 -0.01687308 -0.24340972]\n",
            " [-0.33714896  0.16949053  0.0537031  -0.23644188 -0.20192236 -0.12361825\n",
            "  -0.03988133  0.02796086 -0.08629429 -0.29143724  0.02941391  0.16385245\n",
            "   0.192656    0.20848165 -0.15945216 -0.13000777  0.05062778  0.1041327\n",
            "   0.5878757   0.491735   -0.08834094 -0.0194501  -0.10195152 -0.08016598\n",
            "   0.13628176 -0.17500874 -0.41710243  0.10103616 -0.0992757  -0.36672413\n",
            "   0.32029557 -0.13250843  0.12758379  0.15257828  0.28235272 -0.03888447\n",
            "  -0.01063924  0.11662165  0.33433884  0.21959096]\n",
            " [ 0.11404162 -0.09438193 -0.24040069  0.02466078  0.13875234 -0.28592485\n",
            "  -0.1305729   0.18382373 -0.01673564  0.05465649  0.0962344  -0.33551562\n",
            "   0.22478405 -0.0031623   0.36148667 -0.07476972  0.02241802  0.51605624\n",
            "   0.00636845 -0.00129764  0.10150312 -0.03960503 -0.33358544 -0.25966954\n",
            "  -0.18738183  0.11038141 -0.5275613   0.8277446  -0.00489507  0.02192586\n",
            "   0.38502836  0.18552558  0.11771605 -0.20522119 -0.01976465 -0.2212587\n",
            "   0.18417715  0.4036051   0.13963307 -0.30444047]\n",
            " [-0.06334265 -0.0470292  -0.13637717 -0.2743152  -0.00242865 -0.05378581\n",
            "  -0.23497914  0.2950089  -0.02758183  0.03676796  0.15781148  0.12400311\n",
            "   0.09949499  0.00578881  0.5747767  -0.08777212  0.19221011  0.3357383\n",
            "   0.00121617 -0.0040355  -0.02037096  0.15798827 -0.36814997 -0.06435021\n",
            "  -0.26988712  0.15550463 -0.26509625  0.12659681  0.00156179  0.00580967\n",
            "   0.23183502  0.37747294 -0.25890046 -0.13660765  0.13550355  0.21596469\n",
            "   0.16173969  0.12317301  0.00830073 -0.44642138]]\n",
            "Layer Name: dense_16\n",
            "Weights: [[ 0.03460957]\n",
            " [ 0.00820018]\n",
            " [ 0.41186717]\n",
            " [-0.28371778]\n",
            " [ 0.55714554]\n",
            " [ 0.02745272]\n",
            " [ 0.21243219]\n",
            " [ 0.011504  ]\n",
            " [ 0.8232028 ]\n",
            " [ 0.927361  ]]\n",
            "Biases: [0.23766707]\n"
          ]
        }
      ],
      "source": [
        "mylayers = loaded_first_model.layers\n",
        "for layer in mylayers:\n",
        "    if hasattr(layer, 'get_weights'):\n",
        "        list = layer.get_weights()\n",
        "        # print(list)\n",
        "        print('Layer Name:', layer.name)\n",
        "        print('Weights:', list[0])\n",
        "        print('Biases:', list[1])\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_first_reg = df_1[['produced_acetic_acid_mass_fraction', 'reboiler(pot)_heat_duty(Watt)', 'daily_work(min)',\n",
        "#                     'daily_work_multip_duty', 'daily_work_multip_fraction_over_duty']]\n",
        "# Y_first_reg = df_1[['upper_product_flow_rate(kg/hr)']]\n",
        "# # Y_first_reg = df_1[['upper_product_flow_rate(kg/hr)']]\n",
        "\n",
        "\n",
        "# # Y_first_reg = df_1[['upper_product_flow_rate(kg/hr)']]\n",
        "\n",
        "# X_py = np.array(X_first_reg)\n",
        "# Y_py = np.array(Y_first_reg)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train_first_reg, X_test_first_reg, Y_train_first_reg, Y_test_first_reg = train_test_split(X_py, Y_py , test_size=0.1, random_state=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>real upper product flow rate(kg/hr)</th>\n",
              "      <th>predicted upper product flow rate(kg/hr)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.353886</td>\n",
              "      <td>0.353642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.071235</td>\n",
              "      <td>1.068009</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.522495</td>\n",
              "      <td>0.523316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.909646</td>\n",
              "      <td>0.908488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.169553</td>\n",
              "      <td>2.165348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>2.056071</td>\n",
              "      <td>2.053410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>0.650351</td>\n",
              "      <td>0.650150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>0.565703</td>\n",
              "      <td>0.567084</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>0.980836</td>\n",
              "      <td>0.977171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>1.952170</td>\n",
              "      <td>1.948966</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>260 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     real upper product flow rate(kg/hr)  \\\n",
              "0                               0.353886   \n",
              "1                               1.071235   \n",
              "2                               0.522495   \n",
              "3                               0.909646   \n",
              "4                               2.169553   \n",
              "..                                   ...   \n",
              "255                             2.056071   \n",
              "256                             0.650351   \n",
              "257                             0.565703   \n",
              "258                             0.980836   \n",
              "259                             1.952170   \n",
              "\n",
              "     predicted upper product flow rate(kg/hr)  \n",
              "0                                    0.353642  \n",
              "1                                    1.068009  \n",
              "2                                    0.523316  \n",
              "3                                    0.908488  \n",
              "4                                    2.165348  \n",
              "..                                        ...  \n",
              "255                                  2.053410  \n",
              "256                                  0.650150  \n",
              "257                                  0.567084  \n",
              "258                                  0.977171  \n",
              "259                                  1.948966  \n",
              "\n",
              "[260 rows x 2 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test_newer = pd.DataFrame(X_test_first_reg)\n",
        "Y_pred_general = loaded_first_model.predict(X_test_newer.tail(260))\n",
        "\n",
        "Y_predicted_reboiler_temp = pd.DataFrame(Y_pred_general.transpose()[0])\n",
        "Y_test_newer = pd.DataFrame(Y_test_first_reg).tail(260)\n",
        "Y_test_reboiler_temp = pd.DataFrame(Y_test_newer.values.transpose()[0])\n",
        "\n",
        "pd.DataFrame({'real upper product flow rate(kg/hr)': Y_test_reboiler_temp.squeeze(),\n",
        "              'predicted upper product flow rate(kg/hr)': Y_predicted_reboiler_temp.squeeze()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 865ms/step\n",
            "neural network predict = [[0.8683878]]\n"
          ]
        }
      ],
      "source": [
        "# regressor_main.fit(X,Y)\n",
        "\n",
        "## 2\t2.098692327\t466.7\t0.99\t3.972966667\t165.749064\t163.0687495\t0.499823\t233.4326352\t99.9646\t535.1616894\t\t0.999646\t144.4940959\t0.871764174\t3.030305306\t142.1574937\t1.000000751\t4.358820871\n",
        "## 4  238.378\n",
        "\n",
        "# inputs = (2, 0.999646, 144.4940959, 142.1574937, 0.871764174, 4.358820871 ,535.1616894 , 2.098692327, 0.499823, 233.4326352, 165.749064, 163.0687495, 466.7)\n",
        "##(0.999646, 466.7, 2, 2.098692327, 0.499823, 233.4326352)\n",
        "##  0.871764174\n",
        "inputs_outter = (0.999646, 466.7, 238.378, 238.378*466.7, 238.378*0.999646/466.7, 2)\n",
        "input_data_as_numpy_array_outter = np.asarray(inputs_outter)\n",
        "input_data_reshaped_outter = input_data_as_numpy_array_outter.reshape(1, -1)\n",
        "\n",
        "print(\"neural network predict =\", loaded_first_model.predict(input_data_reshaped_outter))\n",
        "# print(\"random forest predict =\", first_model.predict(input_data_reshaped_outter))\n",
        "# print(\"decision tree predict =\", first_model_1.predict(input_data_reshaped_outter))\n",
        "# print(\"linear reg predict =\", first_model_2.predict(input_data_reshaped_outter))\n",
        "# print(\"xgb regressor predict =\", regressor_xgb.predict(input_data_reshaped_outter))\n",
        "\n",
        "# print(results)\n",
        "#'atmosphere_pressure', 'reboiler(pot)_heat_duty(Watt)', 'produced_acetic_acid_mass_fraction', 'new_reboiler(pot)_temperature(C)', 'upper_product_flow_rate(kg/hr)', 'pot_pressure(atm)', 'condenser_mass_flow_outlet_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_2 = pd.read_csv('Data_for_project_kam.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41/41 [==============================] - 1s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "Y_pred_whole_first_reg = loaded_first_model.predict(X_py)\n",
        "new_column = pd.DataFrame(Y_pred_whole_first_reg, columns=[\"predicted_upper_product_flow_rate(kg/hr)\"])\n",
        "\n",
        "\n",
        "\n",
        "df_2.__delitem__('upper_product_flow_rate(kg/hr)')\n",
        "df_2.insert(9,'predicted_upper_product_flow_rate(kg/hr)', new_column)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_1.describe()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_2.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_second_reg = df_2[['produced_acetic_acid_mass_fraction', 'reboiler(pot)_heat_duty(Watt)', 'daily_work(min)',\n",
        "#                     'daily_work_multip_duty', 'daily_work_multip_fraction_over_duty', 'condensor_pressure(atm)', 'pot_pressure(atm)', 'predicted_upper_product_flow_rate(kg/hr)']]\n",
        "\n",
        "X_second_reg = df_2[['produced_acetic_acid_mass_fraction', 'reboiler(pot)_heat_duty(Watt)', 'condensor_pressure(atm)', 'pot_pressure(atm)','fraction_over_pressure', 'duty_over_frac_multiplyed_by_pressure']]\n",
        "\n",
        "Y_second_reg = df_2[['reboiler(pot)_temperature(C)']]\n",
        "\n",
        "# X_train_second_reg, X_test_second_reg, Y_train_second_reg, Y_test_second_reg = train_test_split(X_second_reg, Y_second_reg , test_size=0.2, random_state=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 6, 25)             2700      \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 6, 30)             6720      \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 24)                5280      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,725\n",
            "Trainable params: 14,725\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout, GRU\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train_second_reg, X_test_second_reg, Y_train_second_reg, Y_test_second_reg = train_test_split(X_second_reg, Y_second_reg , test_size=0.2, random_state=6)\n",
        "n_inputs_second_reg = X_second_reg.shape[1]\n",
        "n_outputs_second_reg = Y_second_reg.shape[1]\n",
        "\n",
        "second_reg_model = Sequential()\n",
        "# second_reg_model.add(Dense(105, input_dim=n_inputs_second_reg, kernel_initializer='uniform', activation='relu'))\n",
        "# second_reg_model.add(Dense(78, kernel_initializer='uniform', activation='relu'))\n",
        "# second_reg_model.add(Dense(78, kernel_initializer='uniform', activation='relu'))\n",
        "# second_reg_model.add(Dense(78, kernel_initializer='uniform', activation='relu'))\n",
        "# second_reg_model.add(Dense(78, kernel_initializer='uniform', activation='relu'))\n",
        "# second_reg_model.add(Dense(n_outputs_second_reg))\n",
        "\n",
        "second_reg_model.add(LSTM(25, recurrent_dropout=0.2, activation='hard_sigmoid', input_shape=(n_inputs_second_reg,1), return_sequences=True))\n",
        "second_reg_model.add(LSTM(30, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "second_reg_model.add(LSTM(24, kernel_initializer='uniform', activation='relu'))\n",
        "\n",
        "# # second_reg_model.add(Dense(78, kernel_initializer='uniform', activation='relu'))\n",
        "# second_reg_model.add(LSTM(13, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "# # second_reg_model.add(Dense(78, kernel_initializer='uniform', activation='relu'))\n",
        "# second_reg_model.add(LSTM(20, recurrent_dropout=0.2, activation='relu',recurrent_activation='tanh', return_sequences=True))\n",
        "# second_reg_model.add(LSTM(25, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "# second_reg_model.add(LSTM(25, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "# second_reg_model.add(LSTM(20, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "# second_reg_model.add(Dense(78, kernel_initializer='uniform', activation='relu'))\n",
        "# second_reg_model.add(LSTM(25, recurrent_dropout=0.2, activation='relu'))\n",
        "second_reg_model.add(Dense(n_outputs_second_reg, activation='linear'))\n",
        "\n",
        "opt = optimizers.Adam(learning_rate=0.01, beta_1=0.8, beta_2=0.75, epsilon=1e-7, amsgrad=False, name='Adam')\n",
        "\n",
        "second_reg_model.compile(loss='mae', optimizer='adam')\n",
        "second_reg_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38/38 [==============================] - 0s 9ms/step - loss: 0.1281 - val_loss: 0.0618\n",
            "Epoch 2/30\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1707 - val_loss: 0.2824\n",
            "Epoch 3/30\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1393 - val_loss: 0.1478\n",
            "Epoch 4/30\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1878 - val_loss: 0.5587\n",
            "Epoch 5/30\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2565 - val_loss: 0.2348\n",
            "Epoch 6/30\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1616 - val_loss: 0.0840\n",
            "Epoch 7/30\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1650 - val_loss: 0.2832\n",
            "Epoch 8/30\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1499 - val_loss: 0.3426\n",
            "Epoch 9/30\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1678 - val_loss: 0.2772\n",
            "Epoch 10/30\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1086 - val_loss: 0.5152\n",
            "Epoch 11/30\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1511 - val_loss: 0.1216\n",
            "Epoch 12/30\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1455 - val_loss: 0.1821\n",
            "Epoch 13/30\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1360 - val_loss: 0.2069\n",
            "Epoch 14/30\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1443 - val_loss: 0.0871\n",
            "Epoch 15/30\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2204 - val_loss: 0.2285\n",
            "Epoch 16/30\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1792 - val_loss: 0.1696\n",
            "Epoch 17/30\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2074 - val_loss: 0.3769\n",
            "Epoch 18/30\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1584 - val_loss: 0.1302\n",
            "Epoch 19/30\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1409 - val_loss: 0.5988\n",
            "Epoch 20/30\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2123 - val_loss: 0.4675\n",
            "Epoch 21/30\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1524 - val_loss: 0.3652\n",
            "Epoch 22/30\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1330 - val_loss: 0.0458\n",
            "Epoch 23/30\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2130 - val_loss: 0.1071\n",
            "Epoch 24/30\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2186 - val_loss: 0.4914\n",
            "Epoch 25/30\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2387 - val_loss: 0.0955\n",
            "Epoch 26/30\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1406 - val_loss: 0.0588\n",
            "Epoch 27/30\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2101 - val_loss: 0.2967\n",
            "Epoch 28/30\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1593 - val_loss: 0.1304\n",
            "Epoch 29/30\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.1253 - val_loss: 0.1430\n",
            "Epoch 30/30\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.1274 - val_loss: 0.0448\n"
          ]
        }
      ],
      "source": [
        "# Fitting the data\n",
        "history_3 = second_reg_model.fit(X_second_reg,\n",
        "                    Y_second_reg,\n",
        "                    #shuffle = False, # Since this is time series data\n",
        "                    epochs=30,\n",
        "                    batch_size=28,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1) # Verbose outputs data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>real REBOILER TEMPERATURE</th>\n",
              "      <th>predicted REBOILER TEMPERATURE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>121.671062</td>\n",
              "      <td>121.652542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>72.833567</td>\n",
              "      <td>72.734955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>90.997136</td>\n",
              "      <td>90.930214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>90.996681</td>\n",
              "      <td>90.930275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>114.972936</td>\n",
              "      <td>115.205124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>115.125082</td>\n",
              "      <td>115.140671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>90.995937</td>\n",
              "      <td>90.930428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>102.634382</td>\n",
              "      <td>102.601685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>111.399351</td>\n",
              "      <td>111.377327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>90.993874</td>\n",
              "      <td>90.931343</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>260 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     real REBOILER TEMPERATURE  predicted REBOILER TEMPERATURE\n",
              "0                   121.671062                      121.652542\n",
              "1                    72.833567                       72.734955\n",
              "2                    90.997136                       90.930214\n",
              "3                    90.996681                       90.930275\n",
              "4                   114.972936                      115.205124\n",
              "..                         ...                             ...\n",
              "255                 115.125082                      115.140671\n",
              "256                  90.995937                       90.930428\n",
              "257                 102.634382                      102.601685\n",
              "258                 111.399351                      111.377327\n",
              "259                  90.993874                       90.931343\n",
              "\n",
              "[260 rows x 2 columns]"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test_newer_reg_2 = pd.DataFrame(X_test_second_reg)\n",
        "Y_pred_general_2 = second_reg_model.predict(X_test_newer_reg_2.tail(260))\n",
        "\n",
        "Y_predicted_upper_flow = pd.DataFrame(Y_pred_general_2.transpose()[0])\n",
        "Y_test_newer_reg_2 = pd.DataFrame(Y_test_second_reg).tail(260)\n",
        "Y_test_upper_flow = pd.DataFrame(Y_test_newer_reg_2.values.transpose()[0])\n",
        "\n",
        "pd.DataFrame({'real REBOILER TEMPERATURE': Y_test_upper_flow.squeeze(),\n",
        "              'predicted REBOILER TEMPERATURE': Y_predicted_upper_flow.squeeze()})\n",
        "\n",
        "\n",
        "# X_test_newer = pd.DataFrame(X_test_first_reg)\n",
        "# Y_pred_general = first_reg_model.predict(X_test_newer.tail(260))\n",
        "\n",
        "# Y_predicted_reboiler_temp = pd.DataFrame(Y_pred_general.transpose()[0])\n",
        "# Y_test_newer = pd.DataFrame(Y_test_first_reg).tail(260)\n",
        "# Y_test_reboiler_temp = pd.DataFrame(Y_test_newer.values.transpose()[0])\n",
        "\n",
        "# pd.DataFrame({'real upper_product_flow_rate(kg/hr)': Y_test_reboiler_temp.squeeze(),\n",
        "#               'predicted upper_product_flow_rate(kg/hr)': Y_predicted_reboiler_temp.squeeze()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(X_test_second_reg.head(6))\n",
        "print(Y_test_second_reg.head(6))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ##serialize model to YAML\n",
        "# from keras.models import model_from_json, load_model\n",
        "\n",
        "# model_neural_json_2 = second_reg_model.to_json()\n",
        "# with open(\"second_regression_model.json\", \"w\") as json_file:\n",
        "#     json_file.write(model_neural_json_2)\n",
        "    \n",
        "# ##serialize weights to HDF5\n",
        "# second_reg_model.save_weights(\"second_regression_model.h5\")\n",
        "# print(\"Saved model to disk\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ],
      "source": [
        "# ##serialize model to YAML\n",
        "# from keras.models import model_from_json, load_model\n",
        "\n",
        "# model_neural_json_2 = second_reg_model.to_json()\n",
        "# with open(\"second_regression_model_LSTM.json\", \"w\") as json_file:\n",
        "#     json_file.write(model_neural_json_2)\n",
        "    \n",
        "# ##serialize weights to HDF5\n",
        "# second_reg_model.save_weights(\"second_regression_model_LSTM.h5\")\n",
        "# print(\"Saved model to disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ],
      "source": [
        "##serialize model to YAML\n",
        "from keras.models import model_from_json, load_model\n",
        "\n",
        "model_neural_json_2 = second_reg_model.to_json()\n",
        "with open(\"second_regression_model_LSTM_only.json\", \"w\") as json_file:\n",
        "    json_file.write(model_neural_json_2)\n",
        "    \n",
        "##serialize weights to HDF5\n",
        "second_reg_model.save_weights(\"second_regression_model_LSTM_only.h5\")\n",
        "print(\"Saved model to disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from keras.models import model_from_json, load_model\n",
        "\n",
        "# ##load YAMl and create model\n",
        "# json_file = open('second_regression_model.json', 'r')\n",
        "# loaded_model_yaml = json_file.read()\n",
        "# json_file.close()\n",
        "# loaded_second_model = model_from_json(loaded_model_yaml)\n",
        "# ##load weights into new model\n",
        "# loaded_second_model.load_weights(\"second_regression_model.h5\")\n",
        "# print(\"Loaded model from disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ]
        }
      ],
      "source": [
        "from keras.models import model_from_json, load_model\n",
        "\n",
        "##load YAMl and create model\n",
        "json_file = open('second_regression_model_LSTM_only.json', 'r')\n",
        "loaded_model_yaml = json_file.read()\n",
        "json_file.close()\n",
        "loaded_second_model = model_from_json(loaded_model_yaml)\n",
        "##load weights into new model\n",
        "loaded_second_model.load_weights(\"second_regression_model_LSTM_only.h5\")\n",
        "print(\"Loaded model from disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ]
        }
      ],
      "source": [
        "from keras.models import model_from_json, load_model\n",
        "\n",
        "##load YAMl and create model\n",
        "json_file = open('second_regression_model_LSTM.json', 'r')\n",
        "loaded_model_yaml = json_file.read()\n",
        "json_file.close()\n",
        "loaded_second_model = model_from_json(loaded_model_yaml)\n",
        "##load weights into new model\n",
        "loaded_second_model.load_weights(\"second_regression_model_LSTM.h5\")\n",
        "print(\"Loaded model from disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 6, 25)             2700      \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 6, 30)             6720      \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 24)                5280      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 25        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,725\n",
            "Trainable params: 14,725\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "loaded_second_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mylayers = loaded_second_model.layers\n",
        "for layer in mylayers:\n",
        "    if hasattr(layer, 'get_weights'):\n",
        "        list = layer.get_weights()\n",
        "        print('Layer Name:', layer.name)\n",
        "        print('Weights:', list[0])\n",
        "        print('Biases:', list[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_second_reg, X_test_second_reg, Y_train_second_reg, Y_test_second_reg = train_test_split(X_second_reg, Y_second_reg , test_size=0.2, random_state=6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Data must be 1-dimensional, got ndarray of shape (6, 130) instead",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[23], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m Y_test_newer_reg_2 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(Y_test_second_reg)\u001b[38;5;241m.\u001b[39mtail(\u001b[38;5;241m130\u001b[39m)\n\u001b[0;32m      6\u001b[0m Y_test_upper_flow \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(Y_test_newer_reg_2\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtranspose()[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m----> 8\u001b[0m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreal REBOILER TEMPERATURE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test_upper_flow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m              \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredicted REBOILER TEMPERATURE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_predicted_upper_flow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Lenovo\\python\\lib\\site-packages\\pandas\\core\\frame.py:733\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    727\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    728\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    729\u001b[0m     )\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    735\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
            "File \u001b[1;32mc:\\Users\\Lenovo\\python\\lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Lenovo\\python\\lib\\site-packages\\pandas\\core\\internals\\construction.py:119\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;66;03m# don't force copy because getting jammed in an ndarray anyway\u001b[39;00m\n\u001b[1;32m--> 119\u001b[0m     arrays, refs \u001b[38;5;241m=\u001b[39m \u001b[43m_homogenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# _homogenize ensures\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m#  - all(len(x) == len(index) for x in arrays)\u001b[39;00m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;66;03m#  - all(x.ndim == 1 for x in arrays)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    125\u001b[0m \n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    127\u001b[0m     index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
            "File \u001b[1;32mc:\\Users\\Lenovo\\python\\lib\\site-packages\\pandas\\core\\internals\\construction.py:629\u001b[0m, in \u001b[0;36m_homogenize\u001b[1;34m(data, index, dtype)\u001b[0m\n\u001b[0;32m    626\u001b[0m         val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(val)\n\u001b[0;32m    627\u001b[0m     val \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mfast_multiget(val, oindex\u001b[38;5;241m.\u001b[39m_values, default\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan)\n\u001b[1;32m--> 629\u001b[0m val \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    630\u001b[0m com\u001b[38;5;241m.\u001b[39mrequire_length_match(val, index)\n\u001b[0;32m    631\u001b[0m refs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Users\\Lenovo\\python\\lib\\site-packages\\pandas\\core\\construction.py:620\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__array__\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;66;03m# e.g. dask array GH#38645\u001b[39;00m\n\u001b[0;32m    619\u001b[0m     data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(data, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m--> 620\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     _sanitize_non_ordered(data)\n",
            "File \u001b[1;32mc:\\Users\\Lenovo\\python\\lib\\site-packages\\pandas\\core\\construction.py:646\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[0;32m    643\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, subarr)\n\u001b[0;32m    644\u001b[0m             subarr \u001b[38;5;241m=\u001b[39m maybe_infer_to_datetimelike(subarr)\n\u001b[1;32m--> 646\u001b[0m subarr \u001b[38;5;241m=\u001b[39m \u001b[43m_sanitize_ndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_2d\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subarr, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;66;03m# at this point we should have dtype be None or subarr.dtype == dtype\u001b[39;00m\n\u001b[0;32m    650\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mdtype, dtype)\n",
            "File \u001b[1;32mc:\\Users\\Lenovo\\python\\lib\\site-packages\\pandas\\core\\construction.py:705\u001b[0m, in \u001b[0;36m_sanitize_ndim\u001b[1;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m allow_2d:\n\u001b[0;32m    704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m--> 705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData must be 1-dimensional, got ndarray of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    707\u001b[0m     )\n\u001b[0;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_object_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype):\n\u001b[0;32m    709\u001b[0m     \u001b[38;5;66;03m# i.e. NumpyEADtype(\"O\")\u001b[39;00m\n\u001b[0;32m    711\u001b[0m     result \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39masarray_tuplesafe(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
            "\u001b[1;31mValueError\u001b[0m: Data must be 1-dimensional, got ndarray of shape (6, 130) instead"
          ]
        }
      ],
      "source": [
        "X_test_newer_reg_2 = pd.DataFrame(X_test_second_reg)\n",
        "Y_pred_general_2 = second_reg_model.predict(X_test_newer_reg_2.tail(130))\n",
        "\n",
        "Y_predicted_upper_flow = pd.DataFrame(Y_pred_general_2.transpose()[0])\n",
        "Y_test_newer_reg_2 = pd.DataFrame(Y_test_second_reg).tail(130)\n",
        "Y_test_upper_flow = pd.DataFrame(Y_test_newer_reg_2.values.transpose()[0])\n",
        "\n",
        "pd.DataFrame({'real REBOILER TEMPERATURE': Y_test_upper_flow.squeeze(),\n",
        "              'predicted REBOILER TEMPERATURE': Y_predicted_upper_flow.squeeze()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 3ms/step\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>real REBOILER TEMPERATURE</th>\n",
              "      <th>predicted REBOILER TEMPERATURE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>107.280890</td>\n",
              "      <td>107.045189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>111.384961</td>\n",
              "      <td>111.297646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>83.189736</td>\n",
              "      <td>83.142319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>72.838146</td>\n",
              "      <td>72.896553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>115.135159</td>\n",
              "      <td>115.100639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>115.125082</td>\n",
              "      <td>115.094246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>90.995937</td>\n",
              "      <td>90.865608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>102.634382</td>\n",
              "      <td>102.495979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>111.399351</td>\n",
              "      <td>111.304955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>90.993874</td>\n",
              "      <td>90.924339</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>130 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     real REBOILER TEMPERATURE  predicted REBOILER TEMPERATURE\n",
              "0                   107.280890                      107.045189\n",
              "1                   111.384961                      111.297646\n",
              "2                    83.189736                       83.142319\n",
              "3                    72.838146                       72.896553\n",
              "4                   115.135159                      115.100639\n",
              "..                         ...                             ...\n",
              "125                 115.125082                      115.094246\n",
              "126                  90.995937                       90.865608\n",
              "127                 102.634382                      102.495979\n",
              "128                 111.399351                      111.304955\n",
              "129                  90.993874                       90.924339\n",
              "\n",
              "[130 rows x 2 columns]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test_newer_reg_2 = pd.DataFrame(X_test_second_reg)\n",
        "Y_pred_general_2 = loaded_second_model.predict(X_test_newer_reg_2.tail(130))\n",
        "\n",
        "Y_predicted_upper_flow = pd.DataFrame(Y_pred_general_2.transpose()[0])\n",
        "Y_test_newer_reg_2 = pd.DataFrame(Y_test_second_reg).tail(130)\n",
        "Y_test_upper_flow = pd.DataFrame(Y_test_newer_reg_2.values.transpose()[0])\n",
        "\n",
        "pd.DataFrame({'real REBOILER TEMPERATURE': Y_test_upper_flow.squeeze(),\n",
        "              'predicted REBOILER TEMPERATURE': Y_predicted_upper_flow.squeeze()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_2 = pd.read_csv(\"Data_for_project_kam.csv\")\n",
        "df_3 = df_2\n",
        "Y_pred_whole_second_reg = loaded_second_model.predict(X_second_reg)\n",
        "new_column_2 = pd.DataFrame(Y_pred_whole_second_reg, columns=[\"predicted_reboiler(pot)_temperature(C)\"])\n",
        "\n",
        "# X_second_reg = X_first_reg.insert(17,'predicted_reboiler(pot)_temperature(C)', new_column)\n",
        "\n",
        "\n",
        "df_3.__delitem__('reboiler(pot)_temperature(C)')\n",
        "df_3.insert(7,'predicted_reboiler(pot)_temperature(C)', new_column_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_2.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_3.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "INJAAAAAAAAAA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_third_reg = df_2[['produced_acetic_acid_mass_fraction', 'reboiler(pot)_heat_duty(Watt)', 'daily_work(min)',\n",
        "                    'daily_work_multip_duty', 'daily_work_multip_fraction_over_duty', 'condensor_pressure(atm)','predicted_upper_product_flow_rate(kg/hr)', 'predicted_reboiler(pot)_temperature(C)']]\n",
        "\n",
        "Y_third_reg = df_2[['reflux_ratio']]\n",
        "\n",
        "type(Y_third_reg) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train_third_reg, X_test_third_reg, Y_train_third_reg, Y_test_third_reg = train_test_split(X_third_reg, Y_third_reg , test_size=0.2, random_state=6)\n",
        "n_inputs_third_reg = X_train_third_reg.shape[1]\n",
        "n_outputs_third_reg = Y_train_third_reg.shape[1]\n",
        "\n",
        "third_reg_model = Sequential()\n",
        "third_reg_model.add(Dense(108, input_dim=n_inputs_third_reg, kernel_initializer='uniform', activation='relu'))\n",
        "third_reg_model.add(Dense(84, kernel_initializer='uniform', activation='relu'))\n",
        "third_reg_model.add(Dense(84, kernel_initializer='uniform', activation='relu'))\n",
        "third_reg_model.add(Dense(84, kernel_initializer='uniform', activation='relu'))\n",
        "third_reg_model.add(Dense(36, kernel_initializer='uniform', activation='relu'))\n",
        "third_reg_model.add(Dense(18, kernel_initializer='uniform', activation='relu'))\n",
        "\n",
        "# third_reg_model.add(LSTM(24, recurrent_dropout=0.2, activation='relu', input_shape=(n_inputs_third_reg,1), return_sequences=True))\n",
        "# third_reg_model.add(Dense(18, kernel_initializer='uniform', activation='relu'))\n",
        "# third_reg_model.add(Dense(16, kernel_initializer='uniform', activation='relu'))\n",
        "# third_reg_model.add(Dense(16, kernel_initializer='uniform', activation='relu'))\n",
        "\n",
        "# third_reg_model.add(Dense(16, kernel_initializer='uniform', activation='relu'))\n",
        "# third_reg_model.add(Dense(16, kernel_initializer='uniform', activation='relu'))\n",
        "# third_reg_model.add(LSTM(83, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "# third_reg_model.add(Dense(108, kernel_initializer='uniform', activation='relu'))\n",
        "# # second_reg_model.add(Dense(108, kernel_initializer='uniform', activation='relu'))\n",
        "\n",
        "# # first_reg_model.add(LSTM(14, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "# # second_reg_model.add(LSTM(40, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "# # second_reg_model.add(LSTM(10, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "# # second_reg_model.add(LSTM(25, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "# third_reg_model.add(LSTM(20, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "# third_reg_model.add(Dense(108, kernel_initializer='uniform', activation='relu'))\n",
        "# third_reg_model.add(LSTM(25, recurrent_dropout=0.2, activation='relu'))\n",
        "# third_reg_model.add(Dense(108, kernel_initializer='uniform', activation='relu'))\n",
        "\n",
        "# second_reg_model.add(Dense(n_outputs_second_reg))\n",
        "\n",
        "# first_reg_model.add(Dense(39, kernel_initializer='uniform', activation='relu'))\n",
        "# first_reg_model.add(Dense(26, kernel_initializer='uniform', activation='relu'))\n",
        "third_reg_model.add(Dense(n_outputs_third_reg))\n",
        "opt = optimizers.Adam(learning_rate=0.001, beta_1=0.8, beta_2=0.75, epsilon=1e-7, amsgrad=False, name='Adam')\n",
        "\n",
        "third_reg_model.compile(loss='mae', optimizer='adam')\n",
        "third_reg_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fitting the data\n",
        "history_4 = third_reg_model.fit(X_third_reg,\n",
        "                    Y_third_reg,\n",
        "                    #shuffle = False, # Since this is time series data\n",
        "                    epochs=400,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1) # Verbose outputs data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# inputs_outter = (0.999646, 466.7, 2, 2.098692327, 0.499823, 233.4326352) \n",
        "# input_data_as_numpy_array_outter = np.asarray(inputs_outter)\n",
        "# input_data_reshaped_outter = input_data_as_numpy_array_outter.reshape(1, -1)\n",
        "\n",
        "# print(\"first neural network predicts the rebioler temperature is \", loaded_first_model.predict(input_data_reshaped_outter))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# inputs_outter = (0.999646, 466.7, 2, 2.098692327, 0.499823, 233.4326352,144.0002)# 144.4940959) \n",
        "# input_data_as_numpy_array_outter = np.asarray(inputs_outter)\n",
        "# input_data_reshaped_outter = input_data_as_numpy_array_outter.reshape(1, -1)\n",
        "\n",
        "# print(\"second neural network predicts the condensor flowrate is \", loaded_second_model.predict(input_data_reshaped_outter))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # X_third_reg = df_2[['produced_acetic_acid_mass_fraction', 'reboiler(pot)_heat_duty(Watt)', 'condensor_pressure(atm)',\n",
        "# #                     'pot_pressure(atm)', 'fraction_over_pressure', 'duty_over_frac_multiplyed_by_pressure', 'predicted_reboiler(pot)_temperature(C)', 'predicted_condensor_mass_flow_outlet_rate']]\n",
        "# # Y_third_reg = df_2[['upper_product_flow_rate(kg/hr)']]\n",
        "\n",
        "# ## 2\t2.098692327\t466.7\t0.99\t3.972966667\t165.749064\t163.0687495\t0.499823\t233.4326352\t99.9646\t535.1616894\t\t0.999646\t144.4940959\t0.871764174\t3.030305306\t142.1574937\t1.000000751\t4.358820871\n",
        "# ## 142.1574937\n",
        "\n",
        "# inputs_outter = (0.999646, 466.7, 2, 2.098692327, 0.499823, 233.4326352, 144.0002, 4.3136415)# 4.358820871)\n",
        "# input_data_as_numpy_array_outter = np.asarray(inputs_outter)\n",
        "# input_data_reshaped_outter = input_data_as_numpy_array_outter.reshape(1, -1)\n",
        "\n",
        "# print(\"third neural network predicts the condensor temperature is \", third_reg_model.predict(input_data_reshaped_outter))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test_newer_reg_3 = pd.DataFrame(X_test_third_reg)\n",
        "Y_pred_general_3 = third_reg_model.predict(X_test_newer_reg_3.tail(130))\n",
        "\n",
        "Y_predicted_cond_temp = pd.DataFrame(Y_pred_general_3.transpose()[0])\n",
        "Y_test_newer_reg_3 = pd.DataFrame(Y_test_third_reg).tail(130)\n",
        "Y_test_cond_temp = pd.DataFrame(Y_test_newer_reg_3.values.transpose()[0])\n",
        "\n",
        "pd.DataFrame({'real reflux ratio': Y_test_cond_temp.squeeze(),\n",
        "              'predicted reflux ratio': Y_predicted_cond_temp.squeeze()})\n",
        "\n",
        "# X_test_newer_reg_2 = pd.DataFrame(X_test_second_reg)\n",
        "# Y_pred_general_2 = loaded_second_model.predict(X_test_newer_reg_2.tail(130))\n",
        "\n",
        "# Y_predicted_upper_flow = pd.DataFrame(Y_pred_general_2.transpose()[0])\n",
        "# Y_test_newer_reg_2 = pd.DataFrame(Y_test_second_reg).tail(130)\n",
        "# Y_test_upper_flow = pd.DataFrame(Y_test_newer_reg_2.values.transpose()[0])\n",
        "\n",
        "# pd.DataFrame({'real REBOILER TEMPERATURE': Y_test_upper_flow.squeeze(),\n",
        "#               'predicted REBOILER TEMPERATURE': Y_predicted_upper_flow.squeeze()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##serialize model to YAML\n",
        "from keras.models import model_from_json, load_model\n",
        "\n",
        "model_neural_json_3 = third_reg_model.to_json()\n",
        "with open(\"third_regression_model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_neural_json_3)\n",
        "    \n",
        "##serialize weights to HDF5\n",
        "third_reg_model.save_weights(\"third_regression_model.h5\")\n",
        "print(\"Saved model to disk\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import model_from_json, load_model\n",
        "\n",
        "##load YAMl and create model\n",
        "json_file_3 = open('third_regression_model.json', 'r')\n",
        "loaded_model_3 = json_file_3.read()\n",
        "json_file_3.close()\n",
        "loaded_third_model = model_from_json(loaded_model_3)\n",
        "##load weights into new model\n",
        "loaded_third_model.load_weights(\"third_regression_model.h5\")\n",
        "print(\"Loaded model from disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_third_reg, X_test_third_reg, Y_train_third_reg, Y_test_third_reg = train_test_split(X_third_reg, Y_third_reg , test_size=0.2, random_state=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test_newer_reg_3 = pd.DataFrame(X_test_third_reg)\n",
        "Y_pred_general_3 = loaded_third_model.predict(X_test_newer_reg_3.tail(60))\n",
        "\n",
        "Y_predicted_cond_temp = pd.DataFrame(Y_pred_general_3.transpose()[0])\n",
        "Y_test_newer_reg_3 = pd.DataFrame(Y_test_third_reg).tail(60)\n",
        "Y_test_cond_temp= pd.DataFrame(Y_test_newer_reg_3.values.transpose()[0])\n",
        "\n",
        "pd.DataFrame({'real reflux ratio': Y_test_cond_temp.squeeze(),\n",
        "              'predicted reflux ratio': Y_predicted_cond_temp.squeeze()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Y_pred_whole_third_reg = loaded_third_model.predict(X_third_reg)\n",
        "# new_column_3 = pd.DataFrame(Y_pred_whole_third_reg, columns=[\"predicted_condensor_temperature(C)\"])\n",
        "\n",
        "# # X_second_reg = X_first_reg.insert(17,'predicted_reboiler(pot)_temperature(C)', new_column)\n",
        "\n",
        "\n",
        "# df_2.__delitem__('condensor_temperature(C)')\n",
        "# df_2.insert(10,'predicted_condensor_temperature(C)', new_column_3)\n",
        "\n",
        "# df_2 = pd.read_csv(\"Data_for_project_kam.csv\")\n",
        "df_4 = df_3\n",
        "Y_pred_whole_third_reg = loaded_third_model.predict(X_third_reg)\n",
        "new_column_3 = pd.DataFrame(Y_pred_whole_third_reg, columns=[\"predicted_reflux_ratio\"])\n",
        "\n",
        "# X_second_reg = X_first_reg.insert(17,'predicted_reboiler(pot)_temperature(C)', new_column)\n",
        "\n",
        "\n",
        "df_4.__delitem__('reflux_ratio')\n",
        "df_4.insert(2,'predicted_reflux_ratio', new_column_3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_4.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_forth_reg = df_2[['produced_acetic_acid_mass_fraction', 'reboiler(pot)_heat_duty(Watt)', 'condensor_pressure(atm)', 'pot_pressure(atm)','fraction_over_pressure', 'duty_over_frac_multiplyed_by_pressure']]#, 'predicted_upper_product_flow_rate(kg/hr)', 'predicted_reboiler(pot)_temperature(C)', 'predicted_reflux_ratio']]\n",
        "Y_forth_reg = df_2[['condensor_temperature(C)']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train_forth_reg, X_test_forth_reg, Y_train_forth_reg, Y_test_forth_reg = train_test_split(X_forth_reg, Y_forth_reg , test_size=0.2, random_state=7)\n",
        "n_inputs_forth_reg = X_train_forth_reg.shape[1]\n",
        "n_outputs_forth_reg = Y_train_forth_reg.shape[1]\n",
        "\n",
        "forth_reg_model = Sequential()\n",
        "forth_reg_model.add(LSTM(24, recurrent_dropout=0.2, activation='relu', input_shape=(n_inputs_forth_reg,1), return_sequences=True))\n",
        "# forth_reg_model.add(Dense(78, kernel_initializer='uniform', activation='relu'))\n",
        "forth_reg_model.add(LSTM(13, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "# forth_reg_model.add(Dense(78, kernel_initializer='uniform', activation='relu'))\n",
        "# second_reg_model.add(Dense(48, kernel_initializer='uniform', activation='relu'))\n",
        "\n",
        "# first_reg_model.add(LSTM(14, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "# second_reg_model.add(LSTM(40, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "# second_reg_model.add(LSTM(10, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "# second_reg_model.add(LSTM(25, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "forth_reg_model.add(LSTM(18, recurrent_dropout=0.2, activation='relu', return_sequences=True))\n",
        "# forth_reg_model.add(Dense(78, kernel_initializer='uniform', activation='relu'))\n",
        "forth_reg_model.add(LSTM(28, recurrent_dropout=0.2, activation='relu'))\n",
        "# forth_reg_model.add(Dense(n_outputs_second_reg))\n",
        "\n",
        "forth_reg_model.add(Dense(n_outputs_forth_reg))\n",
        "opt = optimizers.Adam(learning_rate=0.001, beta_1=0.8, beta_2=0.75, epsilon=1e-7, amsgrad=False, name='Adam')\n",
        "\n",
        "forth_reg_model.compile(loss='mae', optimizer='adam')\n",
        "forth_reg_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history_5 = forth_reg_model.fit(X_forth_reg,\n",
        "                    Y_forth_reg,\n",
        "                    #shuffle = False, # Since this is time series data\n",
        "                    epochs=100,\n",
        "                    batch_size=32,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1) # Verbose outputs data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test_newer_reg_4 = pd.DataFrame(X_test_forth_reg)\n",
        "Y_pred_general_4 = forth_reg_model.predict(X_test_newer_reg_4.tail(60))\n",
        "\n",
        "Y_predicted_cond_temp = pd.DataFrame(Y_pred_general_4.transpose()[0])\n",
        "Y_test_newer_reg_4 = pd.DataFrame(Y_test_forth_reg).tail(60)\n",
        "Y_test_cond_temp = pd.DataFrame(Y_test_newer_reg_4.values.transpose()[0])\n",
        "\n",
        "pd.DataFrame({'real condensor temperature(C)': Y_test_cond_temp.squeeze(),\n",
        "              'predicted condensor temperature(C)': Y_predicted_cond_temp.squeeze()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "##serialize model to YAML\n",
        "from keras.models import model_from_json, load_model\n",
        "\n",
        "model_neural_json_4 = forth_reg_model.to_json()\n",
        "with open(\"fourth_regression_model_LSTM.json\", \"w\") as json_file:\n",
        "    json_file.write(model_neural_json_4)\n",
        "    \n",
        "##serialize weights to HDF5\n",
        "forth_reg_model.save_weights(\"fourth_regression_model_LSTM.h5\")\n",
        "print(\"Saved model to disk\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import model_from_json, load_model\n",
        "\n",
        "##load YAMl and create model\n",
        "json_file_4 = open('fourth_regression_model_LSTM.json', 'r')\n",
        "loaded_model_4 = json_file_4.read()\n",
        "json_file_3.close()\n",
        "loaded_fourth_model = model_from_json(loaded_model_4)\n",
        "##load weights into new model\n",
        "loaded_fourth_model.load_weights(\"fourth_regression_model_LSTM.h5\")\n",
        "print(\"Loaded model from disk\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test_newer_reg_4 = pd.DataFrame(X_test_forth_reg)\n",
        "Y_pred_general_4 = loaded_fourth_model.predict(X_test_newer_reg_4.tail(60))\n",
        "\n",
        "Y_predicted_cond_temp = pd.DataFrame(Y_pred_general_4.transpose()[0])\n",
        "Y_test_newer_reg_4 = pd.DataFrame(Y_test_forth_reg).tail(60)\n",
        "Y_test_cond_temp = pd.DataFrame(Y_test_newer_reg_4.values.transpose()[0])\n",
        "\n",
        "pd.DataFrame({'real condensor temperature(C)': Y_test_cond_temp.squeeze(),\n",
        "              'predicted condensor temperature(C)': Y_predicted_cond_temp.squeeze()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_forth_reg_1 = df_2[['produced_acetic_acid_mass_fraction', 'reboiler(pot)_heat_duty(Watt)', 'condensor_pressure(atm)',\n",
        "                    'pot_pressure(atm)', 'fraction_over_pressure', 'duty_over_frac_multiplyed_by_pressure', 'predicted_reboiler(pot)_temperature(C)', 'predicted_condensor_mass_flow_outlet_rate', 'predicted_condensor_temperature(C)']]#, 'upper_product_flow_rate(kg/hr)']]\n",
        "\n",
        "\n",
        "\n",
        "Y_forth_reg_1 = df_2[['refluxin_pot_devidedby_cond_temp']]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train_forth_reg_1, X_test_forth_reg_1, Y_train_forth_reg_1, Y_test_forth_reg_1 = train_test_split(X_forth_reg_1, Y_forth_reg_1 , test_size=0.2, random_state=6)\n",
        "n_inputs_forth_reg_1 = X_train_forth_reg_1.shape[1]\n",
        "n_outputs_forth_reg_1 = Y_train_forth_reg_1.shape[1]\n",
        "\n",
        "forth_reg_model_1 = Sequential()\n",
        "forth_reg_model_1.add(Dense(108, input_dim=n_inputs_forth_reg_1, kernel_initializer='uniform', activation='relu'))\n",
        "forth_reg_model_1.add(Dense(84, kernel_initializer='uniform', activation='relu'))\n",
        "forth_reg_model_1.add(Dense(84, kernel_initializer='uniform', activation='relu'))\n",
        "forth_reg_model_1.add(Dense(84, kernel_initializer='uniform', activation='relu'))\n",
        "forth_reg_model_1.add(Dense(84, kernel_initializer='uniform', activation='relu'))\n",
        "forth_reg_model_1.add(Dense(48, kernel_initializer='uniform', activation='relu'))\n",
        "forth_reg_model_1.add(Dense(36, kernel_initializer='uniform', activation='relu'))\n",
        "forth_reg_model_1.add(Dense(18, kernel_initializer='uniform', activation='relu'))\n",
        "\n",
        "# first_reg_model.add(Dense(39, kernel_initializer='uniform', activation='relu'))\n",
        "# first_reg_model.add(Dense(26, kernel_initializer='uniform', activation='relu'))\n",
        "forth_reg_model_1.add(Dense(n_outputs_forth_reg_1))\n",
        "opt = optimizers.Adam(learning_rate=0.001, beta_1=0.8, beta_2=0.75, epsilon=1e-7, amsgrad=False, name='Adam')\n",
        "\n",
        "forth_reg_model_1.compile(loss='mae', optimizer='adam')\n",
        "forth_reg_model_1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history_5_1 = forth_reg_model_1.fit(X_train_forth_reg_1,\n",
        "                    Y_train_forth_reg_1,\n",
        "                    #shuffle = False, # Since this is time series data\n",
        "                    epochs=2001,\n",
        "                    batch_size=65,\n",
        "                    validation_split=0.2,\n",
        "                    verbose=1) # Verbose outputs data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_test_newer_reg_4 = pd.DataFrame(X_test_forth_reg)\n",
        "Y_pred_general_4 = forth_reg_model.predict(X_test_newer_reg_4.tail(260))\n",
        "\n",
        "Y_predicted_reflux_in_reb_over_cond_temp = pd.DataFrame(Y_pred_general_4.transpose()[0])\n",
        "Y_test_newer_reg_4 = pd.DataFrame(Y_test_forth_reg).tail(260)\n",
        "Y_test_reflux_in_reb_over_cond_temp = pd.DataFrame(Y_test_newer_reg_4.values.transpose()[0])\n",
        "\n",
        "pd.DataFrame({'real condensor temperature': Y_test_reflux_in_reb_over_cond_temp.squeeze(),\n",
        "              'predicted condensor temperature': Y_predicted_reflux_in_reb_over_cond_temp.squeeze()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_train, X_test, Y_train, Y_test = train_test_split(X_n, Y , test_size=0.2, random_state=6)\n",
        "\n",
        "# def FunctionFindBestParams(X_train, y_train, X_test, Y_test):\n",
        "    \n",
        "#     batch_size_list = [5, 10, 15, 20, 25]\n",
        "#     epoch_list = [20, 40, 60, 80, 100]\n",
        "#     SearchResultsData=pd.DataFrame(columns=['TrialNumber', 'Parameters', 'Accuracy'])\n",
        "#     TrialNumber=0\n",
        "#     for batch_size_trial in batch_size_list:\n",
        "#         for epochs_trial in epoch_list:\n",
        "#             TrialNumber+=1\n",
        "#             model = main_model(X_dense.shape[1],Y_dense.shape[1])\n",
        "#             model.fit(X_train, y_train ,batch_size = batch_size_trial, epochs = epochs_trial, verbose=0)\n",
        "#             MAPE = np.mean(100 * (np.abs(Y_test-model.predict(X_test))/Y_test))\n",
        "#             print(TrialNumber, 'Parameters:','batch_size:', batch_size_trial,'-', 'epochs:',epochs_trial, 'Accuracy:', 100-MAPE)\n",
        "            \n",
        "#             SearchResultsData=SearchResultsData.append(pd.DataFrame(data=[[TrialNumber, str(batch_size_trial)+'-'+str(epochs_trial), 100-MAPE]],\n",
        "#                                                                     columns=['TrialNumber', 'Parameters', 'Accuracy'] ))\n",
        "#     return(SearchResultsData)\n",
        " \n",
        " \n",
        "# ######################################################\n",
        "# # Calling the function\n",
        "# ResultsData=FunctionFindBestParams(X_train, Y_train, X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# %matplotlib inline\n",
        "# ResultsData.plot(x='Parameters', y='Accuracy', figsize=(25,10), kind='line')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(X_n.shape)\n",
        "# print(X_n.shape[1:])\n",
        "# print(X_n.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# atm_pressure = float(input(\"please enter the atmosophere or condenser peresure in atm (a number between 0.1 and 1: )\"))\n",
        "# heat_duty_select = float(input(\"please enter the heat_duty of the heater\"+ '\\n'+ \"insert 1 if this is 466.7 watt \"+ '\\n'+ \"insert 2 if this is 933.3 watt: \" + '\\n'))\n",
        "# if heat_duty_select == 1:\n",
        "#   heat_duty = 466.7\n",
        "# elif heat_duty_select == 2:\n",
        "#   heat_duty = 933.3\n",
        "\n",
        "# acetic_acid_mf = float(input(\"please insert the acetic acid mass fraction that you prefer in distillate receiver: \"))\n",
        "# inputs = (atm_pressure, heat_duty, acetic_acid_mf)\n",
        "# boil_temp = pressure_to_boiler_temp(inputs)\n",
        "# print(boil_temp)\n",
        "# main_inputs = (atm_pressure, heat_duty, acetic_acid_mf, boil_temp)\n",
        "# input_as_numpy_array = np.asarray(main_inputs)\n",
        "# input_data = input_as_numpy_array.reshape(1, -1)\n",
        "# print(main_network.predict(input_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
